
<h1>Python API Reference<a class="headerlink" href="#python-api-reference" title="Permalink to this headline"></a></h1>
<p>This page gives the Python API reference of xgboost, please also refer to Python Package Introduction for more information about the Python package.</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#global-configuration" id="id3">Global Configuration</a></p></li>
<li><p><a class="reference internal" href="#module-xgboost.core" id="id4">Core Data Structure</a></p></li>
<li><p><a class="reference internal" href="#module-xgboost.training" id="id5">Learning API</a></p></li>
<li><p><a class="reference internal" href="#module-xgboost.sklearn" id="id6">Scikit-Learn API</a></p></li>
<li><p><a class="reference internal" href="#module-xgboost.plotting" id="id7">Plotting API</a></p></li>
<li><p><a class="reference internal" href="#module-xgboost.callback" id="id8">Callback API</a></p></li>
<li><p><a class="reference internal" href="#module-xgboost.dask" id="id9">Dask API</a></p>
<ul>
<li><p><a class="reference internal" href="#dask-extensions-for-distributed-training" id="id10">Dask extensions for distributed training</a></p>
<ul>
<li><p><a class="reference internal" href="#optional-dask-configuration" id="id11">Optional dask configuration</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<section id="global-configuration">
<h2>Global Configuration<a class="headerlink" href="#global-configuration" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="xgboost.config_context">
<span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">config_context</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">new_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.config_context" title="Permalink to this definition"></a></dt>
<dd><p>Context manager for global XGBoost configuration.</p>
<p>Global configuration consists of a collection of parameters that can be applied in the
global scope. See <a class="reference internal" href="../parameter.html#global-config"><span class="std std-ref">Global Configuration</span></a> for the full list of parameters supported in
the global configuration.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All settings, not just those presently modified, will be returned to their
previous values when the context manager is exited. This is not thread-safe.</p>
</div>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>new_config</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>Any</em><em>]</em>) – Keyword arguments representing the parameters and their values</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>

<span class="c1"># Show all messages, including ones pertaining to debugging</span>
<span class="n">xgb</span><span class="o">.</span><span class="n">set_config</span><span class="p">(</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Get current value of global configuration</span>
<span class="c1"># This is a dict containing all parameters in the global configuration,</span>
<span class="c1"># including 'verbosity'</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">config</span><span class="p">[</span><span class="s1">'verbosity'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>

<span class="c1"># Example of using the context manager xgb.config_context().</span>
<span class="c1"># The context manager will restore the previous value of the global</span>
<span class="c1"># configuration upon exiting.</span>
<span class="k">with</span> <span class="n">xgb</span><span class="o">.</span><span class="n">config_context</span><span class="p">(</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># Suppress warning caused by model generated with XGBoost version &lt; 1.0.0</span>
    <span class="n">bst</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">Booster</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s1">'./old_model.bin'</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">xgb</span><span class="o">.</span><span class="n">get_config</span><span class="p">()[</span><span class="s1">'verbosity'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>  <span class="c1"># old value restored</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#xgboost.set_config" title="xgboost.set_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_config</span></code></a></dt><dd><p>Set global XGBoost configuration</p>
</dd>
<dt><a class="reference internal" href="#xgboost.get_config" title="xgboost.get_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_config</span></code></a></dt><dd><p>Get current values of the global configuration</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="xgboost.set_config">
<span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">set_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">new_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.set_config" title="Permalink to this definition"></a></dt>
<dd><p>Set global configuration.</p>
<p>Global configuration consists of a collection of parameters that can be applied in the
global scope. See <a class="reference internal" href="../parameter.html#global-config"><span class="std std-ref">Global Configuration</span></a> for the full list of parameters supported in
the global configuration.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>new_config</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>Any</em><em>]</em>) – Keyword arguments representing the parameters and their values</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>

<span class="c1"># Show all messages, including ones pertaining to debugging</span>
<span class="n">xgb</span><span class="o">.</span><span class="n">set_config</span><span class="p">(</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Get current value of global configuration</span>
<span class="c1"># This is a dict containing all parameters in the global configuration,</span>
<span class="c1"># including 'verbosity'</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">config</span><span class="p">[</span><span class="s1">'verbosity'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>

<span class="c1"># Example of using the context manager xgb.config_context().</span>
<span class="c1"># The context manager will restore the previous value of the global</span>
<span class="c1"># configuration upon exiting.</span>
<span class="k">with</span> <span class="n">xgb</span><span class="o">.</span><span class="n">config_context</span><span class="p">(</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># Suppress warning caused by model generated with XGBoost version &lt; 1.0.0</span>
    <span class="n">bst</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">Booster</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s1">'./old_model.bin'</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">xgb</span><span class="o">.</span><span class="n">get_config</span><span class="p">()[</span><span class="s1">'verbosity'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>  <span class="c1"># old value restored</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="xgboost.get_config">
<span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Get current values of the global configuration.</p>
<p>Global configuration consists of a collection of parameters that can be applied in the
global scope. See <a class="reference internal" href="../parameter.html#global-config"><span class="std std-ref">Global Configuration</span></a> for the full list of parameters supported in
the global configuration.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>args</strong> – The list of global parameters and their values</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Dict[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, Any]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>

<span class="c1"># Show all messages, including ones pertaining to debugging</span>
<span class="n">xgb</span><span class="o">.</span><span class="n">set_config</span><span class="p">(</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Get current value of global configuration</span>
<span class="c1"># This is a dict containing all parameters in the global configuration,</span>
<span class="c1"># including 'verbosity'</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">config</span><span class="p">[</span><span class="s1">'verbosity'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>

<span class="c1"># Example of using the context manager xgb.config_context().</span>
<span class="c1"># The context manager will restore the previous value of the global</span>
<span class="c1"># configuration upon exiting.</span>
<span class="k">with</span> <span class="n">xgb</span><span class="o">.</span><span class="n">config_context</span><span class="p">(</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># Suppress warning caused by model generated with XGBoost version &lt; 1.0.0</span>
    <span class="n">bst</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">Booster</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s1">'./old_model.bin'</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">xgb</span><span class="o">.</span><span class="n">get_config</span><span class="p">()[</span><span class="s1">'verbosity'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>  <span class="c1"># old value restored</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-xgboost.core">
<span id="core-data-structure"></span><h2>Core Data Structure<a class="headerlink" href="#module-xgboost.core" title="Permalink to this headline"></a></h2>
<p>Core XGBoost Library.</p>
<dl class="py class">
<dt class="sig sig-object py" id="xgboost.DMatrix">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">DMatrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nthread</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_lower_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_upper_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Data Matrix used in XGBoost.</p>
<p>DMatrix is an internal data structure that is used by XGBoost,
which is optimized for both memory efficiency and training speed.
You can construct DMatrix from multiple different sources of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>os.PathLike/string/numpy.array/scipy.sparse/pd.DataFrame/</em>) – dt.Frame/cudf.DataFrame/cupy.array/dlpack
Data source of DMatrix.
When data is string or os.PathLike type, it represents the path
libsvm format txt file, csv file (by specifying uri parameter
‘path_to_csv?format=csv’), or binary file that xgboost can read
from.</p></li>
<li><p><strong>label</strong> (<em>array_like</em>) – Label of the training data.</p></li>
<li><p><strong>weight</strong> (<em>array_like</em>) – </p><p>Weight for each instance.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For ranking task, weights are per-group.</p>
<p>In ranking task, one weight is assigned to each group (not each
data point). This is because we only care about the relative
ordering of data points within each group, so it doesn’t make
sense to assign weights to individual data points.</p>
</div>
<p></p></li>
<li><p><strong>base_margin</strong> (<em>array_like</em>) – Base margin used for boosting from existing model.</p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>optional</em>) – Value in the input data which needs to be present as a missing
value. If None, defaults to np.nan.</p></li>
<li><p><strong>silent</strong> (<em>boolean</em><em>, </em><em>optional</em>) – Whether print messages during construction</p></li>
<li><p><strong>feature_names</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a><em>, </em><em>optional</em>) – Set names for features.</p></li>
<li><p><strong>feature_types</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Set types for features.  When <cite>enable_categorical</cite> is set to <cite>True</cite>, string
“c” represents categorical data type.</p></li>
<li><p><strong>nthread</strong> (<em>integer</em><em>, </em><em>optional</em>) – Number of threads to use for loading data when parallelization is
applicable. If -1, uses maximum threads available on the system.</p></li>
<li><p><strong>group</strong> (<em>array_like</em>) – Group size for all ranking group.</p></li>
<li><p><strong>qid</strong> (<em>array_like</em>) – Query ID for data samples, used for ranking.</p></li>
<li><p><strong>label_lower_bound</strong> (<em>array_like</em>) – Lower bound for survival training.</p></li>
<li><p><strong>label_upper_bound</strong> (<em>array_like</em>) – Upper bound for survival training.</p></li>
<li><p><strong>feature_weights</strong> (<em>array_like</em><em>, </em><em>optional</em>) – Set feature weights for column sampling.</p></li>
<li><p><strong>enable_categorical</strong> (<em>boolean</em><em>, </em><em>optional</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support of specializing for categorical features.  Do not set
to True unless you are interested in development. Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="xgboost.DMatrix.feature_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#xgboost.DMatrix.feature_names" title="Permalink to this definition"></a></dt>
<dd><p>Get feature names (column labels).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>feature_names</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#list" title="(in Python v3.6)">list</a> or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.DMatrix.feature_types">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_types</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#xgboost.DMatrix.feature_types" title="Permalink to this definition"></a></dt>
<dd><p>Get feature types (column types).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>feature_types</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#list" title="(in Python v3.6)">list</a> or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.get_base_margin">
<span class="sig-name descname"><span class="pre">get_base_margin</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.get_base_margin" title="Permalink to this definition"></a></dt>
<dd><p>Get the base margin of the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>base_margin</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.get_float_info">
<span class="sig-name descname"><span class="pre">get_float_info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">field</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.get_float_info" title="Permalink to this definition"></a></dt>
<dd><p>Get float property from the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>field</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The field name of the information</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>info</strong> – a numpy array of float information of the data</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.get_group">
<span class="sig-name descname"><span class="pre">get_group</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.get_group" title="Permalink to this definition"></a></dt>
<dd><p>Get the group of the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>group</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.get_label">
<span class="sig-name descname"><span class="pre">get_label</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.get_label" title="Permalink to this definition"></a></dt>
<dd><p>Get the label of the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>label</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.get_uint_info">
<span class="sig-name descname"><span class="pre">get_uint_info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">field</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.get_uint_info" title="Permalink to this definition"></a></dt>
<dd><p>Get unsigned integer property from the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>field</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The field name of the information</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>info</strong> – a numpy array of unsigned integer information of the data</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.get_weight">
<span class="sig-name descname"><span class="pre">get_weight</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.get_weight" title="Permalink to this definition"></a></dt>
<dd><p>Get the weight of the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>weight</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.num_col">
<span class="sig-name descname"><span class="pre">num_col</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.num_col" title="Permalink to this definition"></a></dt>
<dd><p>Get the number of columns (features) in the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>number of columns</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.num_row">
<span class="sig-name descname"><span class="pre">num_row</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.num_row" title="Permalink to this definition"></a></dt>
<dd><p>Get the number of rows in the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>number of rows</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.save_binary">
<span class="sig-name descname"><span class="pre">save_binary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.save_binary" title="Permalink to this definition"></a></dt>
<dd><p>Save DMatrix to an XGBoost buffer.  Saved binary can be later loaded
by providing the path to <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">xgboost.DMatrix()</span></code></a> as input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Name of the output buffer file.</p></li>
<li><p><strong>silent</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em> (</em><em>optional; default: True</em><em>)</em>) – If set, the output is suppressed.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.set_base_margin">
<span class="sig-name descname"><span class="pre">set_base_margin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">margin</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.set_base_margin" title="Permalink to this definition"></a></dt>
<dd><p>Set base margin of booster to start from.</p>
<p>This can be used to specify a prediction value of existing model to be
base_margin However, remember margin is needed, instead of transformed
prediction e.g. for logistic regression: need to put in value before
logistic transformation see also example/demo.py</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>margin</strong> (<em>array like</em>) – Prediction margin of each datapoint</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.set_float_info">
<span class="sig-name descname"><span class="pre">set_float_info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">field</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.set_float_info" title="Permalink to this definition"></a></dt>
<dd><p>Set float type property into the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>field</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The field name of the information</p></li>
<li><p><strong>data</strong> (<em>numpy array</em>) – The array of data to be set</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.set_float_info_npy2d">
<span class="sig-name descname"><span class="pre">set_float_info_npy2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">field</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.set_float_info_npy2d" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Set float type property into the DMatrix</dt><dd><p>for numpy 2d array input</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>field</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The field name of the information</p></li>
<li><p><strong>data</strong> (<em>numpy array</em>) – The array of data to be set</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.set_group">
<span class="sig-name descname"><span class="pre">set_group</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">group</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.set_group" title="Permalink to this definition"></a></dt>
<dd><p>Set group size of DMatrix (used for ranking).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>group</strong> (<em>array like</em>) – Group size of each group</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.set_info">
<span class="sig-name descname"><span class="pre">set_info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_lower_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_upper_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.set_info" title="Permalink to this definition"></a></dt>
<dd><p>Set meta info for DMatrix.  See doc string for <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.DMatrix</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>label</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
<li><p><strong>weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
<li><p><strong>qid</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
<li><p><strong>label_lower_bound</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
<li><p><strong>label_upper_bound</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
<li><p><strong>feature_names</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – </p></li>
<li><p><strong>feature_types</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – </p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.set_label">
<span class="sig-name descname"><span class="pre">set_label</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.set_label" title="Permalink to this definition"></a></dt>
<dd><p>Set label of dmatrix</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>label</strong> (<em>array like</em>) – The label information to be set into DMatrix</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.set_uint_info">
<span class="sig-name descname"><span class="pre">set_uint_info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">field</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.set_uint_info" title="Permalink to this definition"></a></dt>
<dd><p>Set uint type property into the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>field</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The field name of the information</p></li>
<li><p><strong>data</strong> (<em>numpy array</em>) – The array of data to be set</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.set_weight">
<span class="sig-name descname"><span class="pre">set_weight</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weight</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.set_weight" title="Permalink to this definition"></a></dt>
<dd><p>Set weight of each instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>weight</strong> (<em>array like</em>) – </p><p>Weight for each data point</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For ranking task, weights are per-group.</p>
<p>In ranking task, one weight is assigned to each group (not each
data point). This is because we only care about the relative
ordering of data points within each group, so it doesn’t make
sense to assign weights to individual data points.</p>
</div>
<p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.slice">
<span class="sig-name descname"><span class="pre">slice</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rindex</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.slice" title="Permalink to this definition"></a></dt>
<dd><p>Slice the DMatrix and return a new DMatrix that only contains <cite>rindex</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rindex</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em>) – List of indices to be selected.</p></li>
<li><p><strong>allow_groups</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Allow slicing of a matrix with a groups attribute</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new DMatrix containing only selected indices.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>res</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.DeviceQuantileDMatrix">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">DeviceQuantileDMatrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nthread</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_bin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_lower_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_upper_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DeviceQuantileDMatrix" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.core.DMatrix</span></code></a></p>
<p>Device memory Data Matrix used in XGBoost for training with tree_method=’gpu_hist’. Do
not use this for test/validation tasks as some information may be lost in
quantisation. This DMatrix is primarily designed to save memory in training from
device memory inputs by avoiding intermediate storage. Set max_bin to control the
number of bins during quantisation.  See doc string in <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.DMatrix</span></code></a> for
documents on meta info.</p>
<p>You can construct DeviceQuantileDMatrix from cupy/cudf/dlpack.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.1.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>os.PathLike/string/numpy.array/scipy.sparse/pd.DataFrame/</em>) – dt.Frame/cudf.DataFrame/cupy.array/dlpack
Data source of DMatrix.
When data is string or os.PathLike type, it represents the path
libsvm format txt file, csv file (by specifying uri parameter
‘path_to_csv?format=csv’), or binary file that xgboost can read
from.</p></li>
<li><p><strong>label</strong> (<em>array_like</em>) – Label of the training data.</p></li>
<li><p><strong>weight</strong> (<em>array_like</em>) – </p><p>Weight for each instance.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For ranking task, weights are per-group.</p>
<p>In ranking task, one weight is assigned to each group (not each
data point). This is because we only care about the relative
ordering of data points within each group, so it doesn’t make
sense to assign weights to individual data points.</p>
</div>
<p></p></li>
<li><p><strong>base_margin</strong> (<em>array_like</em>) – Base margin used for boosting from existing model.</p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>optional</em>) – Value in the input data which needs to be present as a missing
value. If None, defaults to np.nan.</p></li>
<li><p><strong>silent</strong> (<em>boolean</em><em>, </em><em>optional</em>) – Whether print messages during construction</p></li>
<li><p><strong>feature_names</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a><em>, </em><em>optional</em>) – Set names for features.</p></li>
<li><p><strong>feature_types</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Set types for features.  When <cite>enable_categorical</cite> is set to <cite>True</cite>, string
“c” represents categorical data type.</p></li>
<li><p><strong>nthread</strong> (<em>integer</em><em>, </em><em>optional</em>) – Number of threads to use for loading data when parallelization is
applicable. If -1, uses maximum threads available on the system.</p></li>
<li><p><strong>group</strong> (<em>array_like</em>) – Group size for all ranking group.</p></li>
<li><p><strong>qid</strong> (<em>array_like</em>) – Query ID for data samples, used for ranking.</p></li>
<li><p><strong>label_lower_bound</strong> (<em>array_like</em>) – Lower bound for survival training.</p></li>
<li><p><strong>label_upper_bound</strong> (<em>array_like</em>) – Upper bound for survival training.</p></li>
<li><p><strong>feature_weights</strong> (<em>array_like</em><em>, </em><em>optional</em>) – Set feature weights for column sampling.</p></li>
<li><p><strong>enable_categorical</strong> (<em>boolean</em><em>, </em><em>optional</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support of specializing for categorical features.  Do not set
to True unless you are interested in development. Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_bin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.Booster">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">Booster</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>A Booster of XGBoost.</p>
<p>Booster is the model of xgboost, that contains low level routines for
training, prediction and evaluation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a>) – Parameters for boosters.</p></li>
<li><p><strong>cache</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) – List of cache items.</p></li>
<li><p><strong>model_file</strong> (<em>string/os.PathLike/Booster/bytearray</em>) – Path to the model file if it’s string or PathLike.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.attr">
<span class="sig-name descname"><span class="pre">attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.attr" title="Permalink to this definition"></a></dt>
<dd><p>Get attribute string from the Booster.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>key</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The key to get attribute from.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>value</strong> – The attribute value of the key, returns None if attribute do not exist.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.attributes">
<span class="sig-name descname"><span class="pre">attributes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.attributes" title="Permalink to this definition"></a></dt>
<dd><p>Get attributes stored in the Booster as a dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>result</strong> – Returns an empty dict if there’s no attributes.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dictionary of  attribute_name: attribute_value pairs of strings.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.boost">
<span class="sig-name descname"><span class="pre">boost</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtrain</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hess</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.boost" title="Permalink to this definition"></a></dt>
<dd><p>Boost the booster for one iteration, with customized gradient
statistics.  Like <a class="reference internal" href="#xgboost.Booster.update" title="xgboost.Booster.update"><code class="xref py py-func docutils literal notranslate"><span class="pre">xgboost.Booster.update()</span></code></a>, this
function should not be called directly by users.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dtrain</strong> (<a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a>) – The training DMatrix.</p></li>
<li><p><strong>grad</strong> (<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a>) – The first order of gradient.</p></li>
<li><p><strong>hess</strong> (<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a>) – The second order of gradient.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.copy" title="Permalink to this definition"></a></dt>
<dd><p>Copy the booster object.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong> – a copied booster model</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><cite>Booster</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.dump_model">
<span class="sig-name descname"><span class="pre">dump_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_stats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dump_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'text'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.dump_model" title="Permalink to this definition"></a></dt>
<dd><p>Dump model into a text or JSON file.  Unlike <a class="reference internal" href="#xgboost.Booster.save_model" title="xgboost.Booster.save_model"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_model()</span></code></a>, the
output format is primarily used for visualization or interpretation,
hence it’s more human readable but cannot be loaded back to XGBoost.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fout</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name.</p></li>
<li><p><strong>fmap</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>, </em><em>optional</em>) – Name of the file containing feature map names.</p></li>
<li><p><strong>with_stats</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>optional</em>) – Controls whether the split statistics are output.</p></li>
<li><p><strong>dump_format</strong> (<em>string</em><em>, </em><em>optional</em>) – Format of model dump file. Can be ‘text’ or ‘json’.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'eval'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.eval" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the model on mat.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a>) – The dmatrix storing the input.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The name of the dataset.</p></li>
<li><p><strong>iteration</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – The current iteration number.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – Evaluation result string.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.eval_set">
<span class="sig-name descname"><span class="pre">eval_set</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">evals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.eval_set" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate a set of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>evals</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – List of items to be evaluated.</p></li>
<li><p><strong>iteration</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Current iteration.</p></li>
<li><p><strong>feval</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em>) – Custom evaluation function.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – Evaluation result string.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.Booster.feature_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#xgboost.Booster.feature_names" title="Permalink to this definition"></a></dt>
<dd><p>Feature names for this booster.  Can be directly set by input data or by
assignment.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.Booster.feature_types">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_types</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#xgboost.Booster.feature_types" title="Permalink to this definition"></a></dt>
<dd><p>Feature types for this booster.  Can be directly set by input data or by
assignment.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.get_dump">
<span class="sig-name descname"><span class="pre">get_dump</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_stats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dump_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'text'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.get_dump" title="Permalink to this definition"></a></dt>
<dd><p>Returns the model dump as a list of strings.  Unlike <a class="reference internal" href="#xgboost.Booster.save_model" title="xgboost.Booster.save_model"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_model()</span></code></a>, the output
format is primarily used for visualization or interpretation, hence it’s more
human readable but cannot be loaded back to XGBoost.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fmap</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Name of the file containing feature map names.</p></li>
<li><p><strong>with_stats</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Controls whether the split statistics are output.</p></li>
<li><p><strong>dump_format</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – Format of model dump. Can be ‘text’, ‘json’ or ‘dot’.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.get_fscore">
<span class="sig-name descname"><span class="pre">get_fscore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.get_fscore" title="Permalink to this definition"></a></dt>
<dd><p>Get feature importance of each feature.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Zero-importance features will not be included</p>
<p>Keep in mind that this function does not include zero-importance feature, i.e.
those features that have not been used in any split conditions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fmap</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – The name of feature map file</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a>]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.get_score">
<span class="sig-name descname"><span class="pre">get_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">importance_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'weight'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.get_score" title="Permalink to this definition"></a></dt>
<dd><p>Get feature importance of each feature.
For tree model Importance type can be defined as:</p>
<ul class="simple">
<li><p>‘weight’: the number of times a feature is used to split the data across all trees.</p></li>
<li><p>‘gain’: the average gain across all splits the feature is used in.</p></li>
<li><p>‘cover’: the average coverage across all splits the feature is used in.</p></li>
<li><p>‘total_gain’: the total gain across all splits the feature is used in.</p></li>
<li><p>‘total_cover’: the total coverage across all splits the feature is used in.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Zero-importance features will not be included</p>
<p>Keep in mind that this function does not include zero-importance feature, i.e.
those features that have not been used in any split conditions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fmap</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – The name of feature map file.</p></li>
<li><p><strong>importance_type</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – One of the importance types defined above.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p><ul class="simple">
<li><p>A map between feature names and their scores.  When <cite>gblinear</cite> is used for</p></li>
<li><p><em>multi-class classification the scores for each feature is a list with length</em></p></li>
<li><p><cite>n_classes</cite>, otherwise they’re scalars.</p></li>
</ul>
<p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a>]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.get_split_value_histogram">
<span class="sig-name descname"><span class="pre">get_split_value_histogram</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_pandas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.get_split_value_histogram" title="Permalink to this definition"></a></dt>
<dd><p>Get split value histogram of a feature</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The name of the feature.</p></li>
<li><p><strong>fmap</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em> (</em><em>optional</em><em>)</em>) – The name of feature map file.</p></li>
<li><p><strong>bin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><em>default None</em>) – The maximum number of bins.
Number of bins equals number of unique split values n_unique,
if bins == None or bins &gt; n_unique.</p></li>
<li><p><strong>as_pandas</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>default True</em>) – Return pd.DataFrame when pandas is installed.
If False or pandas is not installed, return numpy ndarray.</p></li>
<li><p><strong>bins</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p><ul class="simple">
<li><p><em>a histogram of used splitting values for the specified feature</em></p></li>
<li><p><em>either as numpy array or pandas DataFrame.</em></p></li>
</ul>
<p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a>[<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)">numpy.ndarray</a>, pandas.core.frame.DataFrame]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.inplace_predict">
<span class="sig-name descname"><span class="pre">inplace_predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'value'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.inplace_predict" title="Permalink to this definition"></a></dt>
<dd><p>Run prediction in-place, Unlike <a class="reference internal" href="#xgboost.Booster.predict" title="xgboost.Booster.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a> method, inplace prediction does not
cache the prediction result.</p>
<p>Calling only <code class="docutils literal notranslate"><span class="pre">inplace_predict</span></code> in multiple threads is safe and lock
free.  But the safety does not hold when used in conjunction with other
methods. E.g. you can’t train the booster in one thread and perform
prediction in the other.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">booster</span><span class="o">.</span><span class="n">set_param</span><span class="p">({</span><span class="s1">'predictor'</span><span class="p">:</span> <span class="s1">'gpu_predictor'</span><span class="p">})</span>
<span class="n">booster</span><span class="o">.</span><span class="n">inplace_predict</span><span class="p">(</span><span class="n">cupy_array</span><span class="p">)</span>

<span class="n">booster</span><span class="o">.</span><span class="n">set_param</span><span class="p">({</span><span class="s1">'predictor'</span><span class="p">:</span> <span class="s1">'cpu_predictor})</span>
<span class="n">booster</span><span class="o">.</span><span class="n">inplace_predict</span><span class="p">(</span><span class="n">numpy_array</span><span class="p">)</span>
</pre></div>
</div>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.1.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>numpy.ndarray/scipy.sparse.csr_matrix/cupy.ndarray/</em>) – cudf.DataFrame/pd.DataFrame
The input data, must not be a view for numpy array.  Set
<code class="docutils literal notranslate"><span class="pre">predictor</span></code> to <code class="docutils literal notranslate"><span class="pre">gpu_predictor</span></code> for running prediction on CuPy
array or CuDF DataFrame.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – See <a class="reference internal" href="#xgboost.Booster.predict" title="xgboost.Booster.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a> for details.</p></li>
<li><p><strong>predict_type</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – </p><ul>
<li><p><cite>value</cite> Output model prediction values.</p></li>
<li><p><cite>margin</cite> Output the raw untransformed margin value.</p></li>
</ul>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – See <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.DMatrix</span></code></a> for details.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – See <a class="reference internal" href="#xgboost.Booster.predict" title="xgboost.Booster.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">xgboost.Booster.predict()</span></code></a> for details.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p><p>See <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.DMatrix</span></code></a> for details.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
<li><p><strong>strict_shape</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><p>See <a class="reference internal" href="#xgboost.Booster.predict" title="xgboost.Booster.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">xgboost.Booster.predict()</span></code></a> for details.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>prediction</strong> – The prediction result.  When input data is on GPU, prediction
result is stored in a cupy array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy.ndarray/cupy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.load_config">
<span class="sig-name descname"><span class="pre">load_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.load_config" title="Permalink to this definition"></a></dt>
<dd><p>Load configuration returned by <cite>save_config</cite>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.num_boosted_rounds">
<span class="sig-name descname"><span class="pre">num_boosted_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.num_boosted_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Get number of boosted rounds.  For gblinear this is reset to 0 after
serializing the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.num_features">
<span class="sig-name descname"><span class="pre">num_features</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.num_features" title="Permalink to this definition"></a></dt>
<dd><p>Number of features in booster.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_contribs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approx_contribs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_interactions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with data.  The full model will be used unless <cite>iteration_range</cite> is specified,
meaning user have to either slice the model or use the <code class="docutils literal notranslate"><span class="pre">best_iteration</span></code>
attribute to get prediction from best model returned from early stopping.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>See <a class="reference internal" href="../prediction.html"><span class="doc">Prediction</span></a> for issues like thread safety and a
summary of outputs from this function.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a>) – The dmatrix storing the input.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>pred_leaf</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this option is on, the output will be a matrix of (nsample,
ntrees) with each record indicating the predicted leaf index of
each sample in each tree.  Note that the leaf index of a tree is
unique per tree, so you may find leaf 1 in both tree 1 and tree 0.</p></li>
<li><p><strong>pred_contribs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True the output will be a matrix of size (nsample,
nfeats + 1) with each record indicating the feature contributions
(SHAP values) for that prediction. The sum of all feature
contributions is equal to the raw untransformed margin value of the
prediction. Note the final column is the bias term.</p></li>
<li><p><strong>approx_contribs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Approximate the contributions of each feature.  Used when <code class="docutils literal notranslate"><span class="pre">pred_contribs</span></code> or
<code class="docutils literal notranslate"><span class="pre">pred_interactions</span></code> is set to True.  Changing the default of this parameter
(False) is not recommended.</p></li>
<li><p><strong>pred_interactions</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True the output will be a matrix of size (nsample,
nfeats + 1, nfeats + 1) indicating the SHAP interaction values for
each pair of features. The sum of each row (or column) of the
interaction values equals the corresponding SHAP value (from
pred_contribs), and the sum of the entire matrix equals the raw
untransformed margin value of the prediction. Note the last row and
column correspond to the bias term.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s
feature_names are identical.  Otherwise, it is assumed that the
feature_names are the same.</p></li>
<li><p><strong>training</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><p>Whether the prediction value is used for training.  This can effect <cite>dart</cite>
booster, which performs dropouts during training iterations but use all trees
for inference. If you want to obtain result with dropouts, set this parameter
to <cite>True</cite>.  Also, the parameter is set to true when obtaining prediction for
custom objective function.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.0.</span></p>
</div>
<p></p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <cite>iteration_range=(10,
20)</cite>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
<li><p><strong>strict_shape</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><p>When set to True, output shape is invariant to whether classification is used.
For both value and margin prediction, the output shape is (n_samples,
n_groups), n_groups == 1 when multi-class is not used.  Default to False, in
which case the output shape can be (n_samples, ) if multi-class is not used.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>prediction</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.save_config">
<span class="sig-name descname"><span class="pre">save_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.save_config" title="Permalink to this definition"></a></dt>
<dd><p>Output internal parameter configuration of Booster as a JSON
string.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.save_raw">
<span class="sig-name descname"><span class="pre">save_raw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">raw_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'deprecated'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.save_raw" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a in memory buffer representation instead of file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>raw_format</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – Format of output buffer. Can be <cite>json</cite>, <cite>ubj</cite> or <cite>deprecated</cite>.  Right now
the default is <cite>deprecated</cite> but it will be changed to <cite>ubj</cite> (univeral binary
json) in the future.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>An in memory buffer representation of the model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.set_attr">
<span class="sig-name descname"><span class="pre">set_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.set_attr" title="Permalink to this definition"></a></dt>
<dd><p>Set the attribute of the Booster.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>**kwargs</strong> – The attributes to set. Setting a value to None deletes an attribute.</p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.set_param">
<span class="sig-name descname"><span class="pre">set_param</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.set_param" title="Permalink to this definition"></a></dt>
<dd><p>Set parameters into the Booster.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>dict/list/str</em>) – list of key,value pairs, dict of key to value or simply str key</p></li>
<li><p><strong>value</strong> (<em>optional</em>) – value of the specified parameter, when params is str key</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.trees_to_dataframe">
<span class="sig-name descname"><span class="pre">trees_to_dataframe</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.trees_to_dataframe" title="Permalink to this definition"></a></dt>
<dd><p>Parse a boosted tree model text dump into a pandas DataFrame structure.</p>
<p>This feature is only defined when the decision tree model is chosen as base
learner (<cite>booster in {gbtree, dart}</cite>). It is not defined for other base learner
types, such as linear learners (<cite>booster=gblinear</cite>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fmap</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em> (</em><em>optional</em><em>)</em>) – The name of feature map file.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.core.frame.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtrain</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fobj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.update" title="Permalink to this definition"></a></dt>
<dd><p>Update for one iteration, with objective function calculated
internally.  This function should not be called directly by users.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dtrain</strong> (<a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><em>DMatrix</em></a>) – Training data.</p></li>
<li><p><strong>iteration</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Current iteration number.</p></li>
<li><p><strong>fobj</strong> (<em>function</em>) – Customized objective function.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-xgboost.training">
<span id="learning-api"></span><h2>Learning API<a class="headerlink" href="#module-xgboost.training" title="Permalink to this headline"></a></h2>
<p>Training Library containing training routines.</p>
<dl class="py function">
<dt class="sig sig-object py" id="xgboost.train">
<span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtrain</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_boost_round</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_result</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.train" title="Permalink to this definition"></a></dt>
<dd><p>Train a booster with given parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Booster params.</p></li>
<li><p><strong>dtrain</strong> (<a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a>) – Data to be trained.</p></li>
<li><p><strong>num_boost_round</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of boosting iterations.</p></li>
<li><p><strong>evals</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em>) – List of validation sets for which metrics will evaluated during training.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>obj</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>]</em>) – Custom objective function.  See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective</span></a> for details.</p></li>
<li><p><strong>feval</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>custom_metric</cite> instead.</p>
</div>
<p></p></li>
<li><p><strong>maximize</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to maximize feval.</p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.
Requires at least one item in <strong>evals</strong>.
The method returns the model from the last iteration (not the best one).  Use
custom callback or model slicing if the best model is desired.
If there’s more than one item in <strong>evals</strong>, the last entry will be used for early
stopping.
If there’s more than one metric in the <strong>eval_metric</strong> parameter given in
<strong>params</strong>, the last metric will be used for early stopping.
If early stopping occurs, the model will have two additional fields:
<code class="docutils literal notranslate"><span class="pre">bst.best_score</span></code>, <code class="docutils literal notranslate"><span class="pre">bst.best_iteration</span></code>.</p></li>
<li><p><strong>evals_result</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p><p>This dictionary stores the evaluation results of all the items in watchlist.</p>
<p>Example: with a watchlist containing
<code class="docutils literal notranslate"><span class="pre">[(dtest,'eval'),</span> <span class="pre">(dtrain,'train')]</span></code> and
a parameter containing <code class="docutils literal notranslate"><span class="pre">('eval_metric':</span> <span class="pre">'logloss')</span></code>,
the <strong>evals_result</strong> returns</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'train'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.48253'</span><span class="p">,</span> <span class="s1">'0.35953'</span><span class="p">]},</span>
 <span class="s1">'eval'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.480385'</span><span class="p">,</span> <span class="s1">'0.357756'</span><span class="p">]}}</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>verbose_eval</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – Requires at least one item in <strong>evals</strong>.
If <strong>verbose_eval</strong> is True then the evaluation metric on the validation set is
printed at each boosting stage.
If <strong>verbose_eval</strong> is an integer then the evaluation metric on the validation set
is printed at every given <strong>verbose_eval</strong> boosting stage. The last boosting stage
/ the boosting stage found by using <strong>early_stopping_rounds</strong> is also printed.
Example: with <code class="docutils literal notranslate"><span class="pre">verbose_eval=4</span></code> and at least one item in <strong>evals</strong>, an evaluation metric
is printed every 4 boosting stages, instead of every boosting stage.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>, </em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>]</em><em>]</em>) – Xgb model to be loaded before training (allows training continuation).</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>custom_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em>) – </p><p>Custom metric function.  See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Metric</span></a>
for details.</p>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Booster</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>a trained booster model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="xgboost.cv">
<span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">cv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtrain</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_boost_round</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nfold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stratified</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">folds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fpreproc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_pandas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_stdv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.cv" title="Permalink to this definition"></a></dt>
<dd><p>Cross-validation with given parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a>) – Booster params.</p></li>
<li><p><strong>dtrain</strong> (<a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><em>DMatrix</em></a>) – Data to be trained.</p></li>
<li><p><strong>num_boost_round</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of boosting iterations.</p></li>
<li><p><strong>nfold</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of folds in CV.</p></li>
<li><p><strong>stratified</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Perform stratified sampling.</p></li>
<li><p><strong>folds</strong> (<em>a KFold</em><em> or </em><em>StratifiedKFold instance</em><em> or </em><em>list of fold indices</em>) – Sklearn KFolds or StratifiedKFolds object.
Alternatively may explicitly pass sample indices for each fold.
For <code class="docutils literal notranslate"><span class="pre">n</span></code> folds, <strong>folds</strong> should be a length <code class="docutils literal notranslate"><span class="pre">n</span></code> list of tuples.
Each tuple is <code class="docutils literal notranslate"><span class="pre">(in,out)</span></code> where <code class="docutils literal notranslate"><span class="pre">in</span></code> is a list of indices to be used
as the training samples for the <code class="docutils literal notranslate"><span class="pre">n</span></code> th fold and <code class="docutils literal notranslate"><span class="pre">out</span></code> is a list of
indices to be used as the testing samples for the <code class="docutils literal notranslate"><span class="pre">n</span></code> th fold.</p></li>
<li><p><strong>metrics</strong> (<em>string</em><em> or </em><em>list of strings</em>) – Evaluation metrics to be watched in CV.</p></li>
<li><p><strong>obj</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>]</em>) – Custom objective function.  See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective</span></a> for details.</p></li>
<li><p><strong>feval</strong> (<em>function</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>custom_metric</cite> instead.</p>
</div>
<p></p></li>
<li><p><strong>maximize</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to maximize feval.</p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Activates early stopping. Cross-Validation metric (average of validation
metric computed over CV folds) needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.
The last entry in the evaluation history will represent the best iteration.
If there’s more than one metric in the <strong>eval_metric</strong> parameter given in
<strong>params</strong>, the last metric will be used for early stopping.</p></li>
<li><p><strong>fpreproc</strong> (<em>function</em>) – Preprocessing function that takes (dtrain, dtest, param) and returns
transformed versions of those.</p></li>
<li><p><strong>as_pandas</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>default True</em>) – Return pd.DataFrame when pandas is installed.
If False or pandas is not installed, return np.ndarray</p></li>
<li><p><strong>verbose_eval</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, or </em><em>None</em><em>, </em><em>default None</em>) – Whether to display the progress. If None, progress will be displayed
when np.ndarray is returned. If True, progress will be displayed at
boosting stage. If an integer is given, progress will be displayed
at every given <cite>verbose_eval</cite> boosting stage.</p></li>
<li><p><strong>show_stdv</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>default True</em>) – Whether to display the standard deviation in progress.
Results are not affected, and always contains std.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Seed used to generate the folds (passed to numpy.random.seed).</p></li>
<li><p><strong>callbacks</strong> – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>shuffle</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Shuffle data before creating folds.</p></li>
<li><p><strong>custom_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em>) – </p><p>Custom metric function.  See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Metric</span></a>
for details.</p>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>evaluation history</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#list" title="(in Python v3.6)">list</a>(string)</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-xgboost.sklearn">
<span id="scikit-learn-api"></span><h2>Scikit-Learn API<a class="headerlink" href="#module-xgboost.sklearn" title="Permalink to this headline"></a></h2>
<p>Scikit-Learn Wrapper interface for XGBoost.</p>
<dl class="py class">
<dt class="sig sig-object py" id="xgboost.XGBRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">XGBRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'reg:squarederror'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.sklearn.XGBModel</span></code>, <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html#sklearn.base.RegressorMixin" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.RegressorMixin</span></code></a></p>
<p>Implementation of the scikit-learn API for XGBoost regression.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of gradient boosted trees.  Equivalent to number of boosting
rounds.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.XGBRegressor.fit" title="xgboost.XGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.XGBRegressor.fit" title="xgboost.XGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.XGBRegressor.best_score" title="xgboost.XGBRegressor.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.XGBRegressor.best_iteration" title="xgboost.XGBRegressor.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.XGBRegressor.fit" title="xgboost.XGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Custom objective function</p>
<p>A custom objective function can be provided for the <code class="docutils literal notranslate"><span class="pre">objective</span></code>
parameter. In this case, it should have the signature
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code>:</p>
<dl class="simple">
<dt>y_true: array_like of shape [n_samples]</dt><dd><p>The target values</p>
</dd>
<dt>y_pred: array_like of shape [n_samples]</dt><dd><p>The predicted values</p>
</dd>
<dt>grad: array_like of shape [n_samples]</dt><dd><p>The value of the gradient for each sample point.</p>
</dd>
<dt>hess: array_like of shape [n_samples]</dt><dd><p>The value of the second derivative for each sample point</p>
</dd>
</dl>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.XGBRegressor.predict" title="xgboost.XGBRegressor.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBRegressor.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.XGBRegressor.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRegressor.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.XGBRegressor.fit" title="xgboost.XGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.XGBRegressor.fit" title="xgboost.XGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.XGBRegressor.fit" title="xgboost.XGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRegressor.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRegressor.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.XGBRegressor.fit" title="xgboost.XGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting model.</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Labels</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – instance weights</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, or </em><em>callable</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBRegressor.set_params" title="xgboost.XGBRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.XGBRegressor.set_params" title="xgboost.XGBRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [L_1, L_2, …, L_n], where each L_i is an array like
object storing instance weights for the i-th validation set.</p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBRegressor.set_params" title="xgboost.XGBRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>xgboost.sklearn.XGBModel</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRegressor.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBRegressor.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.XGBRegressor.fit" title="xgboost.XGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.score" title="Permalink to this definition"></a></dt>
<dd><p>Return the coefficient of determination of the prediction.</p>
<p>The coefficient of determination <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="0"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> is defined as
<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="1"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mfrac><mi>u</mi><mi>v</mi></mfrac><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></span>, where <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="2"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>u</mi></math></mjx-assistive-mml></mjx-container></span> is the residual
sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_pred)**</span> <span class="pre">2).sum()</span></code> and <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="3"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>v</mi></math></mjx-assistive-mml></mjx-container></span>
is the total sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_true.mean())</span> <span class="pre">**</span> <span class="pre">2).sum()</span></code>.
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always predicts
the expected value of <cite>y</cite>, disregarding the input features, would get
a <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="4"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> score of 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test samples. For some estimators this may be a precomputed
kernel matrix or a list of generic objects instead with shape
<code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_samples_fitted)</span></code>, where <code class="docutils literal notranslate"><span class="pre">n_samples_fitted</span></code>
is the number of samples used in the fitting for the estimator.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – True values for <cite>X</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> – <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="5"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <cite>y</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="6"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> score used when calling <code class="docutils literal notranslate"><span class="pre">score</span></code> on a regressor uses
<code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code> from version 0.23 to keep consistent
with default value of <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score()</span></code></a>.
This influences the <code class="docutils literal notranslate"><span class="pre">score</span></code> method of all the multioutput
regressors (except for
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRegressor</span></code></a>).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.XGBClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">XGBClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'binary:logistic'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_label_encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.sklearn.XGBModel</span></code>, <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.ClassifierMixin.html#sklearn.base.ClassifierMixin" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.ClassifierMixin</span></code></a></p>
<p>Implementation of the scikit-learn API for XGBoost classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of boosting rounds.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.XGBClassifier.fit" title="xgboost.XGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.XGBClassifier.fit" title="xgboost.XGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.XGBClassifier.best_score" title="xgboost.XGBClassifier.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.XGBClassifier.best_iteration" title="xgboost.XGBClassifier.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.XGBClassifier.fit" title="xgboost.XGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Custom objective function</p>
<p>A custom objective function can be provided for the <code class="docutils literal notranslate"><span class="pre">objective</span></code>
parameter. In this case, it should have the signature
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code>:</p>
<dl class="simple">
<dt>y_true: array_like of shape [n_samples]</dt><dd><p>The target values</p>
</dd>
<dt>y_pred: array_like of shape [n_samples]</dt><dd><p>The predicted values</p>
</dd>
<dt>grad: array_like of shape [n_samples]</dt><dd><p>The value of the gradient for each sample point.</p>
</dd>
<dt>hess: array_like of shape [n_samples]</dt><dd><p>The value of the second derivative for each sample point</p>
</dd>
</dl>
</div>
<p></p></li>
<li><p><strong>use_label_encoder</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.XGBClassifier.predict" title="xgboost.XGBClassifier.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBClassifier.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.XGBClassifier.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBClassifier.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.XGBClassifier.fit" title="xgboost.XGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.XGBClassifier.fit" title="xgboost.XGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.XGBClassifier.fit" title="xgboost.XGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBClassifier.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBClassifier.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.XGBClassifier.fit" title="xgboost.XGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting classifier.</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Labels</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – instance weights</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, or </em><em>callable</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBClassifier.set_params" title="xgboost.XGBClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.XGBClassifier.set_params" title="xgboost.XGBClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [L_1, L_2, …, L_n], where each L_i is an array like
object storing instance weights for the i-th validation set.</p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBClassifier.set_params" title="xgboost.XGBClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.XGBClassifier" title="xgboost.sklearn.XGBClassifier">xgboost.sklearn.XGBClassifier</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBClassifier.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBClassifier.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.XGBClassifier.fit" title="xgboost.XGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.predict_proba" title="Permalink to this definition"></a></dt>
<dd><p>Predict the probability of each <cite>X</cite> example being of a given class.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em>) – Feature matrix.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<em>array_like</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <cite>iteration_range=(10,
20)</cite>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a numpy array of shape array-like of shape (n_samples, n_classes) with the
probability of each data example being of a given class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.score" title="Permalink to this definition"></a></dt>
<dd><p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test samples.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – True labels for <cite>X</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> – Mean accuracy of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <cite>y</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.XGBRanker">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">XGBRanker</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'rank:pairwise'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.sklearn.XGBModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.sklearn.XGBRankerMixIn</span></code></p>
<p>Implementation of the Scikit-Learn API for XGBoost Ranking.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of gradient boosted trees.  Equivalent to number of boosting
rounds.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.XGBRanker.fit" title="xgboost.XGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.XGBRanker.fit" title="xgboost.XGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.XGBRanker.best_score" title="xgboost.XGBRanker.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.XGBRanker.best_iteration" title="xgboost.XGBRanker.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.XGBRanker.fit" title="xgboost.XGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A custom objective function is currently not supported by XGBRanker.
Likewise, a custom metric function is not supported either.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Query group information is required for ranking tasks by either using the
<cite>group</cite> parameter or <cite>qid</cite> parameter in <cite>fit</cite> method.</p>
</div>
<p>Before fitting the model, your data need to be sorted by query group. When fitting
the model, you need to provide an additional array that contains the size of each
query group.</p>
<p>For example, if your original data look like:</p>
<div class="wy-table-responsive"><table class="docutils align-default">
<colgroup>
<col style="width: 21%">
<col style="width: 33%">
<col style="width: 45%">
</colgroup>
<tbody>
<tr class="row-odd"><td><p>qid</p></td>
<td><p>label</p></td>
<td><p>features</p></td>
</tr>
<tr class="row-even"><td><p>1</p></td>
<td><p>0</p></td>
<td><p>x_1</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>1</p></td>
<td><p>x_2</p></td>
</tr>
<tr class="row-even"><td><p>1</p></td>
<td><p>0</p></td>
<td><p>x_3</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>0</p></td>
<td><p>x_4</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>1</p></td>
<td><p>x_5</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>1</p></td>
<td><p>x_6</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>1</p></td>
<td><p>x_7</p></td>
</tr>
</tbody>
</table></div>
<p>then your group array should be <code class="docutils literal notranslate"><span class="pre">[3,</span> <span class="pre">4]</span></code>.  Sometimes using query id (<cite>qid</cite>)
instead of group can be more convenient.</p>
<p></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.XGBRanker.predict" title="xgboost.XGBRanker.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRanker.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBRanker.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRanker.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.XGBRanker.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRanker.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRanker.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.XGBRanker.fit" title="xgboost.XGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.XGBRanker.fit" title="xgboost.XGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.XGBRanker.fit" title="xgboost.XGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRanker.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRanker.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRanker.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRanker.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.XGBRanker.fit" title="xgboost.XGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting ranker</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Labels</p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Size of each query group of training data. Should have as many elements as the
query groups in the training data.  If this is set to None, then user must
provide qid.</p></li>
<li><p><strong>qid</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Query ID for each training sample.  Should have the size of n_samples.  If
this is set to None, then user must provide group.</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p><p>Query group weights</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Weights are per-group for ranking tasks</p>
<p>In ranking task, one weight is assigned to each query group/id (not each
data point). This is because we only care about the relative ordering of
data points within each group, so it doesn’t make sense to assign weights
to individual data points.</p>
</div>
<p></p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list in which <code class="docutils literal notranslate"><span class="pre">eval_group[i]</span></code> is the list containing the sizes of all
query groups in the <code class="docutils literal notranslate"><span class="pre">i</span></code>-th pair in <strong>eval_set</strong>.</p></li>
<li><p><strong>eval_qid</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list in which <code class="docutils literal notranslate"><span class="pre">eval_qid[i]</span></code> is the array containing query ID of <code class="docutils literal notranslate"><span class="pre">i</span></code>-th
pair in <strong>eval_set</strong>.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBRanker.set_params" title="xgboost.XGBRanker.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.XGBRanker.set_params" title="xgboost.XGBRanker.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – </p><p>A list of the form [L_1, L_2, …, L_n], where each L_i is a list of
group weights on the i-th validation set.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Weights are per-group for ranking tasks</p>
<p>In ranking task, one weight is assigned to each query group (not each
data point). This is because we only care about the relative ordering of
data points within each group, so it doesn’t make sense to assign
weights to individual data points.</p>
</div>
<p></p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBRanker.set_params" title="xgboost.XGBRanker.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.XGBRanker" title="xgboost.sklearn.XGBRanker">xgboost.sklearn.XGBRanker</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRanker.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRanker.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRanker.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBRanker.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.XGBRanker.fit" title="xgboost.XGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">XGBRFRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bynode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.XGBRegressor" title="xgboost.sklearn.XGBRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.sklearn.XGBRegressor</span></code></a></p>
<p>scikit-learn API for XGBoost random forest regression.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of trees in random forest to fit.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.XGBRFRegressor.fit" title="xgboost.XGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.XGBRFRegressor.fit" title="xgboost.XGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.XGBRFRegressor.best_score" title="xgboost.XGBRFRegressor.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.XGBRFRegressor.best_iteration" title="xgboost.XGBRFRegressor.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.XGBRFRegressor.fit" title="xgboost.XGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Custom objective function</p>
<p>A custom objective function can be provided for the <code class="docutils literal notranslate"><span class="pre">objective</span></code>
parameter. In this case, it should have the signature
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code>:</p>
<dl class="simple">
<dt>y_true: array_like of shape [n_samples]</dt><dd><p>The target values</p>
</dd>
<dt>y_pred: array_like of shape [n_samples]</dt><dd><p>The predicted values</p>
</dd>
<dt>grad: array_like of shape [n_samples]</dt><dd><p>The value of the gradient for each sample point.</p>
</dd>
<dt>hess: array_like of shape [n_samples]</dt><dd><p>The value of the second derivative for each sample point</p>
</dd>
</dl>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.XGBRFRegressor.predict" title="xgboost.XGBRFRegressor.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBRFRegressor.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.XGBRFRegressor.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRFRegressor.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.XGBRFRegressor.fit" title="xgboost.XGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.XGBRFRegressor.fit" title="xgboost.XGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.XGBRFRegressor.fit" title="xgboost.XGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRFRegressor.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRFRegressor.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.XGBRFRegressor.fit" title="xgboost.XGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting model.</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Labels</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – instance weights</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, or </em><em>callable</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBRFRegressor.set_params" title="xgboost.XGBRFRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.XGBRFRegressor.set_params" title="xgboost.XGBRFRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [L_1, L_2, …, L_n], where each L_i is an array like
object storing instance weights for the i-th validation set.</p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBRFRegressor.set_params" title="xgboost.XGBRFRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.XGBRFRegressor" title="xgboost.sklearn.XGBRFRegressor">xgboost.sklearn.XGBRFRegressor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRFRegressor.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBRFRegressor.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.XGBRFRegressor.fit" title="xgboost.XGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.score" title="Permalink to this definition"></a></dt>
<dd><p>Return the coefficient of determination of the prediction.</p>
<p>The coefficient of determination <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="7"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> is defined as
<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="8"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mfrac><mi>u</mi><mi>v</mi></mfrac><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></span>, where <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="9"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>u</mi></math></mjx-assistive-mml></mjx-container></span> is the residual
sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_pred)**</span> <span class="pre">2).sum()</span></code> and <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="10"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>v</mi></math></mjx-assistive-mml></mjx-container></span>
is the total sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_true.mean())</span> <span class="pre">**</span> <span class="pre">2).sum()</span></code>.
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always predicts
the expected value of <cite>y</cite>, disregarding the input features, would get
a <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="11"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> score of 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test samples. For some estimators this may be a precomputed
kernel matrix or a list of generic objects instead with shape
<code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_samples_fitted)</span></code>, where <code class="docutils literal notranslate"><span class="pre">n_samples_fitted</span></code>
is the number of samples used in the fitting for the estimator.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – True values for <cite>X</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> – <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="12"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <cite>y</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="13"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> score used when calling <code class="docutils literal notranslate"><span class="pre">score</span></code> on a regressor uses
<code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code> from version 0.23 to keep consistent
with default value of <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score()</span></code></a>.
This influences the <code class="docutils literal notranslate"><span class="pre">score</span></code> method of all the multioutput
regressors (except for
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRegressor</span></code></a>).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">XGBRFClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bynode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.XGBClassifier" title="xgboost.sklearn.XGBClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.sklearn.XGBClassifier</span></code></a></p>
<p>scikit-learn API for XGBoost random forest classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of trees in random forest to fit.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.XGBRFClassifier.fit" title="xgboost.XGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.XGBRFClassifier.fit" title="xgboost.XGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.XGBRFClassifier.best_score" title="xgboost.XGBRFClassifier.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.XGBRFClassifier.best_iteration" title="xgboost.XGBRFClassifier.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.XGBRFClassifier.fit" title="xgboost.XGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Custom objective function</p>
<p>A custom objective function can be provided for the <code class="docutils literal notranslate"><span class="pre">objective</span></code>
parameter. In this case, it should have the signature
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code>:</p>
<dl class="simple">
<dt>y_true: array_like of shape [n_samples]</dt><dd><p>The target values</p>
</dd>
<dt>y_pred: array_like of shape [n_samples]</dt><dd><p>The predicted values</p>
</dd>
<dt>grad: array_like of shape [n_samples]</dt><dd><p>The value of the gradient for each sample point.</p>
</dd>
<dt>hess: array_like of shape [n_samples]</dt><dd><p>The value of the second derivative for each sample point</p>
</dd>
</dl>
</div>
<p></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.XGBRFClassifier.predict" title="xgboost.XGBRFClassifier.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBRFClassifier.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.XGBRFClassifier.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRFClassifier.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.XGBRFClassifier.fit" title="xgboost.XGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.XGBRFClassifier.fit" title="xgboost.XGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.XGBRFClassifier.fit" title="xgboost.XGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRFClassifier.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRFClassifier.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.XGBRFClassifier.fit" title="xgboost.XGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting classifier.</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Labels</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – instance weights</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, or </em><em>callable</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBRFClassifier.set_params" title="xgboost.XGBRFClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.XGBRFClassifier.set_params" title="xgboost.XGBRFClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [L_1, L_2, …, L_n], where each L_i is an array like
object storing instance weights for the i-th validation set.</p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBRFClassifier.set_params" title="xgboost.XGBRFClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.XGBRFClassifier" title="xgboost.sklearn.XGBRFClassifier">xgboost.sklearn.XGBRFClassifier</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRFClassifier.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBRFClassifier.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.XGBRFClassifier.fit" title="xgboost.XGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.predict_proba" title="Permalink to this definition"></a></dt>
<dd><p>Predict the probability of each <cite>X</cite> example being of a given class.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em>) – Feature matrix.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<em>array_like</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <cite>iteration_range=(10,
20)</cite>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a numpy array of shape array-like of shape (n_samples, n_classes) with the
probability of each data example being of a given class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.score" title="Permalink to this definition"></a></dt>
<dd><p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test samples.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – True labels for <cite>X</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> – Mean accuracy of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <cite>y</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-xgboost.plotting">
<span id="plotting-api"></span><h2>Plotting API<a class="headerlink" href="#module-xgboost.plotting" title="Permalink to this headline"></a></h2>
<p>Plotting Library.</p>
<dl class="py function">
<dt class="sig sig-object py" id="xgboost.plot_importance">
<span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">plot_importance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">booster</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">height</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xlim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Feature</span> <span class="pre">importance'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xlabel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'F</span> <span class="pre">score'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylabel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Features'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">importance_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'weight'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.plot_importance" title="Permalink to this definition"></a></dt>
<dd><p>Plot importance based on fitted trees.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>booster</strong> (<a class="reference internal" href="#xgboost.Booster" title="xgboost.Booster"><em>Booster</em></a><em>, </em><em>XGBModel</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a>) – Booster or XGBModel instance, or dict taken by Booster.get_fscore()</p></li>
<li><p><strong>ax</strong> (<em>matplotlib Axes</em><em>, </em><em>default None</em>) – Target axes instance. If None, new figure and axes will be created.</p></li>
<li><p><strong>grid</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>Turn the axes grids on</em><em> or </em><em>off.  Default is True</em><em> (</em><em>On</em><em>)</em><em>.</em>) – </p></li>
<li><p><strong>importance_type</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>default "weight"</em>) – </p><p>How the importance is calculated: either “weight”, “gain”, or “cover”</p>
<ul>
<li><p>”weight” is the number of times a feature appears in a tree</p></li>
<li><p>”gain” is the average gain of splits which use the feature</p></li>
<li><p>”cover” is the average coverage of splits which use the feature
where coverage is defined as the number of samples affected by the split</p></li>
</ul>
<p></p></li>
<li><p><strong>max_num_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><em>default None</em>) – Maximum number of top features displayed on plot. If None, all features will be displayed.</p></li>
<li><p><strong>height</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default 0.2</em>) – Bar height, passed to ax.barh()</p></li>
<li><p><strong>xlim</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a><em>, </em><em>default None</em>) – Tuple passed to axes.xlim()</p></li>
<li><p><strong>ylim</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a><em>, </em><em>default None</em>) – Tuple passed to axes.ylim()</p></li>
<li><p><strong>title</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>default "Feature importance"</em>) – Axes title. To disable, pass None.</p></li>
<li><p><strong>xlabel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>default "F score"</em>) – X axis title label. To disable, pass None.</p></li>
<li><p><strong>ylabel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>default "Features"</em>) – Y axis title label. To disable, pass None.</p></li>
<li><p><strong>fmap</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em> (</em><em>optional</em><em>)</em>) – The name of feature map file.</p></li>
<li><p><strong>show_values</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>default True</em>) – Show values on plot. To disable, pass False.</p></li>
<li><p><strong>kwargs</strong> – Other keywords passed to ax.barh()</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ax</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>matplotlib Axes</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="xgboost.plot_tree">
<span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">plot_tree</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">booster</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_trees</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rankdir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.plot_tree" title="Permalink to this definition"></a></dt>
<dd><p>Plot specified tree.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>booster</strong> (<a class="reference internal" href="#xgboost.Booster" title="xgboost.Booster"><em>Booster</em></a><em>, </em><em>XGBModel</em>) – Booster or XGBModel instance</p></li>
<li><p><strong>fmap</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em> (</em><em>optional</em><em>)</em>) – The name of feature map file</p></li>
<li><p><strong>num_trees</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><em>default 0</em>) – Specify the ordinal number of target tree</p></li>
<li><p><strong>rankdir</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>default "TB"</em>) – Passed to graphiz via graph_attr</p></li>
<li><p><strong>ax</strong> (<em>matplotlib Axes</em><em>, </em><em>default None</em>) – Target axes instance. If None, new figure and axes will be created.</p></li>
<li><p><strong>kwargs</strong> – Other keywords passed to to_graphviz</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ax</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>matplotlib Axes</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="xgboost.to_graphviz">
<span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">to_graphviz</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">booster</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_trees</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rankdir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">yes_color</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">no_color</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition_node_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaf_node_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.to_graphviz" title="Permalink to this definition"></a></dt>
<dd><p>Convert specified tree to graphviz instance. IPython can automatically plot
the returned graphiz instance. Otherwise, you should call .render() method
of the returned graphiz instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>booster</strong> (<a class="reference internal" href="#xgboost.Booster" title="xgboost.Booster"><em>Booster</em></a><em>, </em><em>XGBModel</em>) – Booster or XGBModel instance</p></li>
<li><p><strong>fmap</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em> (</em><em>optional</em><em>)</em>) – The name of feature map file</p></li>
<li><p><strong>num_trees</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><em>default 0</em>) – Specify the ordinal number of target tree</p></li>
<li><p><strong>rankdir</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>default "UT"</em>) – Passed to graphiz via graph_attr</p></li>
<li><p><strong>yes_color</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>default '#0000FF'</em>) – Edge color when meets the node condition.</p></li>
<li><p><strong>no_color</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>default '#FF0000'</em>) – Edge color when doesn’t meet the node condition.</p></li>
<li><p><strong>condition_node_params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Condition node configuration for for graphviz.  Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'shape'</span><span class="p">:</span> <span class="s1">'box'</span><span class="p">,</span>
 <span class="s1">'style'</span><span class="p">:</span> <span class="s1">'filled,rounded'</span><span class="p">,</span>
 <span class="s1">'fillcolor'</span><span class="p">:</span> <span class="s1">'#78bceb'</span><span class="p">}</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>leaf_node_params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Leaf node configuration for graphviz. Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'shape'</span><span class="p">:</span> <span class="s1">'box'</span><span class="p">,</span>
 <span class="s1">'style'</span><span class="p">:</span> <span class="s1">'filled'</span><span class="p">,</span>
 <span class="s1">'fillcolor'</span><span class="p">:</span> <span class="s1">'#e48038'</span><span class="p">}</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – Other keywords passed to graphviz graph_attr, e.g. <code class="docutils literal notranslate"><span class="pre">graph</span> <span class="pre">[</span> <span class="pre">{key}</span> <span class="pre">=</span> <span class="pre">{value}</span> <span class="pre">]</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>graph</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>graphviz.Source</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-xgboost.callback">
<span id="id1"></span><span id="callback-api"></span><h2>Callback API<a class="headerlink" href="#module-xgboost.callback" title="Permalink to this headline"></a></h2>
<p>Callback library containing training routines.  See <a class="reference internal" href="callbacks.html"><span class="doc">Callback Functions</span></a> for a quick introduction.</p>
<dl class="py class">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCallback">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.callback.</span></span><span class="sig-name descname"><span class="pre">TrainingCallback</span></span><a class="headerlink" href="#xgboost.callback.TrainingCallback" title="Permalink to this definition"></a></dt>
<dd><p>Interface for training callback.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCallback.after_iteration">
<span class="sig-name descname"><span class="pre">after_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCallback.after_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run after each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCallback.after_training">
<span class="sig-name descname"><span class="pre">after_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCallback.after_training" title="Permalink to this definition"></a></dt>
<dd><p>Run after training is finished.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCallback.before_iteration">
<span class="sig-name descname"><span class="pre">before_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCallback.before_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run before each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCallback.before_training">
<span class="sig-name descname"><span class="pre">before_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCallback.before_training" title="Permalink to this definition"></a></dt>
<dd><p>Run before training starts.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.callback.EvaluationMonitor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.callback.</span></span><span class="sig-name descname"><span class="pre">EvaluationMonitor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">period</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_stdv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EvaluationMonitor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.callback.TrainingCallback</span></code></a></p>
<p>Print the evaluation result at each iteration.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metric</strong> – Extra user defined metric.</p></li>
<li><p><strong>rank</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Which worker should be used for printing the result.</p></li>
<li><p><strong>period</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – How many epoches between printing.</p></li>
<li><p><strong>show_stdv</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Used in cv to show standard deviation.  Users should not specify it.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.EvaluationMonitor.after_iteration">
<span class="sig-name descname"><span class="pre">after_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EvaluationMonitor.after_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run after each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.EvaluationMonitor.after_training">
<span class="sig-name descname"><span class="pre">after_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EvaluationMonitor.after_training" title="Permalink to this definition"></a></dt>
<dd><p>Run after training is finished.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.EvaluationMonitor.before_iteration">
<span class="sig-name descname"><span class="pre">before_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EvaluationMonitor.before_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run before each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.EvaluationMonitor.before_training">
<span class="sig-name descname"><span class="pre">before_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EvaluationMonitor.before_training" title="Permalink to this definition"></a></dt>
<dd><p>Run before training starts.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.callback.EarlyStopping">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.callback.</span></span><span class="sig-name descname"><span class="pre">EarlyStopping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_best</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_delta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EarlyStopping" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.callback.TrainingCallback</span></code></a></p>
<p>Callback function for early stopping</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Early stopping rounds.</p></li>
<li><p><strong>metric_name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Name of metric that is used for early stopping.</p></li>
<li><p><strong>data_name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Name of dataset that is used for early stopping.</p></li>
<li><p><strong>maximize</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Whether to maximize evaluation metric.  None means auto (discouraged).</p></li>
<li><p><strong>save_best</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Whether training should return the best model or the last model.</p></li>
<li><p><strong>min_delta</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – </p><p>Minimum absolute change in score to be qualified as an improvement.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">xgboost</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">tree_method</span><span class="o">=</span><span class="s2">"gpu_hist"</span><span class="p">)</span>
<span class="n">es</span> <span class="o">=</span> <span class="n">xgboost</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span>
    <span class="n">rounds</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">abs_tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">save_best</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">maximize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">data_name</span><span class="o">=</span><span class="s2">"validation_0"</span><span class="p">,</span>
    <span class="n">metric_name</span><span class="o">=</span><span class="s2">"mlogloss"</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)],</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">es</span><span class="p">])</span>
</pre></div>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.EarlyStopping.after_iteration">
<span class="sig-name descname"><span class="pre">after_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EarlyStopping.after_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run after each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.EarlyStopping.after_training">
<span class="sig-name descname"><span class="pre">after_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EarlyStopping.after_training" title="Permalink to this definition"></a></dt>
<dd><p>Run after training is finished.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.EarlyStopping.before_iteration">
<span class="sig-name descname"><span class="pre">before_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EarlyStopping.before_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run before each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.EarlyStopping.before_training">
<span class="sig-name descname"><span class="pre">before_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EarlyStopping.before_training" title="Permalink to this definition"></a></dt>
<dd><p>Run before training starts.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.callback.LearningRateScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.callback.</span></span><span class="sig-name descname"><span class="pre">LearningRateScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">learning_rates</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.LearningRateScheduler" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.callback.TrainingCallback</span></code></a></p>
<p>Callback function for scheduling learning rate.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>learning_rates</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em>) – If it’s a callable object, then it should accept an integer parameter
<cite>epoch</cite> and returns the corresponding learning rate.  Otherwise it
should be a sequence like list or tuple with the same size of boosting
rounds.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.LearningRateScheduler.after_iteration">
<span class="sig-name descname"><span class="pre">after_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.LearningRateScheduler.after_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run after each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.LearningRateScheduler.after_training">
<span class="sig-name descname"><span class="pre">after_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.LearningRateScheduler.after_training" title="Permalink to this definition"></a></dt>
<dd><p>Run after training is finished.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.LearningRateScheduler.before_iteration">
<span class="sig-name descname"><span class="pre">before_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.LearningRateScheduler.before_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run before each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.LearningRateScheduler.before_training">
<span class="sig-name descname"><span class="pre">before_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.LearningRateScheduler.before_training" title="Permalink to this definition"></a></dt>
<dd><p>Run before training starts.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCheckPoint">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.callback.</span></span><span class="sig-name descname"><span class="pre">TrainingCheckPoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">directory</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'model'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_pickle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCheckPoint" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.callback.TrainingCallback</span></code></a></p>
<p>Checkpointing operation.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>directory</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Output model directory.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – pattern of output model file.  Models will be saved as name_0.json, name_1.json,
name_2.json ….</p></li>
<li><p><strong>as_pickle</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to True, all training parameters will be saved in pickle format, instead
of saving only the model.</p></li>
<li><p><strong>iterations</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Interval of checkpointing.  Checkpointing is slow so setting a larger number can
reduce performance hit.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCheckPoint.after_iteration">
<span class="sig-name descname"><span class="pre">after_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCheckPoint.after_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run after each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCheckPoint.after_training">
<span class="sig-name descname"><span class="pre">after_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCheckPoint.after_training" title="Permalink to this definition"></a></dt>
<dd><p>Run after training is finished.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCheckPoint.before_iteration">
<span class="sig-name descname"><span class="pre">before_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCheckPoint.before_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run before each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCheckPoint.before_training">
<span class="sig-name descname"><span class="pre">before_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCheckPoint.before_training" title="Permalink to this definition"></a></dt>
<dd><p>Run before training starts.</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-xgboost.dask">
<span id="id2"></span><span id="dask-api"></span><h2>Dask API<a class="headerlink" href="#module-xgboost.dask" title="Permalink to this headline"></a></h2>
<section id="dask-extensions-for-distributed-training">
<h3>Dask extensions for distributed training<a class="headerlink" href="#dask-extensions-for-distributed-training" title="Permalink to this headline"></a></h3>
<p>See <a class="reference internal" href="../tutorials/dask.html"><span class="doc">Distributed XGBoost with Dask</span></a> for simple tutorial.  Also
<a class="reference internal" href="dask-examples/index.html"><span class="doc">XGBoost Dask Feature Walkthrough</span></a> for some examples.</p>
<p>There are two sets of APIs in this module, one is the functional API including
<code class="docutils literal notranslate"><span class="pre">train</span></code> and <code class="docutils literal notranslate"><span class="pre">predict</span></code> methods.  Another is stateful Scikit-Learner wrapper
inherited from single-node Scikit-Learn interface.</p>
<p>The implementation is heavily influenced by dask_xgboost:
<a class="reference external" href="https://github.com/dask/dask-xgboost">https://github.com/dask/dask-xgboost</a></p>
<section id="optional-dask-configuration">
<h4>Optional dask configuration<a class="headerlink" href="#optional-dask-configuration" title="Permalink to this headline"></a></h4>
<ul>
<li><p><strong>xgboost.scheduler_address</strong>: Specify the scheduler address, see <a class="reference internal" href="../tutorials/dask.html#tracker-ip"><span class="std std-ref">Troubleshooting</span></a>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set</span><span class="p">({</span><span class="s2">"xgboost.scheduler_address"</span><span class="p">:</span> <span class="s2">"192.0.0.100"</span><span class="p">})</span>
<span class="c1"># We can also specify the port.</span>
<span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set</span><span class="p">({</span><span class="s2">"xgboost.scheduler_address"</span><span class="p">:</span> <span class="s2">"192.0.0.100:12345"</span><span class="p">})</span>
</pre></div>
</div>
</li>
</ul>
</section>
</section>
<dl class="py class">
<dt class="sig sig-object py" id="xgboost.dask.DaskDMatrix">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">DaskDMatrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">client</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_lower_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_upper_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskDMatrix" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>DMatrix holding on references to Dask DataFrame or Dask Array.  Constructing a
<cite>DaskDMatrix</cite> forces all lazy computation to be carried out.  Wait for the input data
explicitly if you want to see actual computation of constructing <cite>DaskDMatrix</cite>.</p>
<p>See doc for <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.DMatrix</span></code></a> constructor for other parameters.  DaskDMatrix
accepts only dask collection.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>DaskDMatrix does not repartition or move data between workers.  It’s
the caller’s responsibility to balance the data.</p>
</div>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><em>distributed.Client</em></a>) – Specify the dask client used for training.  Use default client returned from dask
if it’s set to None.</p></li>
<li><p><strong>data</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – </p></li>
<li><p><strong>label</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – </p></li>
<li><p><strong>silent</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
<li><p><strong>feature_names</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – </p></li>
<li><p><strong>feature_types</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – </p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>qid</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>label_lower_bound</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>label_upper_bound</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.dask.DaskDeviceQuantileDMatrix">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">DaskDeviceQuantileDMatrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">client</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_bin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_lower_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_upper_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskDeviceQuantileDMatrix" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.dask.DaskDMatrix" title="xgboost.dask.DaskDMatrix"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.dask.DaskDMatrix</span></code></a></p>
<p>Specialized data type for <cite>gpu_hist</cite> tree method.  This class is used to reduce the
memory usage by eliminating data copies.  Internally the all partitions/chunks of data
are merged by weighted GK sketching.  So the number of partitions from dask may affect
training accuracy as GK generates bounded error for each merge.  See doc string for
<a class="reference internal" href="#xgboost.DeviceQuantileDMatrix" title="xgboost.DeviceQuantileDMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.DeviceQuantileDMatrix</span></code></a> and <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.DMatrix</span></code></a> for other
parameters.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.2.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_bin</strong> (<em>Number of bins for histogram construction.</em>) – </p></li>
<li><p><strong>client</strong> (<a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><em>distributed.Client</em></a>) – </p></li>
<li><p><strong>data</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – </p></li>
<li><p><strong>label</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – </p></li>
<li><p><strong>silent</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
<li><p><strong>feature_names</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – </p></li>
<li><p><strong>feature_types</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>qid</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>label_lower_bound</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>label_upper_bound</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="xgboost.dask.train">
<span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">client</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtrain</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_boost_round</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.train" title="Permalink to this definition"></a></dt>
<dd><p>Train XGBoost model.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Other parameters are the same as <a class="reference internal" href="#xgboost.train" title="xgboost.train"><code class="xref py py-func docutils literal notranslate"><span class="pre">xgboost.train()</span></code></a> except for
<cite>evals_result</cite>, which is returned as part of function return value instead of
argument.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><em>distributed.Client</em></a>) – Specify the dask client used for training.  Use default client returned from dask
if it’s set to None.</p></li>
<li><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
<li><p><strong>dtrain</strong> (<a class="reference internal" href="#xgboost.dask.DaskDMatrix" title="xgboost.dask.DaskDMatrix"><em>xgboost.dask.DaskDMatrix</em></a>) – </p></li>
<li><p><strong>num_boost_round</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference internal" href="#xgboost.dask.DaskDMatrix" title="xgboost.dask.DaskDMatrix"><em>xgboost.dask.DaskDMatrix</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>obj</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>feval</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>]</em>) – </p></li>
<li><p><strong>verbose_eval</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – </p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p></li>
<li><p><strong>custom_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p><p><strong>results</strong> – A dictionary containing trained booster and evaluation history.  <cite>history</cite> field
is the same as <cite>eval_result</cite> from <cite>xgboost.train</cite>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'booster'</span><span class="p">:</span> <span class="n">xgboost</span><span class="o">.</span><span class="n">Booster</span><span class="p">,</span>
 <span class="s1">'history'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'train'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.48253'</span><span class="p">,</span> <span class="s1">'0.35953'</span><span class="p">]},</span>
             <span class="s1">'eval'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.480385'</span><span class="p">,</span> <span class="s1">'0.357756'</span><span class="p">]}}}</span>
</pre></div>
</div>
<p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)">dict</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="xgboost.dask.predict">
<span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">client</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_contribs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approx_contribs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_interactions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.predict" title="Permalink to this definition"></a></dt>
<dd><p>Run prediction with a trained booster.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using <code class="docutils literal notranslate"><span class="pre">inplace_predict</span></code> might be faster when some features are not needed.  See
<a class="reference internal" href="#xgboost.Booster.predict" title="xgboost.Booster.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">xgboost.Booster.predict()</span></code></a> for details on various parameters.  When output
has more than 2 dimensions (shap value, leaf with strict_shape), input should be
<code class="docutils literal notranslate"><span class="pre">da.Array</span></code> or <code class="docutils literal notranslate"><span class="pre">DaskDMatrix</span></code>.</p>
</div>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><em>distributed.Client</em></a>) – Specify the dask client used for training.  Use default client
returned from dask if it’s set to None.</p></li>
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>, </em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Future" title="(in Dask.distributed v2022.5.0)"><em>distributed.Future</em></a><em>]</em>) – The trained model.  It can be a distributed.Future so user can
pre-scatter it onto all workers.</p></li>
<li><p><strong>data</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.dask.DaskDMatrix" title="xgboost.dask.DaskDMatrix"><em>xgboost.dask.DaskDMatrix</em></a><em>, </em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Input data used for prediction.  When input is a dataframe object,
prediction output is a series.</p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Used when input data is not DaskDMatrix.  Specify the value
considered as missing.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
<li><p><strong>pred_leaf</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
<li><p><strong>pred_contribs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
<li><p><strong>approx_contribs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
<li><p><strong>pred_interactions</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p></li>
<li><p><strong>strict_shape</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>prediction</strong> – When input data is <code class="docutils literal notranslate"><span class="pre">dask.array.Array</span></code> or <code class="docutils literal notranslate"><span class="pre">DaskDMatrix</span></code>, the return value is an
array, when input data is <code class="docutils literal notranslate"><span class="pre">dask.dataframe.DataFrame</span></code>, return value can be
<code class="docutils literal notranslate"><span class="pre">dask.dataframe.Series</span></code>, <code class="docutils literal notranslate"><span class="pre">dask.dataframe.DataFrame</span></code>, depending on the output
shape.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dask.array.Array/dask.dataframe.Series</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="xgboost.dask.inplace_predict">
<span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">inplace_predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">client</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'value'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.inplace_predict" title="Permalink to this definition"></a></dt>
<dd><p>Inplace prediction. See doc in <a class="reference internal" href="#xgboost.Booster.inplace_predict" title="xgboost.Booster.inplace_predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">xgboost.Booster.inplace_predict()</span></code></a> for details.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.1.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><em>distributed.Client</em></a>) – Specify the dask client used for training.  Use default client
returned from dask if it’s set to None.</p></li>
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>, </em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Future" title="(in Dask.distributed v2022.5.0)"><em>distributed.Future</em></a><em>]</em>) – See <a class="reference internal" href="#xgboost.dask.predict" title="xgboost.dask.predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">xgboost.dask.predict()</span></code></a> for details.</p></li>
<li><p><strong>data</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – dask collection.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – See <a class="reference internal" href="#xgboost.Booster.predict" title="xgboost.Booster.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">xgboost.Booster.predict()</span></code></a> for details.</p></li>
<li><p><strong>predict_type</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – See <a class="reference internal" href="#xgboost.Booster.inplace_predict" title="xgboost.Booster.inplace_predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">xgboost.Booster.inplace_predict()</span></code></a> for details.</p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Value in the input data which needs to be present as a missing
value. If None, defaults to np.nan.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p><p>See <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.DMatrix</span></code></a> for details.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
<li><p><strong>strict_shape</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><p>See <a class="reference internal" href="#xgboost.Booster.predict" title="xgboost.Booster.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">xgboost.Booster.predict()</span></code></a> for details.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>When input data is <code class="docutils literal notranslate"><span class="pre">dask.array.Array</span></code>, the return value is an array, when input
data is <code class="docutils literal notranslate"><span class="pre">dask.dataframe.DataFrame</span></code>, return value can be
<code class="docutils literal notranslate"><span class="pre">dask.dataframe.Series</span></code>, <code class="docutils literal notranslate"><span class="pre">dask.dataframe.DataFrame</span></code>, depending on the output
shape.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">DaskXGBClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_leaves</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_bin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grow_policy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">booster</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tree_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_child_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_delta_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampling_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bytree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bylevel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bynode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_pos_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_parallel_tree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monotone_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interaction_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">importance_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gpu_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_cat_to_onehot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.dask.DaskScikitLearnBase</span></code>, <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.ClassifierMixin.html#sklearn.base.ClassifierMixin" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.ClassifierMixin</span></code></a></p>
<p>Implementation of the scikit-learn API for XGBoost classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of gradient boosted trees.  Equivalent to number of boosting
rounds.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.fit" title="xgboost.dask.DaskXGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.fit" title="xgboost.dask.DaskXGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.best_score" title="xgboost.dask.DaskXGBClassifier.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.best_iteration" title="xgboost.dask.DaskXGBClassifier.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.fit" title="xgboost.dask.DaskXGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.dask.predict" title="xgboost.dask.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.client">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">client</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><span class="pre">distributed.Client</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.client" title="Permalink to this definition"></a></dt>
<dd><p>The dask client used in this model.  The <cite>Client</cite> object can not be serialized for
transmission, so if task is launched from a worker instead of directly from the
client process, this attribute needs to be set at that worker.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.fit" title="xgboost.dask.DaskXGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.fit" title="xgboost.dask.DaskXGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.fit" title="xgboost.dask.DaskXGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.fit" title="xgboost.dask.DaskXGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting model.</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Labels</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – instance weights</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, or </em><em>callable</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.set_params" title="xgboost.dask.DaskXGBClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.set_params" title="xgboost.dask.DaskXGBClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [L_1, L_2, …, L_n], where each L_i is an array like
object storing instance weights for the i-th validation set.</p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.set_params" title="xgboost.dask.DaskXGBClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.dask.DaskXGBClassifier" title="xgboost.dask.DaskXGBClassifier">DaskXGBClassifier</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.fit" title="xgboost.dask.DaskXGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.predict_proba" title="Permalink to this definition"></a></dt>
<dd><p>Predict the probability of each <cite>X</cite> example being of a given class.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em>) – Feature matrix.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<em>array_like</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <cite>iteration_range=(10,
20)</cite>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a numpy array of shape array-like of shape (n_samples, n_classes) with the
probability of each data example being of a given class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.score" title="Permalink to this definition"></a></dt>
<dd><p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test samples.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – True labels for <cite>X</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> – Mean accuracy of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <cite>y</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">DaskXGBRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_leaves</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_bin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grow_policy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">booster</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tree_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_child_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_delta_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampling_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bytree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bylevel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bynode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_pos_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_parallel_tree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monotone_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interaction_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">importance_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gpu_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_cat_to_onehot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.dask.DaskScikitLearnBase</span></code>, <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html#sklearn.base.RegressorMixin" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.RegressorMixin</span></code></a></p>
<p>Implementation of the Scikit-Learn API for XGBoost.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of gradient boosted trees.  Equivalent to number of boosting
rounds.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.fit" title="xgboost.dask.DaskXGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.fit" title="xgboost.dask.DaskXGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.best_score" title="xgboost.dask.DaskXGBRegressor.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.best_iteration" title="xgboost.dask.DaskXGBRegressor.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.fit" title="xgboost.dask.DaskXGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.dask.predict" title="xgboost.dask.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.client">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">client</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><span class="pre">distributed.Client</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.client" title="Permalink to this definition"></a></dt>
<dd><p>The dask client used in this model.  The <cite>Client</cite> object can not be serialized for
transmission, so if task is launched from a worker instead of directly from the
client process, this attribute needs to be set at that worker.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.fit" title="xgboost.dask.DaskXGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.fit" title="xgboost.dask.DaskXGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.fit" title="xgboost.dask.DaskXGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.fit" title="xgboost.dask.DaskXGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting model.</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Labels</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – instance weights</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, or </em><em>callable</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.set_params" title="xgboost.dask.DaskXGBRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.set_params" title="xgboost.dask.DaskXGBRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [L_1, L_2, …, L_n], where each L_i is an array like
object storing instance weights for the i-th validation set.</p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.set_params" title="xgboost.dask.DaskXGBRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.dask.DaskXGBRegressor" title="xgboost.dask.DaskXGBRegressor">DaskXGBRegressor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.fit" title="xgboost.dask.DaskXGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.score" title="Permalink to this definition"></a></dt>
<dd><p>Return the coefficient of determination of the prediction.</p>
<p>The coefficient of determination <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="14"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> is defined as
<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="15"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mfrac><mi>u</mi><mi>v</mi></mfrac><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></span>, where <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="16"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>u</mi></math></mjx-assistive-mml></mjx-container></span> is the residual
sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_pred)**</span> <span class="pre">2).sum()</span></code> and <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="17"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>v</mi></math></mjx-assistive-mml></mjx-container></span>
is the total sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_true.mean())</span> <span class="pre">**</span> <span class="pre">2).sum()</span></code>.
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always predicts
the expected value of <cite>y</cite>, disregarding the input features, would get
a <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="18"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> score of 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test samples. For some estimators this may be a precomputed
kernel matrix or a list of generic objects instead with shape
<code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_samples_fitted)</span></code>, where <code class="docutils literal notranslate"><span class="pre">n_samples_fitted</span></code>
is the number of samples used in the fitting for the estimator.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – True values for <cite>X</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> – <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="19"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <cite>y</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="20"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> score used when calling <code class="docutils literal notranslate"><span class="pre">score</span></code> on a regressor uses
<code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code> from version 0.23 to keep consistent
with default value of <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score()</span></code></a>.
This influences the <code class="docutils literal notranslate"><span class="pre">score</span></code> method of all the multioutput
regressors (except for
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRegressor</span></code></a>).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">DaskXGBRanker</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'rank:pairwise'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.dask.DaskScikitLearnBase</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.sklearn.XGBRankerMixIn</span></code></p>
<p>Implementation of the Scikit-Learn API for XGBoost Ranking.</p>
<blockquote>
<div><div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of gradient boosted trees.  Equivalent to number of boosting
rounds.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.fit" title="xgboost.dask.DaskXGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.fit" title="xgboost.dask.DaskXGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.dask.DaskXGBRanker.best_score" title="xgboost.dask.DaskXGBRanker.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.best_iteration" title="xgboost.dask.DaskXGBRanker.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.fit" title="xgboost.dask.DaskXGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For dask implementation, group is not supported, use qid instead.</p>
</div>
<p></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.dask.predict" title="xgboost.dask.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.client">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">client</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><span class="pre">distributed.Client</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.client" title="Permalink to this definition"></a></dt>
<dd><p>The dask client used in this model.  The <cite>Client</cite> object can not be serialized for
transmission, so if task is launched from a worker instead of directly from the
client process, this attribute needs to be set at that worker.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.fit" title="xgboost.dask.DaskXGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.fit" title="xgboost.dask.DaskXGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.fit" title="xgboost.dask.DaskXGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.fit" title="xgboost.dask.DaskXGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting ranker</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Labels</p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Size of each query group of training data. Should have as many elements as the
query groups in the training data.  If this is set to None, then user must
provide qid.</p></li>
<li><p><strong>qid</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Query ID for each training sample.  Should have the size of n_samples.  If
this is set to None, then user must provide group.</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p><p>Query group weights</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Weights are per-group for ranking tasks</p>
<p>In ranking task, one weight is assigned to each query group/id (not each
data point). This is because we only care about the relative ordering of
data points within each group, so it doesn’t make sense to assign weights
to individual data points.</p>
</div>
<p></p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list in which <code class="docutils literal notranslate"><span class="pre">eval_group[i]</span></code> is the list containing the sizes of all
query groups in the <code class="docutils literal notranslate"><span class="pre">i</span></code>-th pair in <strong>eval_set</strong>.</p></li>
<li><p><strong>eval_qid</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list in which <code class="docutils literal notranslate"><span class="pre">eval_qid[i]</span></code> is the array containing query ID of <code class="docutils literal notranslate"><span class="pre">i</span></code>-th
pair in <strong>eval_set</strong>.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.set_params" title="xgboost.dask.DaskXGBRanker.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.dask.DaskXGBRanker.set_params" title="xgboost.dask.DaskXGBRanker.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – </p><p>A list of the form [L_1, L_2, …, L_n], where each L_i is a list of
group weights on the i-th validation set.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Weights are per-group for ranking tasks</p>
<p>In ranking task, one weight is assigned to each query group (not each
data point). This is because we only care about the relative ordering of
data points within each group, so it doesn’t make sense to assign
weights to individual data points.</p>
</div>
<p></p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.set_params" title="xgboost.dask.DaskXGBRanker.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.dask.DaskXGBRanker" title="xgboost.dask.DaskXGBRanker">DaskXGBRanker</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.fit" title="xgboost.dask.DaskXGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">DaskXGBRFRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bynode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor" title="xgboost.dask.DaskXGBRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.dask.DaskXGBRegressor</span></code></a></p>
<p>Implementation of the Scikit-Learn API for XGBoost Random Forest Regressor.</p>
<blockquote>
<div><div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of trees in random forest to fit.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="xgboost.dask.DaskXGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="xgboost.dask.DaskXGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.best_score" title="xgboost.dask.DaskXGBRFRegressor.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.best_iteration" title="xgboost.dask.DaskXGBRFRegressor.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="xgboost.dask.DaskXGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Custom objective function</p>
<p>A custom objective function can be provided for the <code class="docutils literal notranslate"><span class="pre">objective</span></code>
parameter. In this case, it should have the signature
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code>:</p>
<dl class="simple">
<dt>y_true: array_like of shape [n_samples]</dt><dd><p>The target values</p>
</dd>
<dt>y_pred: array_like of shape [n_samples]</dt><dd><p>The predicted values</p>
</dd>
<dt>grad: array_like of shape [n_samples]</dt><dd><p>The value of the gradient for each sample point.</p>
</dd>
<dt>hess: array_like of shape [n_samples]</dt><dd><p>The value of the second derivative for each sample point</p>
</dd>
</dl>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.dask.predict" title="xgboost.dask.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.client">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">client</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><span class="pre">distributed.Client</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.client" title="Permalink to this definition"></a></dt>
<dd><p>The dask client used in this model.  The <cite>Client</cite> object can not be serialized for
transmission, so if task is launched from a worker instead of directly from the
client process, this attribute needs to be set at that worker.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="xgboost.dask.DaskXGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="xgboost.dask.DaskXGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="xgboost.dask.DaskXGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="xgboost.dask.DaskXGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting model.</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Labels</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – instance weights</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, or </em><em>callable</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.set_params" title="xgboost.dask.DaskXGBRFRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.set_params" title="xgboost.dask.DaskXGBRFRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [L_1, L_2, …, L_n], where each L_i is an array like
object storing instance weights for the i-th validation set.</p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.set_params" title="xgboost.dask.DaskXGBRFRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor" title="xgboost.dask.DaskXGBRFRegressor">DaskXGBRFRegressor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="xgboost.dask.DaskXGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.score" title="Permalink to this definition"></a></dt>
<dd><p>Return the coefficient of determination of the prediction.</p>
<p>The coefficient of determination <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="21"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> is defined as
<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="22"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mfrac><mi>u</mi><mi>v</mi></mfrac><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></span>, where <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="23"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>u</mi></math></mjx-assistive-mml></mjx-container></span> is the residual
sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_pred)**</span> <span class="pre">2).sum()</span></code> and <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="24"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>v</mi></math></mjx-assistive-mml></mjx-container></span>
is the total sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_true.mean())</span> <span class="pre">**</span> <span class="pre">2).sum()</span></code>.
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always predicts
the expected value of <cite>y</cite>, disregarding the input features, would get
a <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="25"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> score of 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test samples. For some estimators this may be a precomputed
kernel matrix or a list of generic objects instead with shape
<code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_samples_fitted)</span></code>, where <code class="docutils literal notranslate"><span class="pre">n_samples_fitted</span></code>
is the number of samples used in the fitting for the estimator.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – True values for <cite>X</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> – <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="26"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <cite>y</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="27"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> score used when calling <code class="docutils literal notranslate"><span class="pre">score</span></code> on a regressor uses
<code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code> from version 0.23 to keep consistent
with default value of <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score()</span></code></a>.
This influences the <code class="docutils literal notranslate"><span class="pre">score</span></code> method of all the multioutput
regressors (except for
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRegressor</span></code></a>).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">DaskXGBRFClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bynode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier" title="xgboost.dask.DaskXGBClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.dask.DaskXGBClassifier</span></code></a></p>
<p>Implementation of the Scikit-Learn API for XGBoost Random Forest Classifier.</p>
<blockquote>
<div><div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of trees in random forest to fit.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="xgboost.dask.DaskXGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="xgboost.dask.DaskXGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.best_score" title="xgboost.dask.DaskXGBRFClassifier.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.best_iteration" title="xgboost.dask.DaskXGBRFClassifier.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="xgboost.dask.DaskXGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Custom objective function</p>
<p>A custom objective function can be provided for the <code class="docutils literal notranslate"><span class="pre">objective</span></code>
parameter. In this case, it should have the signature
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code>:</p>
<dl class="simple">
<dt>y_true: array_like of shape [n_samples]</dt><dd><p>The target values</p>
</dd>
<dt>y_pred: array_like of shape [n_samples]</dt><dd><p>The predicted values</p>
</dd>
<dt>grad: array_like of shape [n_samples]</dt><dd><p>The value of the gradient for each sample point.</p>
</dd>
<dt>hess: array_like of shape [n_samples]</dt><dd><p>The value of the second derivative for each sample point</p>
</dd>
</dl>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.dask.predict" title="xgboost.dask.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.client">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">client</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><span class="pre">distributed.Client</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.client" title="Permalink to this definition"></a></dt>
<dd><p>The dask client used in this model.  The <cite>Client</cite> object can not be serialized for
transmission, so if task is launched from a worker instead of directly from the
client process, this attribute needs to be set at that worker.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="xgboost.dask.DaskXGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="xgboost.dask.DaskXGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="xgboost.dask.DaskXGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="xgboost.dask.DaskXGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting model.</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Labels</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – instance weights</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, or </em><em>callable</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.set_params" title="xgboost.dask.DaskXGBRFClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.set_params" title="xgboost.dask.DaskXGBRFClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [L_1, L_2, …, L_n], where each L_i is an array like
object storing instance weights for the i-th validation set.</p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.set_params" title="xgboost.dask.DaskXGBRFClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier" title="xgboost.dask.DaskXGBRFClassifier">DaskXGBRFClassifier</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="xgboost.dask.DaskXGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.predict_proba" title="Permalink to this definition"></a></dt>
<dd><p>Predict the probability of each <cite>X</cite> example being of a given class.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em>) – Feature matrix.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<em>array_like</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <cite>iteration_range=(10,
20)</cite>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a numpy array of shape array-like of shape (n_samples, n_classes) with the
probability of each data example being of a given class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.score" title="Permalink to this definition"></a></dt>
<dd><p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test samples.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – True labels for <cite>X</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> – Mean accuracy of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <cite>y</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
