<!DOCTYPE html>
<head>
<!--        <link rel="stylesheet" href="pygments.css" type="text/css" />-->
<!--      <link rel="stylesheet" href="theme.css" type="text/css" />-->
<!--      <link rel="stylesheet" href="plot_directive.css" type="text/css" />-->
<!--      <link rel="stylesheet" href="custom.css" type="text/css" />-->
<!--
      <link rel="stylesheet" href="sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="sg_gallery-rendered-html.css" type="text/css" />
-->
      <link rel="stylesheet" href="custom.css" type="text/css" />
    <style>
html{box-sizing:border-box}*,:after,:before{box-sizing:inherit}article,aside,details,figcaption,figure,footer,header,hgroup,nav,section{display:block}audio,canvas,video{display:inline-block;*display:inline;*zoom:1}[hidden],audio:not([controls]){display:none}*{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box}html{font-size:100%;-webkit-text-size-adjust:100%;-ms-text-size-adjust:100%}body{margin:0}a:active,a:hover{outline:0}abbr[title]{border-bottom:1px dotted}b,strong{font-weight:700}blockquote{margin:0}dfn{font-style:italic}ins{background:#ff9;text-decoration:none}ins,mark{color:#000}mark{background:#ff0;font-style:italic;font-weight:700}.rst-content code,.rst-content tt,code,kbd,pre,samp{font-family:monospace,serif;_font-family:courier new,monospace;font-size:1em}pre{white-space:pre}q{quotes:none}q:after,q:before{content:"";content:none}small{font-size:85%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sup{top:-.5em}sub{bottom:-.25em}dl,ol,ul{margin:0;padding:0;list-style:none;list-style-image:none}li{list-style:none}dd{margin:0}img{border:0;-ms-interpolation-mode:bicubic;vertical-align:middle;max-width:100%}svg:not(:root){overflow:hidden}figure,form{margin:0}label{cursor:pointer}button,input,select,textarea{font-size:100%;margin:0;vertical-align:baseline;*vertical-align:middle}button,input{line-height:normal}button,input[type=button],input[type=reset],input[type=submit]{cursor:pointer;-webkit-appearance:button;*overflow:visible}button[disabled],input[disabled]{cursor:default}input[type=search]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}textarea{resize:vertical}table{border-collapse:collapse;border-spacing:0}td{vertical-align:top}.chromeframe{margin:.2em 0;background:#ccc;color:#000;padding:.2em 0}.ir{display:block;border:0;text-indent:-999em;overflow:hidden;background-color:transparent;background-repeat:no-repeat;text-align:left;direction:ltr;*line-height:0}.ir br{display:none}.hidden{display:none!important;visibility:hidden}.visuallyhidden{border:0;clip:rect(0 0 0 0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}.visuallyhidden.focusable:active,.visuallyhidden.focusable:focus{clip:auto;height:auto;margin:0;overflow:visible;position:static;width:auto}.invisible{visibility:hidden}.relative{position:relative}big,small{font-size:100%}@media print{body,html,section{background:none!important}*{box-shadow:none!important;text-shadow:none!important;filter:none!important;-ms-filter:none!important}a,a:visited{text-decoration:underline}.ir a:after,a[href^="#"]:after,a[href^="javascript:"]:after{content:""}blockquote,pre{page-break-inside:avoid}thead{display:table-header-group}img,tr{page-break-inside:avoid}img{max-width:100%!important}@page{margin:.5cm}.rst-content .toctree-wrapper>p.caption,h2,h3,p{orphans:3;widows:3}.rst-content .toctree-wrapper>p.caption,h2,h3{page-break-after:avoid}}.btn,.fa:before,.icon:before,.rst-content .admonition,.rst-content .admonition-title:before,.rst-content .admonition-todo,.rst-content .attention,.rst-content .caution,.rst-content .code-block-caption .headerlink:before,.rst-content .danger,.rst-content .eqno .headerlink:before,.rst-content .error,.rst-content .hint,.rst-content .important,.rst-content .note,.rst-content .seealso,.rst-content .tip,.rst-content .warning,.rst-content code.download span:first-child:before,.rst-content dl dt .headerlink:before,.rst-content h1 .headerlink:before,.rst-content h2 .headerlink:before,.rst-content h3 .headerlink:before,.rst-content h4 .headerlink:before,.rst-content h5 .headerlink:before,.rst-content h6 .headerlink:before,.rst-content p.caption .headerlink:before,.rst-content p .headerlink:before,.rst-content table>caption .headerlink:before,.rst-content tt.download span:first-child:before,.wy-alert,.wy-dropdown .caret:before,.wy-inline-validate.wy-inline-validate-danger .wy-input-context:before,.wy-inline-validate.wy-inline-validate-info .wy-input-context:before,.wy-inline-validate.wy-inline-validate-success .wy-input-context:before,.wy-inline-validate.wy-inline-validate-warning .wy-input-context:before,.wy-menu-vertical li.current>a,.wy-menu-vertical li.current>a button.toctree-expand:before,.wy-menu-vertical li.on a,.wy-menu-vertical li.on a button.toctree-expand:before,.wy-menu-vertical li button.toctree-expand:before,.wy-nav-top a,.wy-side-nav-search .wy-dropdown>a,.wy-side-nav-search>a,input[type=color],input[type=date],input[type=datetime-local],input[type=datetime],input[type=email],input[type=month],input[type=number],input[type=password],input[type=search],input[type=tel],input[type=text],input[type=time],input[type=url],input[type=week],select,textarea{-webkit-font-smoothing:antialiased}.clearfix{*zoom:1}.clearfix:after,.clearfix:before{display:table;content:""}.clearfix:after{clear:both}/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */@font-face{font-family:FontAwesome;src:url(fonts/fontawesome-webfont.eot?674f50d287a8c48dc19ba404d20fe713);src:url(fonts/fontawesome-webfont.eot?674f50d287a8c48dc19ba404d20fe713?#iefix&v=4.7.0) format("embedded-opentype"),url(fonts/fontawesome-webfont.woff2?af7ae505a9eed503f8b8e6982036873e) format("woff2"),url(fonts/fontawesome-webfont.woff?fee66e712a8a08eef5805a46892932ad) format("woff"),url(fonts/fontawesome-webfont.ttf?b06871f281fee6b241d60582ae9369b9) format("truetype"),url(fonts/fontawesome-webfont.svg?912ec66d7572ff821749319396470bde#fontawesomeregular) format("svg");font-weight:400;font-style:normal}.fa,.icon,.rst-content .admonition-title,.rst-content .code-block-caption .headerlink,.rst-content .eqno .headerlink,.rst-content code.download span:first-child,.rst-content dl dt .headerlink,.rst-content h1 .headerlink,.rst-content h2 .headerlink,.rst-content h3 .headerlink,.rst-content h4 .headerlink,.rst-content h5 .headerlink,.rst-content h6 .headerlink,.rst-content p.caption .headerlink,.rst-content p .headerlink,.rst-content table>caption .headerlink,.rst-content tt.download span:first-child,.wy-menu-vertical li.current>a button.toctree-expand,.wy-menu-vertical li.on a button.toctree-expand,.wy-menu-vertical li button.toctree-expand{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}.fa-lg{font-size:1.33333em;line-height:.75em;vertical-align:-15%}.fa-2x{font-size:2em}.fa-3x{font-size:3em}.fa-4x{font-size:4em}.fa-5x{font-size:5em}.fa-fw{width:1.28571em;text-align:center}.fa-ul{padding-left:0;margin-left:2.14286em;list-style-type:none}.fa-ul>li{position:relative}.fa-li{position:absolute;left:-2.14286em;width:2.14286em;top:.14286em;text-align:center}.fa-li.fa-lg{left:-1.85714em}.fa-border{padding:.2em .25em .15em;border:.08em solid #eee;border-radius:.1em}.fa-pull-left{float:left}.fa-pull-right{float:right}.fa-pull-left.icon,.fa.fa-pull-left,.rst-content .code-block-caption .fa-pull-left.headerlink,.rst-content .eqno .fa-pull-left.headerlink,.rst-content .fa-pull-left.admonition-title,.rst-content code.download span.fa-pull-left:first-child,.rst-content dl dt .fa-pull-left.headerlink,.rst-content h1 .fa-pull-left.headerlink,.rst-content h2 .fa-pull-left.headerlink,.rst-content h3 .fa-pull-left.headerlink,.rst-content h4 .fa-pull-left.headerlink,.rst-content h5 .fa-pull-left.headerlink,.rst-content h6 .fa-pull-left.headerlink,.rst-content p .fa-pull-left.headerlink,.rst-content table>caption .fa-pull-left.headerlink,.rst-content tt.download span.fa-pull-left:first-child,.wy-menu-vertical li.current>a button.fa-pull-left.toctree-expand,.wy-menu-vertical li.on a button.fa-pull-left.toctree-expand,.wy-menu-vertical li button.fa-pull-left.toctree-expand{margin-right:.3em}.fa-pull-right.icon,.fa.fa-pull-right,.rst-content .code-block-caption .fa-pull-right.headerlink,.rst-content .eqno .fa-pull-right.headerlink,.rst-content .fa-pull-right.admonition-title,.rst-content code.download span.fa-pull-right:first-child,.rst-content dl dt .fa-pull-right.headerlink,.rst-content h1 .fa-pull-right.headerlink,.rst-content h2 .fa-pull-right.headerlink,.rst-content h3 .fa-pull-right.headerlink,.rst-content h4 .fa-pull-right.headerlink,.rst-content h5 .fa-pull-right.headerlink,.rst-content h6 .fa-pull-right.headerlink,.rst-content p .fa-pull-right.headerlink,.rst-content table>caption .fa-pull-right.headerlink,.rst-content tt.download span.fa-pull-right:first-child,.wy-menu-vertical li.current>a button.fa-pull-right.toctree-expand,.wy-menu-vertical li.on a button.fa-pull-right.toctree-expand,.wy-menu-vertical li button.fa-pull-right.toctree-expand{margin-left:.3em}.pull-right{float:right}.pull-left{float:left}.fa.pull-left,.pull-left.icon,.rst-content .code-block-caption .pull-left.headerlink,.rst-content .eqno .pull-left.headerlink,.rst-content .pull-left.admonition-title,.rst-content code.download span.pull-left:first-child,.rst-content dl dt .pull-left.headerlink,.rst-content h1 .pull-left.headerlink,.rst-content h2 .pull-left.headerlink,.rst-content h3 .pull-left.headerlink,.rst-content h4 .pull-left.headerlink,.rst-content h5 .pull-left.headerlink,.rst-content h6 .pull-left.headerlink,.rst-content p .pull-left.headerlink,.rst-content table>caption .pull-left.headerlink,.rst-content tt.download span.pull-left:first-child,.wy-menu-vertical li.current>a button.pull-left.toctree-expand,.wy-menu-vertical li.on a button.pull-left.toctree-expand,.wy-menu-vertical li button.pull-left.toctree-expand{margin-right:.3em}.fa.pull-right,.pull-right.icon,.rst-content .code-block-caption .pull-right.headerlink,.rst-content .eqno .pull-right.headerlink,.rst-content .pull-right.admonition-title,.rst-content code.download span.pull-right:first-child,.rst-content dl dt .pull-right.headerlink,.rst-content h1 .pull-right.headerlink,.rst-content h2 .pull-right.headerlink,.rst-content h3 .pull-right.headerlink,.rst-content h4 .pull-right.headerlink,.rst-content h5 .pull-right.headerlink,.rst-content h6 .pull-right.headerlink,.rst-content p .pull-right.headerlink,.rst-content table>caption .pull-right.headerlink,.rst-content tt.download span.pull-right:first-child,.wy-menu-vertical li.current>a button.pull-right.toctree-expand,.wy-menu-vertical li.on a button.pull-right.toctree-expand,.wy-menu-vertical li button.pull-right.toctree-expand{margin-left:.3em}.fa-spin{-webkit-animation:fa-spin 2s linear infinite;animation:fa-spin 2s linear infinite}.fa-pulse{-webkit-animation:fa-spin 1s steps(8) infinite;animation:fa-spin 1s steps(8) infinite}@-webkit-keyframes fa-spin{0%{-webkit-transform:rotate(0deg);transform:rotate(0deg)}to{-webkit-transform:rotate(359deg);transform:rotate(359deg)}}@keyframes fa-spin{0%{-webkit-transform:rotate(0deg);transform:rotate(0deg)}to{-webkit-transform:rotate(359deg);transform:rotate(359deg)}}.fa-rotate-90{-ms-filter:"progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";-webkit-transform:rotate(90deg);-ms-transform:rotate(90deg);transform:rotate(90deg)}.fa-rotate-180{-ms-filter:"progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";-webkit-transform:rotate(180deg);-ms-transform:rotate(180deg);transform:rotate(180deg)}.fa-rotate-270{-ms-filter:"progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";-webkit-transform:rotate(270deg);-ms-transform:rotate(270deg);transform:rotate(270deg)}.fa-flip-horizontal{-ms-filter:"progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";-webkit-transform:scaleX(-1);-ms-transform:scaleX(-1);transform:scaleX(-1)}.fa-flip-vertical{-ms-filter:"progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";-webkit-transform:scaleY(-1);-ms-transform:scaleY(-1);transform:scaleY(-1)}:root .fa-flip-horizontal,:root .fa-flip-vertical,:root .fa-rotate-90,:root .fa-rotate-180,:root .fa-rotate-270{filter:none}.fa-stack{position:relative;display:inline-block;width:2em;height:2em;line-height:2em;vertical-align:middle}.fa-stack-1x,.fa-stack-2x{position:absolute;left:0;width:100%;text-align:center}.fa-stack-1x{line-height:inherit}.fa-stack-2x{font-size:2em}.fa-inverse{color:#fff}.fa-glass:before{content:""}.fa-music:before{content:""}.fa-search:before,.icon-search:before{content:""}.fa-envelope-o:before{content:""}.fa-heart:before{content:""}.fa-star:before{content:""}.fa-star-o:before{content:""}.fa-user:before{content:""}.fa-film:before{content:""}.fa-th-large:before{content:""}.fa-th:before{content:""}.fa-th-list:before{content:""}.fa-check:before{content:""}.fa-close:before,.fa-remove:before,.fa-times:before{content:""}.fa-search-plus:before{content:""}.fa-search-minus:before{content:""}.fa-power-off:before{content:""}.fa-signal:before{content:""}.fa-cog:before,.fa-gear:before{content:""}.fa-trash-o:before{content:""}.fa-home:before,.icon-home:before{content:""}.fa-file-o:before{content:""}.fa-clock-o:before{content:""}.fa-road:before{content:""}.fa-download:before,.rst-content code.download span:first-child:before,.rst-content tt.download span:first-child:before{content:""}.fa-arrow-circle-o-down:before{content:""}.fa-arrow-circle-o-up:before{content:""}.fa-inbox:before{content:""}.fa-play-circle-o:before{content:""}.fa-repeat:before,.fa-rotate-right:before{content:""}.fa-refresh:before{content:""}.fa-list-alt:before{content:""}.fa-lock:before{content:""}.fa-flag:before{content:""}.fa-headphones:before{content:""}.fa-volume-off:before{content:""}.fa-volume-down:before{content:""}.fa-volume-up:before{content:""}.fa-qrcode:before{content:""}.fa-barcode:before{content:""}.fa-tag:before{content:""}.fa-tags:before{content:""}.fa-book:before,.icon-book:before{content:""}.fa-bookmark:before{content:""}.fa-print:before{content:""}.fa-camera:before{content:""}.fa-font:before{content:""}.fa-bold:before{content:""}.fa-italic:before{content:""}.fa-text-height:before{content:""}.fa-text-width:before{content:""}.fa-align-left:before{content:""}.fa-align-center:before{content:""}.fa-align-right:before{content:""}.fa-align-justify:before{content:""}.fa-list:before{content:""}.fa-dedent:before,.fa-outdent:before{content:""}.fa-indent:before{content:""}.fa-video-camera:before{content:""}.fa-image:before,.fa-photo:before,.fa-picture-o:before{content:""}.fa-pencil:before{content:""}.fa-map-marker:before{content:""}.fa-adjust:before{content:""}.fa-tint:before{content:""}.fa-edit:before,.fa-pencil-square-o:before{content:""}.fa-share-square-o:before{content:""}.fa-check-square-o:before{content:""}.fa-arrows:before{content:""}.fa-step-backward:before{content:""}.fa-fast-backward:before{content:""}.fa-backward:before{content:""}.fa-play:before{content:""}.fa-pause:before{content:""}.fa-stop:before{content:""}.fa-forward:before{content:""}.fa-fast-forward:before{content:""}.fa-step-forward:before{content:""}.fa-eject:before{content:""}.fa-chevron-left:before{content:""}.fa-chevron-right:before{content:""}.fa-plus-circle:before{content:""}.fa-minus-circle:before{content:""}.fa-times-circle:before,.wy-inline-validate.wy-inline-validate-danger .wy-input-context:before{content:""}.fa-check-circle:before,.wy-inline-validate.wy-inline-validate-success .wy-input-context:before{content:""}.fa-question-circle:before{content:""}.fa-info-circle:before{content:""}.fa-crosshairs:before{content:""}.fa-times-circle-o:before{content:""}.fa-check-circle-o:before{content:""}.fa-ban:before{content:""}.fa-arrow-left:before{content:""}.fa-arrow-right:before{content:""}.fa-arrow-up:before{content:""}.fa-arrow-down:before{content:""}.fa-mail-forward:before,.fa-share:before{content:""}.fa-expand:before{content:""}.fa-compress:before{content:""}.fa-plus:before{content:""}.fa-minus:before{content:""}.fa-asterisk:before{content:""}.fa-exclamation-circle:before,.rst-content .admonition-title:before,.wy-inline-validate.wy-inline-validate-info .wy-input-context:before,.wy-inline-validate.wy-inline-validate-warning .wy-input-context:before{content:""}.fa-gift:before{content:""}.fa-leaf:before{content:""}.fa-fire:before,.icon-fire:before{content:""}.fa-eye:before{content:""}.fa-eye-slash:before{content:""}.fa-exclamation-triangle:before,.fa-warning:before{content:""}.fa-plane:before{content:""}.fa-calendar:before{content:""}.fa-random:before{content:""}.fa-comment:before{content:""}.fa-magnet:before{content:""}.fa-chevron-up:before{content:""}.fa-chevron-down:before{content:""}.fa-retweet:before{content:""}.fa-shopping-cart:before{content:""}.fa-folder:before{content:""}.fa-folder-open:before{content:""}.fa-arrows-v:before{content:""}.fa-arrows-h:before{content:""}.fa-bar-chart-o:before,.fa-bar-chart:before{content:""}.fa-twitter-square:before{content:""}.fa-facebook-square:before{content:""}.fa-camera-retro:before{content:""}.fa-key:before{content:""}.fa-cogs:before,.fa-gears:before{content:""}.fa-comments:before{content:""}.fa-thumbs-o-up:before{content:""}.fa-thumbs-o-down:before{content:""}.fa-star-half:before{content:""}.fa-heart-o:before{content:""}.fa-sign-out:before{content:""}.fa-linkedin-square:before{content:""}.fa-thumb-tack:before{content:""}.fa-external-link:before{content:""}.fa-sign-in:before{content:""}.fa-trophy:before{content:""}.fa-github-square:before{content:""}.fa-upload:before{content:""}.fa-lemon-o:before{content:""}.fa-phone:before{content:""}.fa-square-o:before{content:""}.fa-bookmark-o:before{content:""}.fa-phone-square:before{content:""}.fa-twitter:before{content:""}.fa-facebook-f:before,.fa-facebook:before{content:""}.fa-github:before,.icon-github:before{content:""}.fa-unlock:before{content:""}.fa-credit-card:before{content:""}.fa-feed:before,.fa-rss:before{content:""}.fa-hdd-o:before{content:""}.fa-bullhorn:before{content:""}.fa-bell:before{content:""}.fa-certificate:before{content:""}.fa-hand-o-right:before{content:""}.fa-hand-o-left:before{content:""}.fa-hand-o-up:before{content:""}.fa-hand-o-down:before{content:""}.fa-arrow-circle-left:before,.icon-circle-arrow-left:before{content:""}.fa-arrow-circle-right:before,.icon-circle-arrow-right:before{content:""}.fa-arrow-circle-up:before{content:""}.fa-arrow-circle-down:before{content:""}.fa-globe:before{content:""}.fa-wrench:before{content:""}.fa-tasks:before{content:""}.fa-filter:before{content:""}.fa-briefcase:before{content:""}.fa-arrows-alt:before{content:""}.fa-group:before,.fa-users:before{content:""}.fa-chain:before,.fa-link:before,.icon-link:before{content:""}.fa-cloud:before{content:""}.fa-flask:before{content:""}.fa-cut:before,.fa-scissors:before{content:""}.fa-copy:before,.fa-files-o:before{content:""}.fa-paperclip:before{content:""}.fa-floppy-o:before,.fa-save:before{content:""}.fa-square:before{content:""}.fa-bars:before,.fa-navicon:before,.fa-reorder:before{content:""}.fa-list-ul:before{content:""}.fa-list-ol:before{content:""}.fa-strikethrough:before{content:""}.fa-underline:before{content:""}.fa-table:before{content:""}.fa-magic:before{content:""}.fa-truck:before{content:""}.fa-pinterest:before{content:""}.fa-pinterest-square:before{content:""}.fa-google-plus-square:before{content:""}.fa-google-plus:before{content:""}.fa-money:before{content:""}.fa-caret-down:before,.icon-caret-down:before,.wy-dropdown .caret:before{content:""}.fa-caret-up:before{content:""}.fa-caret-left:before{content:""}.fa-caret-right:before{content:""}.fa-columns:before{content:""}.fa-sort:before,.fa-unsorted:before{content:""}.fa-sort-desc:before,.fa-sort-down:before{content:""}.fa-sort-asc:before,.fa-sort-up:before{content:""}.fa-envelope:before{content:""}.fa-linkedin:before{content:""}.fa-rotate-left:before,.fa-undo:before{content:""}.fa-gavel:before,.fa-legal:before{content:""}.fa-dashboard:before,.fa-tachometer:before{content:""}.fa-comment-o:before{content:""}.fa-comments-o:before{content:""}.fa-bolt:before,.fa-flash:before{content:""}.fa-sitemap:before{content:""}.fa-umbrella:before{content:""}.fa-clipboard:before,.fa-paste:before{content:""}.fa-lightbulb-o:before{content:""}.fa-exchange:before{content:""}.fa-cloud-download:before{content:""}.fa-cloud-upload:before{content:""}.fa-user-md:before{content:""}.fa-stethoscope:before{content:""}.fa-suitcase:before{content:""}.fa-bell-o:before{content:""}.fa-coffee:before{content:""}.fa-cutlery:before{content:""}.fa-file-text-o:before{content:""}.fa-building-o:before{content:""}.fa-hospital-o:before{content:""}.fa-ambulance:before{content:""}.fa-medkit:before{content:""}.fa-fighter-jet:before{content:""}.fa-beer:before{content:""}.fa-h-square:before{content:""}.fa-plus-square:before{content:""}.fa-angle-double-left:before{content:""}.fa-angle-double-right:before{content:""}.fa-angle-double-up:before{content:""}.fa-angle-double-down:before{content:""}.fa-angle-left:before{content:""}.fa-angle-right:before{content:""}.fa-angle-up:before{content:""}.fa-angle-down:before{content:""}.fa-desktop:before{content:""}.fa-laptop:before{content:""}.fa-tablet:before{content:""}.fa-mobile-phone:before,.fa-mobile:before{content:""}.fa-circle-o:before{content:""}.fa-quote-left:before{content:""}.fa-quote-right:before{content:""}.fa-spinner:before{content:""}.fa-circle:before{content:""}.fa-mail-reply:before,.fa-reply:before{content:""}.fa-github-alt:before{content:""}.fa-folder-o:before{content:""}.fa-folder-open-o:before{content:""}.fa-smile-o:before{content:""}.fa-frown-o:before{content:""}.fa-meh-o:before{content:""}.fa-gamepad:before{content:""}.fa-keyboard-o:before{content:""}.fa-flag-o:before{content:""}.fa-flag-checkered:before{content:""}.fa-terminal:before{content:""}.fa-code:before{content:""}.fa-mail-reply-all:before,.fa-reply-all:before{content:""}.fa-star-half-empty:before,.fa-star-half-full:before,.fa-star-half-o:before{content:""}.fa-location-arrow:before{content:""}.fa-crop:before{content:""}.fa-code-fork:before{content:""}.fa-chain-broken:before,.fa-unlink:before{content:""}.fa-question:before{content:""}.fa-info:before{content:""}.fa-exclamation:before{content:""}.fa-superscript:before{content:""}.fa-subscript:before{content:""}.fa-eraser:before{content:""}.fa-puzzle-piece:before{content:""}.fa-microphone:before{content:""}.fa-microphone-slash:before{content:""}.fa-shield:before{content:""}.fa-calendar-o:before{content:""}.fa-fire-extinguisher:before{content:""}.fa-rocket:before{content:""}.fa-maxcdn:before{content:""}.fa-chevron-circle-left:before{content:""}.fa-chevron-circle-right:before{content:""}.fa-chevron-circle-up:before{content:""}.fa-chevron-circle-down:before{content:""}.fa-html5:before{content:""}.fa-css3:before{content:""}.fa-anchor:before{content:""}.fa-unlock-alt:before{content:""}.fa-bullseye:before{content:""}.fa-ellipsis-h:before{content:""}.fa-ellipsis-v:before{content:""}.fa-rss-square:before{content:""}.fa-play-circle:before{content:""}.fa-ticket:before{content:""}.fa-minus-square:before{content:""}.fa-minus-square-o:before,.wy-menu-vertical li.current>a button.toctree-expand:before,.wy-menu-vertical li.on a button.toctree-expand:before{content:""}.fa-level-up:before{content:""}.fa-level-down:before{content:""}.fa-check-square:before{content:""}.fa-pencil-square:before{content:""}.fa-external-link-square:before{content:""}.fa-share-square:before{content:""}.fa-compass:before{content:""}.fa-caret-square-o-down:before,.fa-toggle-down:before{content:""}.fa-caret-square-o-up:before,.fa-toggle-up:before{content:""}.fa-caret-square-o-right:before,.fa-toggle-right:before{content:""}.fa-eur:before,.fa-euro:before{content:""}.fa-gbp:before{content:""}.fa-dollar:before,.fa-usd:before{content:""}.fa-inr:before,.fa-rupee:before{content:""}.fa-cny:before,.fa-jpy:before,.fa-rmb:before,.fa-yen:before{content:""}.fa-rouble:before,.fa-rub:before,.fa-ruble:before{content:""}.fa-krw:before,.fa-won:before{content:""}.fa-bitcoin:before,.fa-btc:before{content:""}.fa-file:before{content:""}.fa-file-text:before{content:""}.fa-sort-alpha-asc:before{content:""}.fa-sort-alpha-desc:before{content:""}.fa-sort-amount-asc:before{content:""}.fa-sort-amount-desc:before{content:""}.fa-sort-numeric-asc:before{content:""}.fa-sort-numeric-desc:before{content:""}.fa-thumbs-up:before{content:""}.fa-thumbs-down:before{content:""}.fa-youtube-square:before{content:""}.fa-youtube:before{content:""}.fa-xing:before{content:""}.fa-xing-square:before{content:""}.fa-youtube-play:before{content:""}.fa-dropbox:before{content:""}.fa-stack-overflow:before{content:""}.fa-instagram:before{content:""}.fa-flickr:before{content:""}.fa-adn:before{content:""}.fa-bitbucket:before,.icon-bitbucket:before{content:""}.fa-bitbucket-square:before{content:""}.fa-tumblr:before{content:""}.fa-tumblr-square:before{content:""}.fa-long-arrow-down:before{content:""}.fa-long-arrow-up:before{content:""}.fa-long-arrow-left:before{content:""}.fa-long-arrow-right:before{content:""}.fa-apple:before{content:""}.fa-windows:before{content:""}.fa-android:before{content:""}.fa-linux:before{content:""}.fa-dribbble:before{content:""}.fa-skype:before{content:""}.fa-foursquare:before{content:""}.fa-trello:before{content:""}.fa-female:before{content:""}.fa-male:before{content:""}.fa-gittip:before,.fa-gratipay:before{content:""}.fa-sun-o:before{content:""}.fa-moon-o:before{content:""}.fa-archive:before{content:""}.fa-bug:before{content:""}.fa-vk:before{content:""}.fa-weibo:before{content:""}.fa-renren:before{content:""}.fa-pagelines:before{content:""}.fa-stack-exchange:before{content:""}.fa-arrow-circle-o-right:before{content:""}.fa-arrow-circle-o-left:before{content:""}.fa-caret-square-o-left:before,.fa-toggle-left:before{content:""}.fa-dot-circle-o:before{content:""}.fa-wheelchair:before{content:""}.fa-vimeo-square:before{content:""}.fa-try:before,.fa-turkish-lira:before{content:""}.fa-plus-square-o:before,.wy-menu-vertical li button.toctree-expand:before{content:""}.fa-space-shuttle:before{content:""}.fa-slack:before{content:""}.fa-envelope-square:before{content:""}.fa-wordpress:before{content:""}.fa-openid:before{content:""}.fa-bank:before,.fa-institution:before,.fa-university:before{content:""}.fa-graduation-cap:before,.fa-mortar-board:before{content:""}.fa-yahoo:before{content:""}.fa-google:before{content:""}.fa-reddit:before{content:""}.fa-reddit-square:before{content:""}.fa-stumbleupon-circle:before{content:""}.fa-stumbleupon:before{content:""}.fa-delicious:before{content:""}.fa-digg:before{content:""}.fa-pied-piper-pp:before{content:""}.fa-pied-piper-alt:before{content:""}.fa-drupal:before{content:""}.fa-joomla:before{content:""}.fa-language:before{content:""}.fa-fax:before{content:""}.fa-building:before{content:""}.fa-child:before{content:""}.fa-paw:before{content:""}.fa-spoon:before{content:""}.fa-cube:before{content:""}.fa-cubes:before{content:""}.fa-behance:before{content:""}.fa-behance-square:before{content:""}.fa-steam:before{content:""}.fa-steam-square:before{content:""}.fa-recycle:before{content:""}.fa-automobile:before,.fa-car:before{content:""}.fa-cab:before,.fa-taxi:before{content:""}.fa-tree:before{content:""}.fa-spotify:before{content:""}.fa-deviantart:before{content:""}.fa-soundcloud:before{content:""}.fa-database:before{content:""}.fa-file-pdf-o:before{content:""}.fa-file-word-o:before{content:""}.fa-file-excel-o:before{content:""}.fa-file-powerpoint-o:before{content:""}.fa-file-image-o:before,.fa-file-photo-o:before,.fa-file-picture-o:before{content:""}.fa-file-archive-o:before,.fa-file-zip-o:before{content:""}.fa-file-audio-o:before,.fa-file-sound-o:before{content:""}.fa-file-movie-o:before,.fa-file-video-o:before{content:""}.fa-file-code-o:before{content:""}.fa-vine:before{content:""}.fa-codepen:before{content:""}.fa-jsfiddle:before{content:""}.fa-life-bouy:before,.fa-life-buoy:before,.fa-life-ring:before,.fa-life-saver:before,.fa-support:before{content:""}.fa-circle-o-notch:before{content:""}.fa-ra:before,.fa-rebel:before,.fa-resistance:before{content:""}.fa-empire:before,.fa-ge:before{content:""}.fa-git-square:before{content:""}.fa-git:before{content:""}.fa-hacker-news:before,.fa-y-combinator-square:before,.fa-yc-square:before{content:""}.fa-tencent-weibo:before{content:""}.fa-qq:before{content:""}.fa-wechat:before,.fa-weixin:before{content:""}.fa-paper-plane:before,.fa-send:before{content:""}.fa-paper-plane-o:before,.fa-send-o:before{content:""}.fa-history:before{content:""}.fa-circle-thin:before{content:""}.fa-header:before{content:""}.fa-paragraph:before{content:""}.fa-sliders:before{content:""}.fa-share-alt:before{content:""}.fa-share-alt-square:before{content:""}.fa-bomb:before{content:""}.fa-futbol-o:before,.fa-soccer-ball-o:before{content:""}.fa-tty:before{content:""}.fa-binoculars:before{content:""}.fa-plug:before{content:""}.fa-slideshare:before{content:""}.fa-twitch:before{content:""}.fa-yelp:before{content:""}.fa-newspaper-o:before{content:""}.fa-wifi:before{content:""}.fa-calculator:before{content:""}.fa-paypal:before{content:""}.fa-google-wallet:before{content:""}.fa-cc-visa:before{content:""}.fa-cc-mastercard:before{content:""}.fa-cc-discover:before{content:""}.fa-cc-amex:before{content:""}.fa-cc-paypal:before{content:""}.fa-cc-stripe:before{content:""}.fa-bell-slash:before{content:""}.fa-bell-slash-o:before{content:""}.fa-trash:before{content:""}.fa-copyright:before{content:""}.fa-at:before{content:""}.fa-eyedropper:before{content:""}.fa-paint-brush:before{content:""}.fa-birthday-cake:before{content:""}.fa-area-chart:before{content:""}.fa-pie-chart:before{content:""}.fa-line-chart:before{content:""}.fa-lastfm:before{content:""}.fa-lastfm-square:before{content:""}.fa-toggle-off:before{content:""}.fa-toggle-on:before{content:""}.fa-bicycle:before{content:""}.fa-bus:before{content:""}.fa-ioxhost:before{content:""}.fa-angellist:before{content:""}.fa-cc:before{content:""}.fa-ils:before,.fa-shekel:before,.fa-sheqel:before{content:""}.fa-meanpath:before{content:""}.fa-buysellads:before{content:""}.fa-connectdevelop:before{content:""}.fa-dashcube:before{content:""}.fa-forumbee:before{content:""}.fa-leanpub:before{content:""}.fa-sellsy:before{content:""}.fa-shirtsinbulk:before{content:""}.fa-simplybuilt:before{content:""}.fa-skyatlas:before{content:""}.fa-cart-plus:before{content:""}.fa-cart-arrow-down:before{content:""}.fa-diamond:before{content:""}.fa-ship:before{content:""}.fa-user-secret:before{content:""}.fa-motorcycle:before{content:""}.fa-street-view:before{content:""}.fa-heartbeat:before{content:""}.fa-venus:before{content:""}.fa-mars:before{content:""}.fa-mercury:before{content:""}.fa-intersex:before,.fa-transgender:before{content:""}.fa-transgender-alt:before{content:""}.fa-venus-double:before{content:""}.fa-mars-double:before{content:""}.fa-venus-mars:before{content:""}.fa-mars-stroke:before{content:""}.fa-mars-stroke-v:before{content:""}.fa-mars-stroke-h:before{content:""}.fa-neuter:before{content:""}.fa-genderless:before{content:""}.fa-facebook-official:before{content:""}.fa-pinterest-p:before{content:""}.fa-whatsapp:before{content:""}.fa-server:before{content:""}.fa-user-plus:before{content:""}.fa-user-times:before{content:""}.fa-bed:before,.fa-hotel:before{content:""}.fa-viacoin:before{content:""}.fa-train:before{content:""}.fa-subway:before{content:""}.fa-medium:before{content:""}.fa-y-combinator:before,.fa-yc:before{content:""}.fa-optin-monster:before{content:""}.fa-opencart:before{content:""}.fa-expeditedssl:before{content:""}.fa-battery-4:before,.fa-battery-full:before,.fa-battery:before{content:""}.fa-battery-3:before,.fa-battery-three-quarters:before{content:""}.fa-battery-2:before,.fa-battery-half:before{content:""}.fa-battery-1:before,.fa-battery-quarter:before{content:""}.fa-battery-0:before,.fa-battery-empty:before{content:""}.fa-mouse-pointer:before{content:""}.fa-i-cursor:before{content:""}.fa-object-group:before{content:""}.fa-object-ungroup:before{content:""}.fa-sticky-note:before{content:""}.fa-sticky-note-o:before{content:""}.fa-cc-jcb:before{content:""}.fa-cc-diners-club:before{content:""}.fa-clone:before{content:""}.fa-balance-scale:before{content:""}.fa-hourglass-o:before{content:""}.fa-hourglass-1:before,.fa-hourglass-start:before{content:""}.fa-hourglass-2:before,.fa-hourglass-half:before{content:""}.fa-hourglass-3:before,.fa-hourglass-end:before{content:""}.fa-hourglass:before{content:""}.fa-hand-grab-o:before,.fa-hand-rock-o:before{content:""}.fa-hand-paper-o:before,.fa-hand-stop-o:before{content:""}.fa-hand-scissors-o:before{content:""}.fa-hand-lizard-o:before{content:""}.fa-hand-spock-o:before{content:""}.fa-hand-pointer-o:before{content:""}.fa-hand-peace-o:before{content:""}.fa-trademark:before{content:""}.fa-registered:before{content:""}.fa-creative-commons:before{content:""}.fa-gg:before{content:""}.fa-gg-circle:before{content:""}.fa-tripadvisor:before{content:""}.fa-odnoklassniki:before{content:""}.fa-odnoklassniki-square:before{content:""}.fa-get-pocket:before{content:""}.fa-wikipedia-w:before{content:""}.fa-safari:before{content:""}.fa-chrome:before{content:""}.fa-firefox:before{content:""}.fa-opera:before{content:""}.fa-internet-explorer:before{content:""}.fa-television:before,.fa-tv:before{content:""}.fa-contao:before{content:""}.fa-500px:before{content:""}.fa-amazon:before{content:""}.fa-calendar-plus-o:before{content:""}.fa-calendar-minus-o:before{content:""}.fa-calendar-times-o:before{content:""}.fa-calendar-check-o:before{content:""}.fa-industry:before{content:""}.fa-map-pin:before{content:""}.fa-map-signs:before{content:""}.fa-map-o:before{content:""}.fa-map:before{content:""}.fa-commenting:before{content:""}.fa-commenting-o:before{content:""}.fa-houzz:before{content:""}.fa-vimeo:before{content:""}.fa-black-tie:before{content:""}.fa-fonticons:before{content:""}.fa-reddit-alien:before{content:""}.fa-edge:before{content:""}.fa-credit-card-alt:before{content:""}.fa-codiepie:before{content:""}.fa-modx:before{content:""}.fa-fort-awesome:before{content:""}.fa-usb:before{content:""}.fa-product-hunt:before{content:""}.fa-mixcloud:before{content:""}.fa-scribd:before{content:""}.fa-pause-circle:before{content:""}.fa-pause-circle-o:before{content:""}.fa-stop-circle:before{content:""}.fa-stop-circle-o:before{content:""}.fa-shopping-bag:before{content:""}.fa-shopping-basket:before{content:""}.fa-hashtag:before{content:""}.fa-bluetooth:before{content:""}.fa-bluetooth-b:before{content:""}.fa-percent:before{content:""}.fa-gitlab:before,.icon-gitlab:before{content:""}.fa-wpbeginner:before{content:""}.fa-wpforms:before{content:""}.fa-envira:before{content:""}.fa-universal-access:before{content:""}.fa-wheelchair-alt:before{content:""}.fa-question-circle-o:before{content:""}.fa-blind:before{content:""}.fa-audio-description:before{content:""}.fa-volume-control-phone:before{content:""}.fa-braille:before{content:""}.fa-assistive-listening-systems:before{content:""}.fa-american-sign-language-interpreting:before,.fa-asl-interpreting:before{content:""}.fa-deaf:before,.fa-deafness:before,.fa-hard-of-hearing:before{content:""}.fa-glide:before{content:""}.fa-glide-g:before{content:""}.fa-sign-language:before,.fa-signing:before{content:""}.fa-low-vision:before{content:""}.fa-viadeo:before{content:""}.fa-viadeo-square:before{content:""}.fa-snapchat:before{content:""}.fa-snapchat-ghost:before{content:""}.fa-snapchat-square:before{content:""}.fa-pied-piper:before{content:""}.fa-first-order:before{content:""}.fa-yoast:before{content:""}.fa-themeisle:before{content:""}.fa-google-plus-circle:before,.fa-google-plus-official:before{content:""}.fa-fa:before,.fa-font-awesome:before{content:""}.fa-handshake-o:before{content:""}.fa-envelope-open:before{content:""}.fa-envelope-open-o:before{content:""}.fa-linode:before{content:""}.fa-address-book:before{content:""}.fa-address-book-o:before{content:""}.fa-address-card:before,.fa-vcard:before{content:""}.fa-address-card-o:before,.fa-vcard-o:before{content:""}.fa-user-circle:before{content:""}.fa-user-circle-o:before{content:""}.fa-user-o:before{content:""}.fa-id-badge:before{content:""}.fa-drivers-license:before,.fa-id-card:before{content:""}.fa-drivers-license-o:before,.fa-id-card-o:before{content:""}.fa-quora:before{content:""}.fa-free-code-camp:before{content:""}.fa-telegram:before{content:""}.fa-thermometer-4:before,.fa-thermometer-full:before,.fa-thermometer:before{content:""}.fa-thermometer-3:before,.fa-thermometer-three-quarters:before{content:""}.fa-thermometer-2:before,.fa-thermometer-half:before{content:""}.fa-thermometer-1:before,.fa-thermometer-quarter:before{content:""}.fa-thermometer-0:before,.fa-thermometer-empty:before{content:""}.fa-shower:before{content:""}.fa-bath:before,.fa-bathtub:before,.fa-s15:before{content:""}.fa-podcast:before{content:""}.fa-window-maximize:before{content:""}.fa-window-minimize:before{content:""}.fa-window-restore:before{content:""}.fa-times-rectangle:before,.fa-window-close:before{content:""}.fa-times-rectangle-o:before,.fa-window-close-o:before{content:""}.fa-bandcamp:before{content:""}.fa-grav:before{content:""}.fa-etsy:before{content:""}.fa-imdb:before{content:""}.fa-ravelry:before{content:""}.fa-eercast:before{content:""}.fa-microchip:before{content:""}.fa-snowflake-o:before{content:""}.fa-superpowers:before{content:""}.fa-wpexplorer:before{content:""}.fa-meetup:before{content:""}.sr-only{position:absolute;width:1px;height:1px;padding:0;margin:-1px;overflow:hidden;clip:rect(0,0,0,0);border:0}.sr-only-focusable:active,.sr-only-focusable:focus{position:static;width:auto;height:auto;margin:0;overflow:visible;clip:auto}.fa,.icon,.rst-content .admonition-title,.rst-content .code-block-caption .headerlink,.rst-content .eqno .headerlink,.rst-content code.download span:first-child,.rst-content dl dt .headerlink,.rst-content h1 .headerlink,.rst-content h2 .headerlink,.rst-content h3 .headerlink,.rst-content h4 .headerlink,.rst-content h5 .headerlink,.rst-content h6 .headerlink,.rst-content p.caption .headerlink,.rst-content p .headerlink,.rst-content table>caption .headerlink,.rst-content tt.download span:first-child,.wy-dropdown .caret,.wy-inline-validate.wy-inline-validate-danger .wy-input-context,.wy-inline-validate.wy-inline-validate-info .wy-input-context,.wy-inline-validate.wy-inline-validate-success .wy-input-context,.wy-inline-validate.wy-inline-validate-warning .wy-input-context,.wy-menu-vertical li.current>a button.toctree-expand,.wy-menu-vertical li.on a button.toctree-expand,.wy-menu-vertical li button.toctree-expand{font-family:inherit}.fa:before,.icon:before,.rst-content .admonition-title:before,.rst-content .code-block-caption .headerlink:before,.rst-content .eqno .headerlink:before,.rst-content code.download span:first-child:before,.rst-content dl dt .headerlink:before,.rst-content h1 .headerlink:before,.rst-content h2 .headerlink:before,.rst-content h3 .headerlink:before,.rst-content h4 .headerlink:before,.rst-content h5 .headerlink:before,.rst-content h6 .headerlink:before,.rst-content p.caption .headerlink:before,.rst-content p .headerlink:before,.rst-content table>caption .headerlink:before,.rst-content tt.download span:first-child:before,.wy-dropdown .caret:before,.wy-inline-validate.wy-inline-validate-danger .wy-input-context:before,.wy-inline-validate.wy-inline-validate-info .wy-input-context:before,.wy-inline-validate.wy-inline-validate-success .wy-input-context:before,.wy-inline-validate.wy-inline-validate-warning .wy-input-context:before,.wy-menu-vertical li.current>a button.toctree-expand:before,.wy-menu-vertical li.on a button.toctree-expand:before,.wy-menu-vertical li button.toctree-expand:before{font-family:FontAwesome;display:inline-block;font-style:normal;font-weight:400;line-height:1;text-decoration:inherit}.rst-content .code-block-caption a .headerlink,.rst-content .eqno a .headerlink,.rst-content a .admonition-title,.rst-content code.download a span:first-child,.rst-content dl dt a .headerlink,.rst-content h1 a .headerlink,.rst-content h2 a .headerlink,.rst-content h3 a .headerlink,.rst-content h4 a .headerlink,.rst-content h5 a .headerlink,.rst-content h6 a .headerlink,.rst-content p.caption a .headerlink,.rst-content p a .headerlink,.rst-content table>caption a .headerlink,.rst-content tt.download a span:first-child,.wy-menu-vertical li.current>a button.toctree-expand,.wy-menu-vertical li.on a button.toctree-expand,.wy-menu-vertical li a button.toctree-expand,a .fa,a .icon,a .rst-content .admonition-title,a .rst-content .code-block-caption .headerlink,a .rst-content .eqno .headerlink,a .rst-content code.download span:first-child,a .rst-content dl dt .headerlink,a .rst-content h1 .headerlink,a .rst-content h2 .headerlink,a .rst-content h3 .headerlink,a .rst-content h4 .headerlink,a .rst-content h5 .headerlink,a .rst-content h6 .headerlink,a .rst-content p.caption .headerlink,a .rst-content p .headerlink,a .rst-content table>caption .headerlink,a .rst-content tt.download span:first-child,a .wy-menu-vertical li button.toctree-expand{display:inline-block;text-decoration:inherit}.btn .fa,.btn .icon,.btn .rst-content .admonition-title,.btn .rst-content .code-block-caption .headerlink,.btn .rst-content .eqno .headerlink,.btn .rst-content code.download span:first-child,.btn .rst-content dl dt .headerlink,.btn .rst-content h1 .headerlink,.btn .rst-content h2 .headerlink,.btn .rst-content h3 .headerlink,.btn .rst-content h4 .headerlink,.btn .rst-content h5 .headerlink,.btn .rst-content h6 .headerlink,.btn .rst-content p .headerlink,.btn .rst-content table>caption .headerlink,.btn .rst-content tt.download span:first-child,.btn .wy-menu-vertical li.current>a button.toctree-expand,.btn .wy-menu-vertical li.on a button.toctree-expand,.btn .wy-menu-vertical li button.toctree-expand,.nav .fa,.nav .icon,.nav .rst-content .admonition-title,.nav .rst-content .code-block-caption .headerlink,.nav .rst-content .eqno .headerlink,.nav .rst-content code.download span:first-child,.nav .rst-content dl dt .headerlink,.nav .rst-content h1 .headerlink,.nav .rst-content h2 .headerlink,.nav .rst-content h3 .headerlink,.nav .rst-content h4 .headerlink,.nav .rst-content h5 .headerlink,.nav .rst-content h6 .headerlink,.nav .rst-content p .headerlink,.nav .rst-content table>caption .headerlink,.nav .rst-content tt.download span:first-child,.nav .wy-menu-vertical li.current>a button.toctree-expand,.nav .wy-menu-vertical li.on a button.toctree-expand,.nav .wy-menu-vertical li button.toctree-expand,.rst-content .btn .admonition-title,.rst-content .code-block-caption .btn .headerlink,.rst-content .code-block-caption .nav .headerlink,.rst-content .eqno .btn .headerlink,.rst-content .eqno .nav .headerlink,.rst-content .nav .admonition-title,.rst-content code.download .btn span:first-child,.rst-content code.download .nav span:first-child,.rst-content dl dt .btn .headerlink,.rst-content dl dt .nav .headerlink,.rst-content h1 .btn .headerlink,.rst-content h1 .nav .headerlink,.rst-content h2 .btn .headerlink,.rst-content h2 .nav .headerlink,.rst-content h3 .btn .headerlink,.rst-content h3 .nav .headerlink,.rst-content h4 .btn .headerlink,.rst-content h4 .nav .headerlink,.rst-content h5 .btn .headerlink,.rst-content h5 .nav .headerlink,.rst-content h6 .btn .headerlink,.rst-content h6 .nav .headerlink,.rst-content p .btn .headerlink,.rst-content p .nav .headerlink,.rst-content table>caption .btn .headerlink,.rst-content table>caption .nav .headerlink,.rst-content tt.download .btn span:first-child,.rst-content tt.download .nav span:first-child,.wy-menu-vertical li .btn button.toctree-expand,.wy-menu-vertical li.current>a .btn button.toctree-expand,.wy-menu-vertical li.current>a .nav button.toctree-expand,.wy-menu-vertical li .nav button.toctree-expand,.wy-menu-vertical li.on a .btn button.toctree-expand,.wy-menu-vertical li.on a .nav button.toctree-expand{display:inline}.btn .fa-large.icon,.btn .fa.fa-large,.btn .rst-content .code-block-caption .fa-large.headerlink,.btn .rst-content .eqno .fa-large.headerlink,.btn .rst-content .fa-large.admonition-title,.btn .rst-content code.download span.fa-large:first-child,.btn .rst-content dl dt .fa-large.headerlink,.btn .rst-content h1 .fa-large.headerlink,.btn .rst-content h2 .fa-large.headerlink,.btn .rst-content h3 .fa-large.headerlink,.btn .rst-content h4 .fa-large.headerlink,.btn .rst-content h5 .fa-large.headerlink,.btn .rst-content h6 .fa-large.headerlink,.btn .rst-content p .fa-large.headerlink,.btn .rst-content table>caption .fa-large.headerlink,.btn .rst-content tt.download span.fa-large:first-child,.btn .wy-menu-vertical li button.fa-large.toctree-expand,.nav .fa-large.icon,.nav .fa.fa-large,.nav .rst-content .code-block-caption .fa-large.headerlink,.nav .rst-content .eqno .fa-large.headerlink,.nav .rst-content .fa-large.admonition-title,.nav .rst-content code.download span.fa-large:first-child,.nav .rst-content dl dt .fa-large.headerlink,.nav .rst-content h1 .fa-large.headerlink,.nav .rst-content h2 .fa-large.headerlink,.nav .rst-content h3 .fa-large.headerlink,.nav .rst-content h4 .fa-large.headerlink,.nav .rst-content h5 .fa-large.headerlink,.nav .rst-content h6 .fa-large.headerlink,.nav .rst-content p .fa-large.headerlink,.nav .rst-content table>caption .fa-large.headerlink,.nav .rst-content tt.download span.fa-large:first-child,.nav .wy-menu-vertical li button.fa-large.toctree-expand,.rst-content .btn .fa-large.admonition-title,.rst-content .code-block-caption .btn .fa-large.headerlink,.rst-content .code-block-caption .nav .fa-large.headerlink,.rst-content .eqno .btn .fa-large.headerlink,.rst-content .eqno .nav .fa-large.headerlink,.rst-content .nav .fa-large.admonition-title,.rst-content code.download .btn span.fa-large:first-child,.rst-content code.download .nav span.fa-large:first-child,.rst-content dl dt .btn .fa-large.headerlink,.rst-content dl dt .nav .fa-large.headerlink,.rst-content h1 .btn .fa-large.headerlink,.rst-content h1 .nav .fa-large.headerlink,.rst-content h2 .btn .fa-large.headerlink,.rst-content h2 .nav .fa-large.headerlink,.rst-content h3 .btn .fa-large.headerlink,.rst-content h3 .nav .fa-large.headerlink,.rst-content h4 .btn .fa-large.headerlink,.rst-content h4 .nav .fa-large.headerlink,.rst-content h5 .btn .fa-large.headerlink,.rst-content h5 .nav .fa-large.headerlink,.rst-content h6 .btn .fa-large.headerlink,.rst-content h6 .nav .fa-large.headerlink,.rst-content p .btn .fa-large.headerlink,.rst-content p .nav .fa-large.headerlink,.rst-content table>caption .btn .fa-large.headerlink,.rst-content table>caption .nav .fa-large.headerlink,.rst-content tt.download .btn span.fa-large:first-child,.rst-content tt.download .nav span.fa-large:first-child,.wy-menu-vertical li .btn button.fa-large.toctree-expand,.wy-menu-vertical li .nav button.fa-large.toctree-expand{line-height:.9em}.btn .fa-spin.icon,.btn .fa.fa-spin,.btn .rst-content .code-block-caption .fa-spin.headerlink,.btn .rst-content .eqno .fa-spin.headerlink,.btn .rst-content .fa-spin.admonition-title,.btn .rst-content code.download span.fa-spin:first-child,.btn .rst-content dl dt .fa-spin.headerlink,.btn .rst-content h1 .fa-spin.headerlink,.btn .rst-content h2 .fa-spin.headerlink,.btn .rst-content h3 .fa-spin.headerlink,.btn .rst-content h4 .fa-spin.headerlink,.btn .rst-content h5 .fa-spin.headerlink,.btn .rst-content h6 .fa-spin.headerlink,.btn .rst-content p .fa-spin.headerlink,.btn .rst-content table>caption .fa-spin.headerlink,.btn .rst-content tt.download span.fa-spin:first-child,.btn .wy-menu-vertical li button.fa-spin.toctree-expand,.nav .fa-spin.icon,.nav .fa.fa-spin,.nav .rst-content .code-block-caption .fa-spin.headerlink,.nav .rst-content .eqno .fa-spin.headerlink,.nav .rst-content .fa-spin.admonition-title,.nav .rst-content code.download span.fa-spin:first-child,.nav .rst-content dl dt .fa-spin.headerlink,.nav .rst-content h1 .fa-spin.headerlink,.nav .rst-content h2 .fa-spin.headerlink,.nav .rst-content h3 .fa-spin.headerlink,.nav .rst-content h4 .fa-spin.headerlink,.nav .rst-content h5 .fa-spin.headerlink,.nav .rst-content h6 .fa-spin.headerlink,.nav .rst-content p .fa-spin.headerlink,.nav .rst-content table>caption .fa-spin.headerlink,.nav .rst-content tt.download span.fa-spin:first-child,.nav .wy-menu-vertical li button.fa-spin.toctree-expand,.rst-content .btn .fa-spin.admonition-title,.rst-content .code-block-caption .btn .fa-spin.headerlink,.rst-content .code-block-caption .nav .fa-spin.headerlink,.rst-content .eqno .btn .fa-spin.headerlink,.rst-content .eqno .nav .fa-spin.headerlink,.rst-content .nav .fa-spin.admonition-title,.rst-content code.download .btn span.fa-spin:first-child,.rst-content code.download .nav span.fa-spin:first-child,.rst-content dl dt .btn .fa-spin.headerlink,.rst-content dl dt .nav .fa-spin.headerlink,.rst-content h1 .btn .fa-spin.headerlink,.rst-content h1 .nav .fa-spin.headerlink,.rst-content h2 .btn .fa-spin.headerlink,.rst-content h2 .nav .fa-spin.headerlink,.rst-content h3 .btn .fa-spin.headerlink,.rst-content h3 .nav .fa-spin.headerlink,.rst-content h4 .btn .fa-spin.headerlink,.rst-content h4 .nav .fa-spin.headerlink,.rst-content h5 .btn .fa-spin.headerlink,.rst-content h5 .nav .fa-spin.headerlink,.rst-content h6 .btn .fa-spin.headerlink,.rst-content h6 .nav .fa-spin.headerlink,.rst-content p .btn .fa-spin.headerlink,.rst-content p .nav .fa-spin.headerlink,.rst-content table>caption .btn .fa-spin.headerlink,.rst-content table>caption .nav .fa-spin.headerlink,.rst-content tt.download .btn span.fa-spin:first-child,.rst-content tt.download .nav span.fa-spin:first-child,.wy-menu-vertical li .btn button.fa-spin.toctree-expand,.wy-menu-vertical li .nav button.fa-spin.toctree-expand{display:inline-block}.btn.fa:before,.btn.icon:before,.rst-content .btn.admonition-title:before,.rst-content .code-block-caption .btn.headerlink:before,.rst-content .eqno .btn.headerlink:before,.rst-content code.download span.btn:first-child:before,.rst-content dl dt .btn.headerlink:before,.rst-content h1 .btn.headerlink:before,.rst-content h2 .btn.headerlink:before,.rst-content h3 .btn.headerlink:before,.rst-content h4 .btn.headerlink:before,.rst-content h5 .btn.headerlink:before,.rst-content h6 .btn.headerlink:before,.rst-content p .btn.headerlink:before,.rst-content table>caption .btn.headerlink:before,.rst-content tt.download span.btn:first-child:before,.wy-menu-vertical li button.btn.toctree-expand:before{opacity:.5;-webkit-transition:opacity .05s ease-in;-moz-transition:opacity .05s ease-in;transition:opacity .05s ease-in}.btn.fa:hover:before,.btn.icon:hover:before,.rst-content .btn.admonition-title:hover:before,.rst-content .code-block-caption .btn.headerlink:hover:before,.rst-content .eqno .btn.headerlink:hover:before,.rst-content code.download span.btn:first-child:hover:before,.rst-content dl dt .btn.headerlink:hover:before,.rst-content h1 .btn.headerlink:hover:before,.rst-content h2 .btn.headerlink:hover:before,.rst-content h3 .btn.headerlink:hover:before,.rst-content h4 .btn.headerlink:hover:before,.rst-content h5 .btn.headerlink:hover:before,.rst-content h6 .btn.headerlink:hover:before,.rst-content p .btn.headerlink:hover:before,.rst-content table>caption .btn.headerlink:hover:before,.rst-content tt.download span.btn:first-child:hover:before,.wy-menu-vertical li button.btn.toctree-expand:hover:before{opacity:1}.btn-mini .fa:before,.btn-mini .icon:before,.btn-mini .rst-content .admonition-title:before,.btn-mini .rst-content .code-block-caption .headerlink:before,.btn-mini .rst-content .eqno .headerlink:before,.btn-mini .rst-content code.download span:first-child:before,.btn-mini .rst-content dl dt .headerlink:before,.btn-mini .rst-content h1 .headerlink:before,.btn-mini .rst-content h2 .headerlink:before,.btn-mini .rst-content h3 .headerlink:before,.btn-mini .rst-content h4 .headerlink:before,.btn-mini .rst-content h5 .headerlink:before,.btn-mini .rst-content h6 .headerlink:before,.btn-mini .rst-content p .headerlink:before,.btn-mini .rst-content table>caption .headerlink:before,.btn-mini .rst-content tt.download span:first-child:before,.btn-mini .wy-menu-vertical li button.toctree-expand:before,.rst-content .btn-mini .admonition-title:before,.rst-content .code-block-caption .btn-mini .headerlink:before,.rst-content .eqno .btn-mini .headerlink:before,.rst-content code.download .btn-mini span:first-child:before,.rst-content dl dt .btn-mini .headerlink:before,.rst-content h1 .btn-mini .headerlink:before,.rst-content h2 .btn-mini .headerlink:before,.rst-content h3 .btn-mini .headerlink:before,.rst-content h4 .btn-mini .headerlink:before,.rst-content h5 .btn-mini .headerlink:before,.rst-content h6 .btn-mini .headerlink:before,.rst-content p .btn-mini .headerlink:before,.rst-content table>caption .btn-mini .headerlink:before,.rst-content tt.download .btn-mini span:first-child:before,.wy-menu-vertical li .btn-mini button.toctree-expand:before{font-size:14px;vertical-align:-15%}.rst-content .admonition,.rst-content .admonition-todo,.rst-content .attention,.rst-content .caution,.rst-content .danger,.rst-content .error,.rst-content .hint,.rst-content .important,.rst-content .note,.rst-content .seealso,.rst-content .tip,.rst-content .warning,.wy-alert{padding:12px;line-height:24px;margin-bottom:24px;background:#e7f2fa}.rst-content .admonition-title,.wy-alert-title{font-weight:700;display:block;color:#fff;background:#6ab0de;padding:6px 12px;margin:-12px -12px 12px}.rst-content .danger,.rst-content .error,.rst-content .wy-alert-danger.admonition,.rst-content .wy-alert-danger.admonition-todo,.rst-content .wy-alert-danger.attention,.rst-content .wy-alert-danger.caution,.rst-content .wy-alert-danger.hint,.rst-content .wy-alert-danger.important,.rst-content .wy-alert-danger.note,.rst-content .wy-alert-danger.seealso,.rst-content .wy-alert-danger.tip,.rst-content .wy-alert-danger.warning,.wy-alert.wy-alert-danger{background:#fdf3f2}.rst-content .danger .admonition-title,.rst-content .danger .wy-alert-title,.rst-content .error .admonition-title,.rst-content .error .wy-alert-title,.rst-content .wy-alert-danger.admonition-todo .admonition-title,.rst-content .wy-alert-danger.admonition-todo .wy-alert-title,.rst-content .wy-alert-danger.admonition .admonition-title,.rst-content .wy-alert-danger.admonition .wy-alert-title,.rst-content .wy-alert-danger.attention .admonition-title,.rst-content .wy-alert-danger.attention .wy-alert-title,.rst-content .wy-alert-danger.caution .admonition-title,.rst-content .wy-alert-danger.caution .wy-alert-title,.rst-content .wy-alert-danger.hint .admonition-title,.rst-content .wy-alert-danger.hint .wy-alert-title,.rst-content .wy-alert-danger.important .admonition-title,.rst-content .wy-alert-danger.important .wy-alert-title,.rst-content .wy-alert-danger.note .admonition-title,.rst-content .wy-alert-danger.note .wy-alert-title,.rst-content .wy-alert-danger.seealso .admonition-title,.rst-content .wy-alert-danger.seealso .wy-alert-title,.rst-content .wy-alert-danger.tip .admonition-title,.rst-content .wy-alert-danger.tip .wy-alert-title,.rst-content .wy-alert-danger.warning .admonition-title,.rst-content .wy-alert-danger.warning .wy-alert-title,.rst-content .wy-alert.wy-alert-danger .admonition-title,.wy-alert.wy-alert-danger .rst-content .admonition-title,.wy-alert.wy-alert-danger .wy-alert-title{background:#f29f97}.rst-content .admonition-todo,.rst-content .attention,.rst-content .caution,.rst-content .warning,.rst-content .wy-alert-warning.admonition,.rst-content .wy-alert-warning.danger,.rst-content .wy-alert-warning.error,.rst-content .wy-alert-warning.hint,.rst-content .wy-alert-warning.important,.rst-content .wy-alert-warning.note,.rst-content .wy-alert-warning.seealso,.rst-content .wy-alert-warning.tip,.wy-alert.wy-alert-warning{background:#ffedcc}.rst-content .admonition-todo .admonition-title,.rst-content .admonition-todo .wy-alert-title,.rst-content .attention .admonition-title,.rst-content .attention .wy-alert-title,.rst-content .caution .admonition-title,.rst-content .caution .wy-alert-title,.rst-content .warning .admonition-title,.rst-content .warning .wy-alert-title,.rst-content .wy-alert-warning.admonition .admonition-title,.rst-content .wy-alert-warning.admonition .wy-alert-title,.rst-content .wy-alert-warning.danger .admonition-title,.rst-content .wy-alert-warning.danger .wy-alert-title,.rst-content .wy-alert-warning.error .admonition-title,.rst-content .wy-alert-warning.error .wy-alert-title,.rst-content .wy-alert-warning.hint .admonition-title,.rst-content .wy-alert-warning.hint .wy-alert-title,.rst-content .wy-alert-warning.important .admonition-title,.rst-content .wy-alert-warning.important .wy-alert-title,.rst-content .wy-alert-warning.note .admonition-title,.rst-content .wy-alert-warning.note .wy-alert-title,.rst-content .wy-alert-warning.seealso .admonition-title,.rst-content .wy-alert-warning.seealso .wy-alert-title,.rst-content .wy-alert-warning.tip .admonition-title,.rst-content .wy-alert-warning.tip .wy-alert-title,.rst-content .wy-alert.wy-alert-warning .admonition-title,.wy-alert.wy-alert-warning .rst-content .admonition-title,.wy-alert.wy-alert-warning .wy-alert-title{background:#f0b37e}.rst-content .note,.rst-content .seealso,.rst-content .wy-alert-info.admonition,.rst-content .wy-alert-info.admonition-todo,.rst-content .wy-alert-info.attention,.rst-content .wy-alert-info.caution,.rst-content .wy-alert-info.danger,.rst-content .wy-alert-info.error,.rst-content .wy-alert-info.hint,.rst-content .wy-alert-info.important,.rst-content .wy-alert-info.tip,.rst-content .wy-alert-info.warning,.wy-alert.wy-alert-info{background:#e7f2fa}.rst-content .note .admonition-title,.rst-content .note .wy-alert-title,.rst-content .seealso .admonition-title,.rst-content .seealso .wy-alert-title,.rst-content .wy-alert-info.admonition-todo .admonition-title,.rst-content .wy-alert-info.admonition-todo .wy-alert-title,.rst-content .wy-alert-info.admonition .admonition-title,.rst-content .wy-alert-info.admonition .wy-alert-title,.rst-content .wy-alert-info.attention .admonition-title,.rst-content .wy-alert-info.attention .wy-alert-title,.rst-content .wy-alert-info.caution .admonition-title,.rst-content .wy-alert-info.caution .wy-alert-title,.rst-content .wy-alert-info.danger .admonition-title,.rst-content .wy-alert-info.danger .wy-alert-title,.rst-content .wy-alert-info.error .admonition-title,.rst-content .wy-alert-info.error .wy-alert-title,.rst-content .wy-alert-info.hint .admonition-title,.rst-content .wy-alert-info.hint .wy-alert-title,.rst-content .wy-alert-info.important .admonition-title,.rst-content .wy-alert-info.important .wy-alert-title,.rst-content .wy-alert-info.tip .admonition-title,.rst-content .wy-alert-info.tip .wy-alert-title,.rst-content .wy-alert-info.warning .admonition-title,.rst-content .wy-alert-info.warning .wy-alert-title,.rst-content .wy-alert.wy-alert-info .admonition-title,.wy-alert.wy-alert-info .rst-content .admonition-title,.wy-alert.wy-alert-info .wy-alert-title{background:#6ab0de}.rst-content .hint,.rst-content .important,.rst-content .tip,.rst-content .wy-alert-success.admonition,.rst-content .wy-alert-success.admonition-todo,.rst-content .wy-alert-success.attention,.rst-content .wy-alert-success.caution,.rst-content .wy-alert-success.danger,.rst-content .wy-alert-success.error,.rst-content .wy-alert-success.note,.rst-content .wy-alert-success.seealso,.rst-content .wy-alert-success.warning,.wy-alert.wy-alert-success{background:#dbfaf4}.rst-content .hint .admonition-title,.rst-content .hint .wy-alert-title,.rst-content .important .admonition-title,.rst-content .important .wy-alert-title,.rst-content .tip .admonition-title,.rst-content .tip .wy-alert-title,.rst-content .wy-alert-success.admonition-todo .admonition-title,.rst-content .wy-alert-success.admonition-todo .wy-alert-title,.rst-content .wy-alert-success.admonition .admonition-title,.rst-content .wy-alert-success.admonition .wy-alert-title,.rst-content .wy-alert-success.attention .admonition-title,.rst-content .wy-alert-success.attention .wy-alert-title,.rst-content .wy-alert-success.caution .admonition-title,.rst-content .wy-alert-success.caution .wy-alert-title,.rst-content .wy-alert-success.danger .admonition-title,.rst-content .wy-alert-success.danger .wy-alert-title,.rst-content .wy-alert-success.error .admonition-title,.rst-content .wy-alert-success.error .wy-alert-title,.rst-content .wy-alert-success.note .admonition-title,.rst-content .wy-alert-success.note .wy-alert-title,.rst-content .wy-alert-success.seealso .admonition-title,.rst-content .wy-alert-success.seealso .wy-alert-title,.rst-content .wy-alert-success.warning .admonition-title,.rst-content .wy-alert-success.warning .wy-alert-title,.rst-content .wy-alert.wy-alert-success .admonition-title,.wy-alert.wy-alert-success .rst-content .admonition-title,.wy-alert.wy-alert-success .wy-alert-title{background:#1abc9c}.rst-content .wy-alert-neutral.admonition,.rst-content .wy-alert-neutral.admonition-todo,.rst-content .wy-alert-neutral.attention,.rst-content .wy-alert-neutral.caution,.rst-content .wy-alert-neutral.danger,.rst-content .wy-alert-neutral.error,.rst-content .wy-alert-neutral.hint,.rst-content .wy-alert-neutral.important,.rst-content .wy-alert-neutral.note,.rst-content .wy-alert-neutral.seealso,.rst-content .wy-alert-neutral.tip,.rst-content .wy-alert-neutral.warning,.wy-alert.wy-alert-neutral{background:#f3f6f6}.rst-content .wy-alert-neutral.admonition-todo .admonition-title,.rst-content .wy-alert-neutral.admonition-todo .wy-alert-title,.rst-content .wy-alert-neutral.admonition .admonition-title,.rst-content .wy-alert-neutral.admonition .wy-alert-title,.rst-content .wy-alert-neutral.attention .admonition-title,.rst-content .wy-alert-neutral.attention .wy-alert-title,.rst-content .wy-alert-neutral.caution .admonition-title,.rst-content .wy-alert-neutral.caution .wy-alert-title,.rst-content .wy-alert-neutral.danger .admonition-title,.rst-content .wy-alert-neutral.danger .wy-alert-title,.rst-content .wy-alert-neutral.error .admonition-title,.rst-content .wy-alert-neutral.error .wy-alert-title,.rst-content .wy-alert-neutral.hint .admonition-title,.rst-content .wy-alert-neutral.hint .wy-alert-title,.rst-content .wy-alert-neutral.important .admonition-title,.rst-content .wy-alert-neutral.important .wy-alert-title,.rst-content .wy-alert-neutral.note .admonition-title,.rst-content .wy-alert-neutral.note .wy-alert-title,.rst-content .wy-alert-neutral.seealso .admonition-title,.rst-content .wy-alert-neutral.seealso .wy-alert-title,.rst-content .wy-alert-neutral.tip .admonition-title,.rst-content .wy-alert-neutral.tip .wy-alert-title,.rst-content .wy-alert-neutral.warning .admonition-title,.rst-content .wy-alert-neutral.warning .wy-alert-title,.rst-content .wy-alert.wy-alert-neutral .admonition-title,.wy-alert.wy-alert-neutral .rst-content .admonition-title,.wy-alert.wy-alert-neutral .wy-alert-title{color:#404040;background:#e1e4e5}.rst-content .wy-alert-neutral.admonition-todo a,.rst-content .wy-alert-neutral.admonition a,.rst-content .wy-alert-neutral.attention a,.rst-content .wy-alert-neutral.caution a,.rst-content .wy-alert-neutral.danger a,.rst-content .wy-alert-neutral.error a,.rst-content .wy-alert-neutral.hint a,.rst-content .wy-alert-neutral.important a,.rst-content .wy-alert-neutral.note a,.rst-content .wy-alert-neutral.seealso a,.rst-content .wy-alert-neutral.tip a,.rst-content .wy-alert-neutral.warning a,.wy-alert.wy-alert-neutral a{color:#2980b9}.rst-content .admonition-todo p:last-child,.rst-content .admonition p:last-child,.rst-content .attention p:last-child,.rst-content .caution p:last-child,.rst-content .danger p:last-child,.rst-content .error p:last-child,.rst-content .hint p:last-child,.rst-content .important p:last-child,.rst-content .note p:last-child,.rst-content .seealso p:last-child,.rst-content .tip p:last-child,.rst-content .warning p:last-child,.wy-alert p:last-child{margin-bottom:0}.wy-tray-container{position:fixed;bottom:0;left:0;z-index:600}.wy-tray-container li{display:block;width:300px;background:transparent;color:#fff;text-align:center;box-shadow:0 5px 5px 0 rgba(0,0,0,.1);padding:0 24px;min-width:20%;opacity:0;height:0;line-height:56px;overflow:hidden;-webkit-transition:all .3s ease-in;-moz-transition:all .3s ease-in;transition:all .3s ease-in}.wy-tray-container li.wy-tray-item-success{background:#27ae60}.wy-tray-container li.wy-tray-item-info{background:#2980b9}.wy-tray-container li.wy-tray-item-warning{background:#e67e22}.wy-tray-container li.wy-tray-item-danger{background:#e74c3c}.wy-tray-container li.on{opacity:1;height:56px}@media screen and (max-width:768px){.wy-tray-container{bottom:auto;top:0;width:100%}.wy-tray-container li{width:100%}}button{font-size:100%;margin:0;vertical-align:baseline;*vertical-align:middle;cursor:pointer;line-height:normal;-webkit-appearance:button;*overflow:visible}button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}button[disabled]{cursor:default}.btn{display:inline-block;border-radius:2px;line-height:normal;white-space:nowrap;text-align:center;cursor:pointer;font-size:100%;padding:6px 12px 8px;color:#fff;border:1px solid rgba(0,0,0,.1);background-color:#27ae60;text-decoration:none;font-weight:400;font-family:Lato,proxima-nova,Helvetica Neue,Arial,sans-serif;box-shadow:inset 0 1px 2px -1px hsla(0,0%,100%,.5),inset 0 -2px 0 0 rgba(0,0,0,.1);outline-none:false;vertical-align:middle;*display:inline;zoom:1;-webkit-user-drag:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-transition:all .1s linear;-moz-transition:all .1s linear;transition:all .1s linear}.btn-hover{background:#2e8ece;color:#fff}.btn:hover{background:#2cc36b;color:#fff}.btn:focus{background:#2cc36b;outline:0}.btn:active{box-shadow:inset 0 -1px 0 0 rgba(0,0,0,.05),inset 0 2px 0 0 rgba(0,0,0,.1);padding:8px 12px 6px}.btn:visited{color:#fff}.btn-disabled,.btn-disabled:active,.btn-disabled:focus,.btn-disabled:hover,.btn:disabled{background-image:none;filter:progid:DXImageTransform.Microsoft.gradient(enabled = false);filter:alpha(opacity=40);opacity:.4;cursor:not-allowed;box-shadow:none}.btn::-moz-focus-inner{padding:0;border:0}.btn-small{font-size:80%}.btn-info{background-color:#2980b9!important}.btn-info:hover{background-color:#2e8ece!important}.btn-neutral{background-color:#f3f6f6!important;color:#404040!important}.btn-neutral:hover{background-color:#e5ebeb!important;color:#404040}.btn-neutral:visited{color:#404040!important}.btn-success{background-color:#27ae60!important}.btn-success:hover{background-color:#295!important}.btn-danger{background-color:#e74c3c!important}.btn-danger:hover{background-color:#ea6153!important}.btn-warning{background-color:#e67e22!important}.btn-warning:hover{background-color:#e98b39!important}.btn-invert{background-color:#222}.btn-invert:hover{background-color:#2f2f2f!important}.btn-link{background-color:transparent!important;color:#2980b9;box-shadow:none;border-color:transparent!important}.btn-link:active,.btn-link:hover{background-color:transparent!important;color:#409ad5!important;box-shadow:none}.btn-link:visited{color:#9b59b6}.wy-btn-group .btn,.wy-control .btn{vertical-align:middle}.wy-btn-group{margin-bottom:24px;*zoom:1}.wy-btn-group:after,.wy-btn-group:before{display:table;content:""}.wy-btn-group:after{clear:both}.wy-dropdown{position:relative;display:inline-block}.wy-dropdown-active .wy-dropdown-menu{display:block}.wy-dropdown-menu{position:absolute;left:0;display:none;float:left;top:100%;min-width:100%;background:#fcfcfc;z-index:100;border:1px solid #cfd7dd;box-shadow:0 2px 2px 0 rgba(0,0,0,.1);padding:12px}.wy-dropdown-menu>dd>a{display:block;clear:both;color:#404040;white-space:nowrap;font-size:90%;padding:0 12px;cursor:pointer}.wy-dropdown-menu>dd>a:hover{background:#2980b9;color:#fff}.wy-dropdown-menu>dd.divider{border-top:1px solid #cfd7dd;margin:6px 0}.wy-dropdown-menu>dd.search{padding-bottom:12px}.wy-dropdown-menu>dd.search input[type=search]{width:100%}.wy-dropdown-menu>dd.call-to-action{background:#e3e3e3;text-transform:uppercase;font-weight:500;font-size:80%}.wy-dropdown-menu>dd.call-to-action:hover{background:#e3e3e3}.wy-dropdown-menu>dd.call-to-action .btn{color:#fff}.wy-dropdown.wy-dropdown-up .wy-dropdown-menu{bottom:100%;top:auto;left:auto;right:0}.wy-dropdown.wy-dropdown-bubble .wy-dropdown-menu{background:#fcfcfc;margin-top:2px}.wy-dropdown.wy-dropdown-bubble .wy-dropdown-menu a{padding:6px 12px}.wy-dropdown.wy-dropdown-bubble .wy-dropdown-menu a:hover{background:#2980b9;color:#fff}.wy-dropdown.wy-dropdown-left .wy-dropdown-menu{right:0;left:auto;text-align:right}.wy-dropdown-arrow:before{content:" ";border-bottom:5px solid #f5f5f5;border-left:5px solid transparent;border-right:5px solid transparent;position:absolute;display:block;top:-4px;left:50%;margin-left:-3px}.wy-dropdown-arrow.wy-dropdown-arrow-left:before{left:11px}.wy-form-stacked select{display:block}.wy-form-aligned .wy-help-inline,.wy-form-aligned input,.wy-form-aligned label,.wy-form-aligned select,.wy-form-aligned textarea{display:inline-block;*display:inline;*zoom:1;vertical-align:middle}.wy-form-aligned .wy-control-group>label{display:inline-block;vertical-align:middle;width:10em;margin:6px 12px 0 0;float:left}.wy-form-aligned .wy-control{float:left}.wy-form-aligned .wy-control label{display:block}.wy-form-aligned .wy-control select{margin-top:6px}fieldset{margin:0}fieldset,legend{border:0;padding:0}legend{width:100%;white-space:normal;margin-bottom:24px;font-size:150%;*margin-left:-7px}label,legend{display:block}label{margin:0 0 .3125em;color:#333;font-size:90%}input,select,textarea{font-size:100%;margin:0;vertical-align:baseline;*vertical-align:middle}.wy-control-group{margin-bottom:24px;max-width:1200px;margin-left:auto;margin-right:auto;*zoom:1}.wy-control-group:after,.wy-control-group:before{display:table;content:""}.wy-control-group:after{clear:both}.wy-control-group.wy-control-group-required>label:after{content:" *";color:#e74c3c}.wy-control-group .wy-form-full,.wy-control-group .wy-form-halves,.wy-control-group .wy-form-thirds{padding-bottom:12px}.wy-control-group .wy-form-full input[type=color],.wy-control-group .wy-form-full input[type=date],.wy-control-group .wy-form-full input[type=datetime-local],.wy-control-group .wy-form-full input[type=datetime],.wy-control-group .wy-form-full input[type=email],.wy-control-group .wy-form-full input[type=month],.wy-control-group .wy-form-full input[type=number],.wy-control-group .wy-form-full input[type=password],.wy-control-group .wy-form-full input[type=search],.wy-control-group .wy-form-full input[type=tel],.wy-control-group .wy-form-full input[type=text],.wy-control-group .wy-form-full input[type=time],.wy-control-group .wy-form-full input[type=url],.wy-control-group .wy-form-full input[type=week],.wy-control-group .wy-form-full select,.wy-control-group .wy-form-halves input[type=color],.wy-control-group .wy-form-halves input[type=date],.wy-control-group .wy-form-halves input[type=datetime-local],.wy-control-group .wy-form-halves input[type=datetime],.wy-control-group .wy-form-halves input[type=email],.wy-control-group .wy-form-halves input[type=month],.wy-control-group .wy-form-halves input[type=number],.wy-control-group .wy-form-halves input[type=password],.wy-control-group .wy-form-halves input[type=search],.wy-control-group .wy-form-halves input[type=tel],.wy-control-group .wy-form-halves input[type=text],.wy-control-group .wy-form-halves input[type=time],.wy-control-group .wy-form-halves input[type=url],.wy-control-group .wy-form-halves input[type=week],.wy-control-group .wy-form-halves select,.wy-control-group .wy-form-thirds input[type=color],.wy-control-group .wy-form-thirds input[type=date],.wy-control-group .wy-form-thirds input[type=datetime-local],.wy-control-group .wy-form-thirds input[type=datetime],.wy-control-group .wy-form-thirds input[type=email],.wy-control-group .wy-form-thirds input[type=month],.wy-control-group .wy-form-thirds input[type=number],.wy-control-group .wy-form-thirds input[type=password],.wy-control-group .wy-form-thirds input[type=search],.wy-control-group .wy-form-thirds input[type=tel],.wy-control-group .wy-form-thirds input[type=text],.wy-control-group .wy-form-thirds input[type=time],.wy-control-group .wy-form-thirds input[type=url],.wy-control-group .wy-form-thirds input[type=week],.wy-control-group .wy-form-thirds select{width:100%}.wy-control-group .wy-form-full{float:left;display:block;width:100%;margin-right:0}.wy-control-group .wy-form-full:last-child{margin-right:0}.wy-control-group .wy-form-halves{float:left;display:block;margin-right:2.35765%;width:48.82117%}.wy-control-group .wy-form-halves:last-child,.wy-control-group .wy-form-halves:nth-of-type(2n){margin-right:0}.wy-control-group .wy-form-halves:nth-of-type(odd){clear:left}.wy-control-group .wy-form-thirds{float:left;display:block;margin-right:2.35765%;width:31.76157%}.wy-control-group .wy-form-thirds:last-child,.wy-control-group .wy-form-thirds:nth-of-type(3n){margin-right:0}.wy-control-group .wy-form-thirds:nth-of-type(3n+1){clear:left}.wy-control-group.wy-control-group-no-input .wy-control,.wy-control-no-input{margin:6px 0 0;font-size:90%}.wy-control-no-input{display:inline-block}.wy-control-group.fluid-input input[type=color],.wy-control-group.fluid-input input[type=date],.wy-control-group.fluid-input input[type=datetime-local],.wy-control-group.fluid-input input[type=datetime],.wy-control-group.fluid-input input[type=email],.wy-control-group.fluid-input input[type=month],.wy-control-group.fluid-input input[type=number],.wy-control-group.fluid-input input[type=password],.wy-control-group.fluid-input input[type=search],.wy-control-group.fluid-input input[type=tel],.wy-control-group.fluid-input input[type=text],.wy-control-group.fluid-input input[type=time],.wy-control-group.fluid-input input[type=url],.wy-control-group.fluid-input input[type=week]{width:100%}.wy-form-message-inline{padding-left:.3em;color:#666;font-size:90%}.wy-form-message{display:block;color:#999;font-size:70%;margin-top:.3125em;font-style:italic}.wy-form-message p{font-size:inherit;font-style:italic;margin-bottom:6px}.wy-form-message p:last-child{margin-bottom:0}input{line-height:normal}input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer;font-family:Lato,proxima-nova,Helvetica Neue,Arial,sans-serif;*overflow:visible}input[type=color],input[type=date],input[type=datetime-local],input[type=datetime],input[type=email],input[type=month],input[type=number],input[type=password],input[type=search],input[type=tel],input[type=text],input[type=time],input[type=url],input[type=week]{-webkit-appearance:none;padding:6px;display:inline-block;border:1px solid #ccc;font-size:80%;font-family:Lato,proxima-nova,Helvetica Neue,Arial,sans-serif;box-shadow:inset 0 1px 3px #ddd;border-radius:0;-webkit-transition:border .3s linear;-moz-transition:border .3s linear;transition:border .3s linear}input[type=datetime-local]{padding:.34375em .625em}input[disabled]{cursor:default}input[type=checkbox],input[type=radio]{padding:0;margin-right:.3125em;*height:13px;*width:13px}input[type=checkbox],input[type=radio],input[type=search]{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box}input[type=search]::-webkit-search-cancel-button,input[type=search]::-webkit-search-decoration{-webkit-appearance:none}input[type=color]:focus,input[type=date]:focus,input[type=datetime-local]:focus,input[type=datetime]:focus,input[type=email]:focus,input[type=month]:focus,input[type=number]:focus,input[type=password]:focus,input[type=search]:focus,input[type=tel]:focus,input[type=text]:focus,input[type=time]:focus,input[type=url]:focus,input[type=week]:focus{outline:0;outline:thin dotted\9;border-color:#333}input.no-focus:focus{border-color:#ccc!important}input[type=checkbox]:focus,input[type=file]:focus,input[type=radio]:focus{outline:thin dotted #333;outline:1px auto #129fea}input[type=color][disabled],input[type=date][disabled],input[type=datetime-local][disabled],input[type=datetime][disabled],input[type=email][disabled],input[type=month][disabled],input[type=number][disabled],input[type=password][disabled],input[type=search][disabled],input[type=tel][disabled],input[type=text][disabled],input[type=time][disabled],input[type=url][disabled],input[type=week][disabled]{cursor:not-allowed;background-color:#fafafa}input:focus:invalid,select:focus:invalid,textarea:focus:invalid{color:#e74c3c;border:1px solid #e74c3c}input:focus:invalid:focus,select:focus:invalid:focus,textarea:focus:invalid:focus{border-color:#e74c3c}input[type=checkbox]:focus:invalid:focus,input[type=file]:focus:invalid:focus,input[type=radio]:focus:invalid:focus{outline-color:#e74c3c}input.wy-input-large{padding:12px;font-size:100%}textarea{overflow:auto;vertical-align:top;width:100%;font-family:Lato,proxima-nova,Helvetica Neue,Arial,sans-serif}select,textarea{padding:.5em .625em;display:inline-block;border:1px solid #ccc;font-size:80%;box-shadow:inset 0 1px 3px #ddd;-webkit-transition:border .3s linear;-moz-transition:border .3s linear;transition:border .3s linear}select{border:1px solid #ccc;background-color:#fff}select[multiple]{height:auto}select:focus,textarea:focus{outline:0}input[readonly],select[disabled],select[readonly],textarea[disabled],textarea[readonly]{cursor:not-allowed;background-color:#fafafa}input[type=checkbox][disabled],input[type=radio][disabled]{cursor:not-allowed}.wy-checkbox,.wy-radio{margin:6px 0;color:#404040;display:block}.wy-checkbox input,.wy-radio input{vertical-align:baseline}.wy-form-message-inline{display:inline-block;*display:inline;*zoom:1;vertical-align:middle}.wy-input-prefix,.wy-input-suffix{white-space:nowrap;padding:6px}.wy-input-prefix .wy-input-context,.wy-input-suffix .wy-input-context{line-height:27px;padding:0 8px;display:inline-block;font-size:80%;background-color:#f3f6f6;border:1px solid #ccc;color:#999}.wy-input-suffix .wy-input-context{border-left:0}.wy-input-prefix .wy-input-context{border-right:0}.wy-switch{position:relative;display:block;height:24px;margin-top:12px;cursor:pointer}.wy-switch:before{left:0;top:0;width:36px;height:12px;background:#ccc}.wy-switch:after,.wy-switch:before{position:absolute;content:"";display:block;border-radius:4px;-webkit-transition:all .2s ease-in-out;-moz-transition:all .2s ease-in-out;transition:all .2s ease-in-out}.wy-switch:after{width:18px;height:18px;background:#999;left:-3px;top:-3px}.wy-switch span{position:absolute;left:48px;display:block;font-size:12px;color:#ccc;line-height:1}.wy-switch.active:before{background:#1e8449}.wy-switch.active:after{left:24px;background:#27ae60}.wy-switch.disabled{cursor:not-allowed;opacity:.8}.wy-control-group.wy-control-group-error .wy-form-message,.wy-control-group.wy-control-group-error>label{color:#e74c3c}.wy-control-group.wy-control-group-error input[type=color],.wy-control-group.wy-control-group-error input[type=date],.wy-control-group.wy-control-group-error input[type=datetime-local],.wy-control-group.wy-control-group-error input[type=datetime],.wy-control-group.wy-control-group-error input[type=email],.wy-control-group.wy-control-group-error input[type=month],.wy-control-group.wy-control-group-error input[type=number],.wy-control-group.wy-control-group-error input[type=password],.wy-control-group.wy-control-group-error input[type=search],.wy-control-group.wy-control-group-error input[type=tel],.wy-control-group.wy-control-group-error input[type=text],.wy-control-group.wy-control-group-error input[type=time],.wy-control-group.wy-control-group-error input[type=url],.wy-control-group.wy-control-group-error input[type=week],.wy-control-group.wy-control-group-error textarea{border:1px solid #e74c3c}.wy-inline-validate{white-space:nowrap}.wy-inline-validate .wy-input-context{padding:.5em .625em;display:inline-block;font-size:80%}.wy-inline-validate.wy-inline-validate-success .wy-input-context{color:#27ae60}.wy-inline-validate.wy-inline-validate-danger .wy-input-context{color:#e74c3c}.wy-inline-validate.wy-inline-validate-warning .wy-input-context{color:#e67e22}.wy-inline-validate.wy-inline-validate-info .wy-input-context{color:#2980b9}.rotate-90{-webkit-transform:rotate(90deg);-moz-transform:rotate(90deg);-ms-transform:rotate(90deg);-o-transform:rotate(90deg);transform:rotate(90deg)}.rotate-180{-webkit-transform:rotate(180deg);-moz-transform:rotate(180deg);-ms-transform:rotate(180deg);-o-transform:rotate(180deg);transform:rotate(180deg)}.rotate-270{-webkit-transform:rotate(270deg);-moz-transform:rotate(270deg);-ms-transform:rotate(270deg);-o-transform:rotate(270deg);transform:rotate(270deg)}.mirror{-webkit-transform:scaleX(-1);-moz-transform:scaleX(-1);-ms-transform:scaleX(-1);-o-transform:scaleX(-1);transform:scaleX(-1)}.mirror.rotate-90{-webkit-transform:scaleX(-1) rotate(90deg);-moz-transform:scaleX(-1) rotate(90deg);-ms-transform:scaleX(-1) rotate(90deg);-o-transform:scaleX(-1) rotate(90deg);transform:scaleX(-1) rotate(90deg)}.mirror.rotate-180{-webkit-transform:scaleX(-1) rotate(180deg);-moz-transform:scaleX(-1) rotate(180deg);-ms-transform:scaleX(-1) rotate(180deg);-o-transform:scaleX(-1) rotate(180deg);transform:scaleX(-1) rotate(180deg)}.mirror.rotate-270{-webkit-transform:scaleX(-1) rotate(270deg);-moz-transform:scaleX(-1) rotate(270deg);-ms-transform:scaleX(-1) rotate(270deg);-o-transform:scaleX(-1) rotate(270deg);transform:scaleX(-1) rotate(270deg)}@media only screen and (max-width:480px){.wy-form button[type=submit]{margin:.7em 0 0}.wy-form input[type=color],.wy-form input[type=date],.wy-form input[type=datetime-local],.wy-form input[type=datetime],.wy-form input[type=email],.wy-form input[type=month],.wy-form input[type=number],.wy-form input[type=password],.wy-form input[type=search],.wy-form input[type=tel],.wy-form input[type=text],.wy-form input[type=time],.wy-form input[type=url],.wy-form input[type=week],.wy-form label{margin-bottom:.3em;display:block}.wy-form input[type=color],.wy-form input[type=date],.wy-form input[type=datetime-local],.wy-form input[type=datetime],.wy-form input[type=email],.wy-form input[type=month],.wy-form input[type=number],.wy-form input[type=password],.wy-form input[type=search],.wy-form input[type=tel],.wy-form input[type=time],.wy-form input[type=url],.wy-form input[type=week]{margin-bottom:0}.wy-form-aligned .wy-control-group label{margin-bottom:.3em;text-align:left;display:block;width:100%}.wy-form-aligned .wy-control{margin:1.5em 0 0}.wy-form-message,.wy-form-message-inline,.wy-form .wy-help-inline{display:block;font-size:80%;padding:6px 0}}@media screen and (max-width:768px){.tablet-hide{display:none}}@media screen and (max-width:480px){.mobile-hide{display:none}}.float-left{float:left}.float-right{float:right}.full-width{width:100%}.rst-content table.docutils,.rst-content table.field-list,.wy-table{border-collapse:collapse;border-spacing:0;empty-cells:show;margin-bottom:24px}.rst-content table.docutils caption,.rst-content table.field-list caption,.wy-table caption{color:#000;font:italic 85%/1 arial,sans-serif;padding:1em 0;text-align:center}.rst-content table.docutils td,.rst-content table.docutils th,.rst-content table.field-list td,.rst-content table.field-list th,.wy-table td,.wy-table th{font-size:90%;margin:0;overflow:visible;padding:8px 16px}.rst-content table.docutils td:first-child,.rst-content table.docutils th:first-child,.rst-content table.field-list td:first-child,.rst-content table.field-list th:first-child,.wy-table td:first-child,.wy-table th:first-child{border-left-width:0}.rst-content table.docutils thead,.rst-content table.field-list thead,.wy-table thead{color:#000;text-align:left;vertical-align:bottom;white-space:nowrap}.rst-content table.docutils thead th,.rst-content table.field-list thead th,.wy-table thead th{font-weight:700;border-bottom:2px solid #e1e4e5}.rst-content table.docutils td,.rst-content table.field-list td,.wy-table td{background-color:transparent;vertical-align:middle}.rst-content table.docutils td p,.rst-content table.field-list td p,.wy-table td p{line-height:18px}.rst-content table.docutils td p:last-child,.rst-content table.field-list td p:last-child,.wy-table td p:last-child{margin-bottom:0}.rst-content table.docutils .wy-table-cell-min,.rst-content table.field-list .wy-table-cell-min,.wy-table .wy-table-cell-min{width:1%;padding-right:0}.rst-content table.docutils .wy-table-cell-min input[type=checkbox],.rst-content table.field-list .wy-table-cell-min input[type=checkbox],.wy-table .wy-table-cell-min input[type=checkbox]{margin:0}.wy-table-secondary{color:grey;font-size:90%}.wy-table-tertiary{color:grey;font-size:80%}.rst-content table.docutils:not(.field-list) tr:nth-child(2n-1) td,.wy-table-backed,.wy-table-odd td,.wy-table-striped tr:nth-child(2n-1) td{background-color:#f3f6f6}.rst-content table.docutils,.wy-table-bordered-all{border:1px solid #e1e4e5}.rst-content table.docutils td,.wy-table-bordered-all td{border-bottom:1px solid #e1e4e5;border-left:1px solid #e1e4e5}.rst-content table.docutils tbody>tr:last-child td,.wy-table-bordered-all tbody>tr:last-child td{border-bottom-width:0}.wy-table-bordered{border:1px solid #e1e4e5}.wy-table-bordered-rows td{border-bottom:1px solid #e1e4e5}.wy-table-bordered-rows tbody>tr:last-child td{border-bottom-width:0}.wy-table-horizontal td,.wy-table-horizontal th{border-width:0 0 1px;border-bottom:1px solid #e1e4e5}.wy-table-horizontal tbody>tr:last-child td{border-bottom-width:0}.wy-table-responsive{margin-bottom:24px;max-width:100%;overflow:auto}.wy-table-responsive table{margin-bottom:0!important}.wy-table-responsive table td,.wy-table-responsive table th{white-space:nowrap}a{color:#2980b9;text-decoration:none;cursor:pointer}a:hover{color:#3091d1}a:visited{color:#9b59b6}html{height:100%}body,html{overflow-x:hidden}body{font-family:Lato,proxima-nova,Helvetica Neue,Arial,sans-serif;font-weight:400;color:#404040;min-height:100%;background:#edf0f2}.wy-text-left{text-align:left}.wy-text-center{text-align:center}.wy-text-right{text-align:right}.wy-text-large{font-size:120%}.wy-text-normal{font-size:100%}.wy-text-small,small{font-size:80%}.wy-text-strike{text-decoration:line-through}.wy-text-warning{color:#e67e22!important}a.wy-text-warning:hover{color:#eb9950!important}.wy-text-info{color:#2980b9!important}a.wy-text-info:hover{color:#409ad5!important}.wy-text-success{color:#27ae60!important}a.wy-text-success:hover{color:#36d278!important}.wy-text-danger{color:#e74c3c!important}a.wy-text-danger:hover{color:#ed7669!important}.wy-text-neutral{color:#404040!important}a.wy-text-neutral:hover{color:#595959!important}.rst-content .toctree-wrapper>p.caption,h1,h2,h3,h4,h5,h6,legend{margin-top:0;font-weight:700;font-family:Roboto Slab,ff-tisa-web-pro,Georgia,Arial,sans-serif}p{line-height:24px;font-size:16px;margin:0 0 24px}h1{font-size:175%}.rst-content .toctree-wrapper>p.caption,h2{font-size:150%}h3{font-size:125%}h4{font-size:115%}h5{font-size:110%}h6{font-size:100%}hr{display:block;height:1px;border:0;border-top:1px solid #e1e4e5;margin:24px 0;padding:0}.rst-content code,.rst-content tt,code{white-space:nowrap;max-width:100%;background:#fff;border:1px solid #e1e4e5;font-size:75%;padding:0 5px;font-family:SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,Courier,monospace;color:#e74c3c;overflow-x:auto}.rst-content tt.code-large,code.code-large{font-size:90%}.rst-content .section ul,.rst-content .toctree-wrapper ul,.rst-content section ul,.wy-plain-list-disc,article ul{list-style:disc;line-height:24px;margin-bottom:24px}.rst-content .section ul li,.rst-content .toctree-wrapper ul li,.rst-content section ul li,.wy-plain-list-disc li,article ul li{list-style:disc;margin-left:24px}.rst-content .section ul li p:last-child,.rst-content .section ul li ul,.rst-content .toctree-wrapper ul li p:last-child,.rst-content .toctree-wrapper ul li ul,.rst-content section ul li p:last-child,.rst-content section ul li ul,.wy-plain-list-disc li p:last-child,.wy-plain-list-disc li ul,article ul li p:last-child,article ul li ul{margin-bottom:0}.rst-content .section ul li li,.rst-content .toctree-wrapper ul li li,.rst-content section ul li li,.wy-plain-list-disc li li,article ul li li{list-style:circle}.rst-content .section ul li li li,.rst-content .toctree-wrapper ul li li li,.rst-content section ul li li li,.wy-plain-list-disc li li li,article ul li li li{list-style:square}.rst-content .section ul li ol li,.rst-content .toctree-wrapper ul li ol li,.rst-content section ul li ol li,.wy-plain-list-disc li ol li,article ul li ol li{list-style:decimal}.rst-content .section ol,.rst-content .section ol.arabic,.rst-content .toctree-wrapper ol,.rst-content .toctree-wrapper ol.arabic,.rst-content section ol,.rst-content section ol.arabic,.wy-plain-list-decimal,article ol{list-style:decimal;line-height:24px;margin-bottom:24px}.rst-content .section ol.arabic li,.rst-content .section ol li,.rst-content .toctree-wrapper ol.arabic li,.rst-content .toctree-wrapper ol li,.rst-content section ol.arabic li,.rst-content section ol li,.wy-plain-list-decimal li,article ol li{list-style:decimal;margin-left:24px}.rst-content .section ol.arabic li ul,.rst-content .section ol li p:last-child,.rst-content .section ol li ul,.rst-content .toctree-wrapper ol.arabic li ul,.rst-content .toctree-wrapper ol li p:last-child,.rst-content .toctree-wrapper ol li ul,.rst-content section ol.arabic li ul,.rst-content section ol li p:last-child,.rst-content section ol li ul,.wy-plain-list-decimal li p:last-child,.wy-plain-list-decimal li ul,article ol li p:last-child,article ol li ul{margin-bottom:0}.rst-content .section ol.arabic li ul li,.rst-content .section ol li ul li,.rst-content .toctree-wrapper ol.arabic li ul li,.rst-content .toctree-wrapper ol li ul li,.rst-content section ol.arabic li ul li,.rst-content section ol li ul li,.wy-plain-list-decimal li ul li,article ol li ul li{list-style:disc}.wy-breadcrumbs{*zoom:1}.wy-breadcrumbs:after,.wy-breadcrumbs:before{display:table;content:""}.wy-breadcrumbs:after{clear:both}.wy-breadcrumbs li{display:inline-block}.wy-breadcrumbs li.wy-breadcrumbs-aside{float:right}.wy-breadcrumbs li a{display:inline-block;padding:5px}.wy-breadcrumbs li a:first-child{padding-left:0}.rst-content .wy-breadcrumbs li tt,.wy-breadcrumbs li .rst-content tt,.wy-breadcrumbs li code{padding:5px;border:none;background:none}.rst-content .wy-breadcrumbs li tt.literal,.wy-breadcrumbs li .rst-content tt.literal,.wy-breadcrumbs li code.literal{color:#404040}.wy-breadcrumbs-extra{margin-bottom:0;color:#b3b3b3;font-size:80%;display:inline-block}@media screen and (max-width:480px){.wy-breadcrumbs-extra,.wy-breadcrumbs li.wy-breadcrumbs-aside{display:none}}@media print{.wy-breadcrumbs li.wy-breadcrumbs-aside{display:none}}html{font-size:16px}.wy-affix{position:fixed;top:1.618em}.wy-menu a:hover{text-decoration:none}.wy-menu-horiz{*zoom:1}.wy-menu-horiz:after,.wy-menu-horiz:before{display:table;content:""}.wy-menu-horiz:after{clear:both}.wy-menu-horiz li,.wy-menu-horiz ul{display:inline-block}.wy-menu-horiz li:hover{background:hsla(0,0%,100%,.1)}.wy-menu-horiz li.divide-left{border-left:1px solid #404040}.wy-menu-horiz li.divide-right{border-right:1px solid #404040}.wy-menu-horiz a{height:32px;display:inline-block;line-height:32px;padding:0 16px}.wy-menu-vertical{width:300px}.wy-menu-vertical header,.wy-menu-vertical p.caption{color:#55a5d9;height:32px;line-height:32px;padding:0 1.618em;margin:12px 0 0;display:block;font-weight:700;text-transform:uppercase;font-size:85%;white-space:nowrap}.wy-menu-vertical ul{margin-bottom:0}.wy-menu-vertical li.divide-top{border-top:1px solid #404040}.wy-menu-vertical li.divide-bottom{border-bottom:1px solid #404040}.wy-menu-vertical li.current{background:#e3e3e3}.wy-menu-vertical li.current a{color:grey;border-right:1px solid #c9c9c9;padding:.4045em 2.427em}.wy-menu-vertical li.current a:hover{background:#d6d6d6}.rst-content .wy-menu-vertical li tt,.wy-menu-vertical li .rst-content tt,.wy-menu-vertical li code{border:none;background:inherit;color:inherit;padding-left:0;padding-right:0}.wy-menu-vertical li button.toctree-expand{display:block;float:left;margin-left:-1.2em;line-height:18px;color:#4d4d4d;border:none;background:none;padding:0}.wy-menu-vertical li.current>a,.wy-menu-vertical li.on a{color:#404040;font-weight:700;position:relative;background:#fcfcfc;border:none;padding:.4045em 1.618em}.wy-menu-vertical li.current>a:hover,.wy-menu-vertical li.on a:hover{background:#fcfcfc}.wy-menu-vertical li.current>a:hover button.toctree-expand,.wy-menu-vertical li.on a:hover button.toctree-expand{color:grey}.wy-menu-vertical li.current>a button.toctree-expand,.wy-menu-vertical li.on a button.toctree-expand{display:block;line-height:18px;color:#333}.wy-menu-vertical li.toctree-l1.current>a{border-bottom:1px solid #c9c9c9;border-top:1px solid #c9c9c9}.wy-menu-vertical .toctree-l1.current .toctree-l2>ul,.wy-menu-vertical .toctree-l2.current .toctree-l3>ul,.wy-menu-vertical .toctree-l3.current .toctree-l4>ul,.wy-menu-vertical .toctree-l4.current .toctree-l5>ul,.wy-menu-vertical .toctree-l5.current .toctree-l6>ul,.wy-menu-vertical .toctree-l6.current .toctree-l7>ul,.wy-menu-vertical .toctree-l7.current .toctree-l8>ul,.wy-menu-vertical .toctree-l8.current .toctree-l9>ul,.wy-menu-vertical .toctree-l9.current .toctree-l10>ul,.wy-menu-vertical .toctree-l10.current .toctree-l11>ul{display:none}.wy-menu-vertical .toctree-l1.current .current.toctree-l2>ul,.wy-menu-vertical .toctree-l2.current .current.toctree-l3>ul,.wy-menu-vertical .toctree-l3.current .current.toctree-l4>ul,.wy-menu-vertical .toctree-l4.current .current.toctree-l5>ul,.wy-menu-vertical .toctree-l5.current .current.toctree-l6>ul,.wy-menu-vertical .toctree-l6.current .current.toctree-l7>ul,.wy-menu-vertical .toctree-l7.current .current.toctree-l8>ul,.wy-menu-vertical .toctree-l8.current .current.toctree-l9>ul,.wy-menu-vertical .toctree-l9.current .current.toctree-l10>ul,.wy-menu-vertical .toctree-l10.current .current.toctree-l11>ul{display:block}.wy-menu-vertical li.toctree-l3,.wy-menu-vertical li.toctree-l4{font-size:.9em}.wy-menu-vertical li.toctree-l2 a,.wy-menu-vertical li.toctree-l3 a,.wy-menu-vertical li.toctree-l4 a,.wy-menu-vertical li.toctree-l5 a,.wy-menu-vertical li.toctree-l6 a,.wy-menu-vertical li.toctree-l7 a,.wy-menu-vertical li.toctree-l8 a,.wy-menu-vertical li.toctree-l9 a,.wy-menu-vertical li.toctree-l10 a{color:#404040}.wy-menu-vertical li.toctree-l2 a:hover button.toctree-expand,.wy-menu-vertical li.toctree-l3 a:hover button.toctree-expand,.wy-menu-vertical li.toctree-l4 a:hover button.toctree-expand,.wy-menu-vertical li.toctree-l5 a:hover button.toctree-expand,.wy-menu-vertical li.toctree-l6 a:hover button.toctree-expand,.wy-menu-vertical li.toctree-l7 a:hover button.toctree-expand,.wy-menu-vertical li.toctree-l8 a:hover button.toctree-expand,.wy-menu-vertical li.toctree-l9 a:hover button.toctree-expand,.wy-menu-vertical li.toctree-l10 a:hover button.toctree-expand{color:grey}.wy-menu-vertical li.toctree-l2.current li.toctree-l3>a,.wy-menu-vertical li.toctree-l3.current li.toctree-l4>a,.wy-menu-vertical li.toctree-l4.current li.toctree-l5>a,.wy-menu-vertical li.toctree-l5.current li.toctree-l6>a,.wy-menu-vertical li.toctree-l6.current li.toctree-l7>a,.wy-menu-vertical li.toctree-l7.current li.toctree-l8>a,.wy-menu-vertical li.toctree-l8.current li.toctree-l9>a,.wy-menu-vertical li.toctree-l9.current li.toctree-l10>a,.wy-menu-vertical li.toctree-l10.current li.toctree-l11>a{display:block}.wy-menu-vertical li.toctree-l2.current>a{padding:.4045em 2.427em}.wy-menu-vertical li.toctree-l2.current li.toctree-l3>a{padding:.4045em 1.618em .4045em 4.045em}.wy-menu-vertical li.toctree-l3.current>a{padding:.4045em 4.045em}.wy-menu-vertical li.toctree-l3.current li.toctree-l4>a{padding:.4045em 1.618em .4045em 5.663em}.wy-menu-vertical li.toctree-l4.current>a{padding:.4045em 5.663em}.wy-menu-vertical li.toctree-l4.current li.toctree-l5>a{padding:.4045em 1.618em .4045em 7.281em}.wy-menu-vertical li.toctree-l5.current>a{padding:.4045em 7.281em}.wy-menu-vertical li.toctree-l5.current li.toctree-l6>a{padding:.4045em 1.618em .4045em 8.899em}.wy-menu-vertical li.toctree-l6.current>a{padding:.4045em 8.899em}.wy-menu-vertical li.toctree-l6.current li.toctree-l7>a{padding:.4045em 1.618em .4045em 10.517em}.wy-menu-vertical li.toctree-l7.current>a{padding:.4045em 10.517em}.wy-menu-vertical li.toctree-l7.current li.toctree-l8>a{padding:.4045em 1.618em .4045em 12.135em}.wy-menu-vertical li.toctree-l8.current>a{padding:.4045em 12.135em}.wy-menu-vertical li.toctree-l8.current li.toctree-l9>a{padding:.4045em 1.618em .4045em 13.753em}.wy-menu-vertical li.toctree-l9.current>a{padding:.4045em 13.753em}.wy-menu-vertical li.toctree-l9.current li.toctree-l10>a{padding:.4045em 1.618em .4045em 15.371em}.wy-menu-vertical li.toctree-l10.current>a{padding:.4045em 15.371em}.wy-menu-vertical li.toctree-l10.current li.toctree-l11>a{padding:.4045em 1.618em .4045em 16.989em}.wy-menu-vertical li.toctree-l2.current>a,.wy-menu-vertical li.toctree-l2.current li.toctree-l3>a{background:#c9c9c9}.wy-menu-vertical li.toctree-l2 button.toctree-expand{color:#a3a3a3}.wy-menu-vertical li.toctree-l3.current>a,.wy-menu-vertical li.toctree-l3.current li.toctree-l4>a{background:#bdbdbd}.wy-menu-vertical li.toctree-l3 button.toctree-expand{color:#969696}.wy-menu-vertical li.current ul{display:block}.wy-menu-vertical li ul{margin-bottom:0;display:none}.wy-menu-vertical li ul li a{margin-bottom:0;color:#d9d9d9;font-weight:400}.wy-menu-vertical a{line-height:18px;padding:.4045em 1.618em;display:block;position:relative;font-size:90%;color:#d9d9d9}.wy-menu-vertical a:hover{background-color:#4e4a4a;cursor:pointer}.wy-menu-vertical a:hover button.toctree-expand{color:#d9d9d9}.wy-menu-vertical a:active{background-color:#2980b9;cursor:pointer;color:#fff}.wy-menu-vertical a:active button.toctree-expand{color:#fff}.wy-side-nav-search{display:block;width:300px;padding:.809em;margin-bottom:.809em;z-index:200;background-color:#2980b9;text-align:center;color:#fcfcfc}.wy-side-nav-search input[type=text]{width:100%;border-radius:50px;padding:6px 12px;border-color:#2472a4}.wy-side-nav-search img{display:block;margin:auto auto .809em;height:45px;width:45px;background-color:#2980b9;padding:5px;border-radius:100%}.wy-side-nav-search .wy-dropdown>a,.wy-side-nav-search>a{color:#fcfcfc;font-size:100%;font-weight:700;display:inline-block;padding:4px 6px;margin-bottom:.809em;max-width:100%}.wy-side-nav-search .wy-dropdown>a:hover,.wy-side-nav-search>a:hover{background:hsla(0,0%,100%,.1)}.wy-side-nav-search .wy-dropdown>a img.logo,.wy-side-nav-search>a img.logo{display:block;margin:0 auto;height:auto;width:auto;border-radius:0;max-width:100%;background:transparent}.wy-side-nav-search .wy-dropdown>a.icon img.logo,.wy-side-nav-search>a.icon img.logo{margin-top:.85em}.wy-side-nav-search>div.version{margin-top:-.4045em;margin-bottom:.809em;font-weight:400;color:hsla(0,0%,100%,.3)}.wy-nav .wy-menu-vertical header{color:#2980b9}.wy-nav .wy-menu-vertical a{color:#b3b3b3}.wy-nav .wy-menu-vertical a:hover{background-color:#2980b9;color:#fff}[data-menu-wrap]{-webkit-transition:all .2s ease-in;-moz-transition:all .2s ease-in;transition:all .2s ease-in;position:absolute;opacity:1;width:100%;opacity:0}[data-menu-wrap].move-center{left:0;right:auto;opacity:1}[data-menu-wrap].move-left{right:auto;left:-100%;opacity:0}[data-menu-wrap].move-right{right:-100%;left:auto;opacity:0}.wy-body-for-nav{background:#fcfcfc}.wy-grid-for-nav{position:absolute;width:100%;height:100%}.wy-nav-side{position:fixed;top:0;bottom:0;left:0;padding-bottom:2em;width:300px;overflow-x:hidden;overflow-y:hidden;min-height:100%;color:#9b9b9b;background:#343131;z-index:200}.wy-side-scroll{width:320px;position:relative;overflow-x:hidden;overflow-y:scroll;height:100%}.wy-nav-top{display:none;background:#2980b9;color:#fff;padding:.4045em .809em;position:relative;line-height:50px;text-align:center;font-size:100%;*zoom:1}.wy-nav-top:after,.wy-nav-top:before{display:table;content:""}.wy-nav-top:after{clear:both}.wy-nav-top a{color:#fff;font-weight:700}.wy-nav-top img{margin-right:12px;height:45px;width:45px;background-color:#2980b9;padding:5px;border-radius:100%}.wy-nav-top i{font-size:30px;float:left;cursor:pointer;padding-top:inherit}.wy-nav-content-wrap{margin-left:300px;background:#fcfcfc;min-height:100%}.wy-nav-content{padding:1.618em 3.236em;height:100%;max-width:800px;margin:auto}.wy-body-mask{position:fixed;width:100%;height:100%;background:rgba(0,0,0,.2);display:none;z-index:499}.wy-body-mask.on{display:block}footer{color:grey}footer p{margin-bottom:12px}.rst-content footer span.commit tt,footer span.commit .rst-content tt,footer span.commit code{padding:0;font-family:SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,Courier,monospace;font-size:1em;background:none;border:none;color:grey}.rst-footer-buttons{*zoom:1}.rst-footer-buttons:after,.rst-footer-buttons:before{width:100%;display:table;content:""}.rst-footer-buttons:after{clear:both}.rst-breadcrumbs-buttons{margin-top:12px;*zoom:1}.rst-breadcrumbs-buttons:after,.rst-breadcrumbs-buttons:before{display:table;content:""}.rst-breadcrumbs-buttons:after{clear:both}#search-results .search li{margin-bottom:24px;border-bottom:1px solid #e1e4e5;padding-bottom:24px}#search-results .search li:first-child{border-top:1px solid #e1e4e5;padding-top:24px}#search-results .search li a{font-size:120%;margin-bottom:12px;display:inline-block}#search-results .context{color:grey;font-size:90%}.genindextable li>ul{margin-left:24px}@media screen and (max-width:768px){.wy-body-for-nav{background:#fcfcfc}.wy-nav-top{display:block}.wy-nav-side{left:-300px}.wy-nav-side.shift{width:85%;left:0}.wy-menu.wy-menu-vertical,.wy-side-nav-search,.wy-side-scroll{width:auto}.wy-nav-content-wrap{margin-left:0}.wy-nav-content-wrap .wy-nav-content{padding:1.618em}.wy-nav-content-wrap.shift{position:fixed;min-width:100%;left:85%;top:0;height:100%;overflow:hidden}}@media screen and (min-width:1100px){.wy-nav-content-wrap{background:rgba(0,0,0,.05)}.wy-nav-content{margin:0;background:#fcfcfc}}@media print{.rst-versions,.wy-nav-side,footer{display:none}.wy-nav-content-wrap{margin-left:0}}.rst-versions{position:fixed;bottom:0;left:0;width:300px;color:#fcfcfc;background:#1f1d1d;font-family:Lato,proxima-nova,Helvetica Neue,Arial,sans-serif;z-index:400}.rst-versions a{color:#2980b9;text-decoration:none}.rst-versions .rst-badge-small{display:none}.rst-versions .rst-current-version{padding:12px;background-color:#272525;display:block;text-align:right;font-size:90%;cursor:pointer;color:#27ae60;*zoom:1}.rst-versions .rst-current-version:after,.rst-versions .rst-current-version:before{display:table;content:""}.rst-versions .rst-current-version:after{clear:both}.rst-content .code-block-caption .rst-versions .rst-current-version .headerlink,.rst-content .eqno .rst-versions .rst-current-version .headerlink,.rst-content .rst-versions .rst-current-version .admonition-title,.rst-content code.download .rst-versions .rst-current-version span:first-child,.rst-content dl dt .rst-versions .rst-current-version .headerlink,.rst-content h1 .rst-versions .rst-current-version .headerlink,.rst-content h2 .rst-versions .rst-current-version .headerlink,.rst-content h3 .rst-versions .rst-current-version .headerlink,.rst-content h4 .rst-versions .rst-current-version .headerlink,.rst-content h5 .rst-versions .rst-current-version .headerlink,.rst-content h6 .rst-versions .rst-current-version .headerlink,.rst-content p .rst-versions .rst-current-version .headerlink,.rst-content table>caption .rst-versions .rst-current-version .headerlink,.rst-content tt.download .rst-versions .rst-current-version span:first-child,.rst-versions .rst-current-version .fa,.rst-versions .rst-current-version .icon,.rst-versions .rst-current-version .rst-content .admonition-title,.rst-versions .rst-current-version .rst-content .code-block-caption .headerlink,.rst-versions .rst-current-version .rst-content .eqno .headerlink,.rst-versions .rst-current-version .rst-content code.download span:first-child,.rst-versions .rst-current-version .rst-content dl dt .headerlink,.rst-versions .rst-current-version .rst-content h1 .headerlink,.rst-versions .rst-current-version .rst-content h2 .headerlink,.rst-versions .rst-current-version .rst-content h3 .headerlink,.rst-versions .rst-current-version .rst-content h4 .headerlink,.rst-versions .rst-current-version .rst-content h5 .headerlink,.rst-versions .rst-current-version .rst-content h6 .headerlink,.rst-versions .rst-current-version .rst-content p .headerlink,.rst-versions .rst-current-version .rst-content table>caption .headerlink,.rst-versions .rst-current-version .rst-content tt.download span:first-child,.rst-versions .rst-current-version .wy-menu-vertical li button.toctree-expand,.wy-menu-vertical li .rst-versions .rst-current-version button.toctree-expand{color:#fcfcfc}.rst-versions .rst-current-version .fa-book,.rst-versions .rst-current-version .icon-book{float:left}.rst-versions .rst-current-version.rst-out-of-date{background-color:#e74c3c;color:#fff}.rst-versions .rst-current-version.rst-active-old-version{background-color:#f1c40f;color:#000}.rst-versions.shift-up{height:auto;max-height:100%;overflow-y:scroll}.rst-versions.shift-up .rst-other-versions{display:block}.rst-versions .rst-other-versions{font-size:90%;padding:12px;color:grey;display:none}.rst-versions .rst-other-versions hr{display:block;height:1px;border:0;margin:20px 0;padding:0;border-top:1px solid #413d3d}.rst-versions .rst-other-versions dd{display:inline-block;margin:0}.rst-versions .rst-other-versions dd a{display:inline-block;padding:6px;color:#fcfcfc}.rst-versions.rst-badge{width:auto;bottom:20px;right:20px;left:auto;border:none;max-width:300px;max-height:90%}.rst-versions.rst-badge .fa-book,.rst-versions.rst-badge .icon-book{float:none;line-height:30px}.rst-versions.rst-badge.shift-up .rst-current-version{text-align:right}.rst-versions.rst-badge.shift-up .rst-current-version .fa-book,.rst-versions.rst-badge.shift-up .rst-current-version .icon-book{float:left}.rst-versions.rst-badge>.rst-current-version{width:auto;height:30px;line-height:30px;padding:0 6px;display:block;text-align:center}@media screen and (max-width:768px){.rst-versions{width:85%;display:none}.rst-versions.shift{display:block}}.rst-content .toctree-wrapper>p.caption,.rst-content h1,.rst-content h2,.rst-content h3,.rst-content h4,.rst-content h5,.rst-content h6{margin-bottom:24px}.rst-content img{max-width:100%;height:auto}.rst-content div.figure,.rst-content figure{margin-bottom:24px}.rst-content div.figure .caption-text,.rst-content figure .caption-text{font-style:italic}.rst-content div.figure p:last-child.caption,.rst-content figure p:last-child.caption{margin-bottom:0}.rst-content div.figure.align-center,.rst-content figure.align-center{text-align:center}.rst-content .section>a>img,.rst-content .section>img,.rst-content section>a>img,.rst-content section>img{margin-bottom:24px}.rst-content abbr[title]{text-decoration:none}.rst-content.style-external-links a.reference.external:after{font-family:FontAwesome;content:"\f08e";color:#b3b3b3;vertical-align:super;font-size:60%;margin:0 .2em}.rst-content blockquote{margin-left:24px;line-height:24px;margin-bottom:24px}.rst-content pre.literal-block{white-space:pre;margin:0;padding:12px;font-family:SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,Courier,monospace;display:block;overflow:auto}.rst-content div[class^=highlight],.rst-content pre.literal-block{border:1px solid #e1e4e5;overflow-x:auto;margin:1px 0 24px}.rst-content div[class^=highlight] div[class^=highlight],.rst-content pre.literal-block div[class^=highlight]{padding:0;border:none;margin:0}.rst-content div[class^=highlight] td.code{width:100%}.rst-content .linenodiv pre{border-right:1px solid #e6e9ea;margin:0;padding:12px;font-family:SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,Courier,monospace;user-select:none;pointer-events:none}.rst-content div[class^=highlight] pre{white-space:pre;margin:0;padding:12px;display:block;overflow:auto}.rst-content div[class^=highlight] pre .hll{display:block;margin:0 -12px;padding:0 12px}.rst-content .linenodiv pre,.rst-content div[class^=highlight] pre,.rst-content pre.literal-block{font-family:SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,Courier,monospace;font-size:12px;line-height:1.4}.rst-content div.highlight .gp,.rst-content div.highlight span.linenos{user-select:none;pointer-events:none}.rst-content div.highlight span.linenos{display:inline-block;padding-left:0;padding-right:12px;margin-right:12px;border-right:1px solid #e6e9ea}.rst-content .code-block-caption{font-style:italic;font-size:85%;line-height:1;padding:1em 0;text-align:center}@media print{.rst-content .codeblock,.rst-content div[class^=highlight],.rst-content div[class^=highlight] pre{white-space:pre-wrap}}.rst-content .admonition,.rst-content .admonition-todo,.rst-content .attention,.rst-content .caution,.rst-content .danger,.rst-content .error,.rst-content .hint,.rst-content .important,.rst-content .note,.rst-content .seealso,.rst-content .tip,.rst-content .warning{clear:both}.rst-content .admonition-todo .last,.rst-content .admonition-todo>:last-child,.rst-content .admonition .last,.rst-content .admonition>:last-child,.rst-content .attention .last,.rst-content .attention>:last-child,.rst-content .caution .last,.rst-content .caution>:last-child,.rst-content .danger .last,.rst-content .danger>:last-child,.rst-content .error .last,.rst-content .error>:last-child,.rst-content .hint .last,.rst-content .hint>:last-child,.rst-content .important .last,.rst-content .important>:last-child,.rst-content .note .last,.rst-content .note>:last-child,.rst-content .seealso .last,.rst-content .seealso>:last-child,.rst-content .tip .last,.rst-content .tip>:last-child,.rst-content .warning .last,.rst-content .warning>:last-child{margin-bottom:0}.rst-content .admonition-title:before{margin-right:4px}.rst-content .admonition table{border-color:rgba(0,0,0,.1)}.rst-content .admonition table td,.rst-content .admonition table th{background:transparent!important;border-color:rgba(0,0,0,.1)!important}.rst-content .section ol.loweralpha,.rst-content .section ol.loweralpha>li,.rst-content .toctree-wrapper ol.loweralpha,.rst-content .toctree-wrapper ol.loweralpha>li,.rst-content section ol.loweralpha,.rst-content section ol.loweralpha>li{list-style:lower-alpha}.rst-content .section ol.upperalpha,.rst-content .section ol.upperalpha>li,.rst-content .toctree-wrapper ol.upperalpha,.rst-content .toctree-wrapper ol.upperalpha>li,.rst-content section ol.upperalpha,.rst-content section ol.upperalpha>li{list-style:upper-alpha}.rst-content .section ol li>*,.rst-content .section ul li>*,.rst-content .toctree-wrapper ol li>*,.rst-content .toctree-wrapper ul li>*,.rst-content section ol li>*,.rst-content section ul li>*{margin-top:12px;margin-bottom:12px}.rst-content .section ol li>:first-child,.rst-content .section ul li>:first-child,.rst-content .toctree-wrapper ol li>:first-child,.rst-content .toctree-wrapper ul li>:first-child,.rst-content section ol li>:first-child,.rst-content section ul li>:first-child{margin-top:0}.rst-content .section ol li>p,.rst-content .section ol li>p:last-child,.rst-content .section ul li>p,.rst-content .section ul li>p:last-child,.rst-content .toctree-wrapper ol li>p,.rst-content .toctree-wrapper ol li>p:last-child,.rst-content .toctree-wrapper ul li>p,.rst-content .toctree-wrapper ul li>p:last-child,.rst-content section ol li>p,.rst-content section ol li>p:last-child,.rst-content section ul li>p,.rst-content section ul li>p:last-child{margin-bottom:12px}.rst-content .section ol li>p:only-child,.rst-content .section ol li>p:only-child:last-child,.rst-content .section ul li>p:only-child,.rst-content .section ul li>p:only-child:last-child,.rst-content .toctree-wrapper ol li>p:only-child,.rst-content .toctree-wrapper ol li>p:only-child:last-child,.rst-content .toctree-wrapper ul li>p:only-child,.rst-content .toctree-wrapper ul li>p:only-child:last-child,.rst-content section ol li>p:only-child,.rst-content section ol li>p:only-child:last-child,.rst-content section ul li>p:only-child,.rst-content section ul li>p:only-child:last-child{margin-bottom:0}.rst-content .section ol li>ol,.rst-content .section ol li>ul,.rst-content .section ul li>ol,.rst-content .section ul li>ul,.rst-content .toctree-wrapper ol li>ol,.rst-content .toctree-wrapper ol li>ul,.rst-content .toctree-wrapper ul li>ol,.rst-content .toctree-wrapper ul li>ul,.rst-content section ol li>ol,.rst-content section ol li>ul,.rst-content section ul li>ol,.rst-content section ul li>ul{margin-bottom:12px}.rst-content .section ol.simple li>*,.rst-content .section ol.simple li ol,.rst-content .section ol.simple li ul,.rst-content .section ul.simple li>*,.rst-content .section ul.simple li ol,.rst-content .section ul.simple li ul,.rst-content .toctree-wrapper ol.simple li>*,.rst-content .toctree-wrapper ol.simple li ol,.rst-content .toctree-wrapper ol.simple li ul,.rst-content .toctree-wrapper ul.simple li>*,.rst-content .toctree-wrapper ul.simple li ol,.rst-content .toctree-wrapper ul.simple li ul,.rst-content section ol.simple li>*,.rst-content section ol.simple li ol,.rst-content section ol.simple li ul,.rst-content section ul.simple li>*,.rst-content section ul.simple li ol,.rst-content section ul.simple li ul{margin-top:0;margin-bottom:0}.rst-content .line-block{margin-left:0;margin-bottom:24px;line-height:24px}.rst-content .line-block .line-block{margin-left:24px;margin-bottom:0}.rst-content .topic-title{font-weight:700;margin-bottom:12px}.rst-content .toc-backref{color:#404040}.rst-content .align-right{float:right;margin:0 0 24px 24px}.rst-content .align-left{float:left;margin:0 24px 24px 0}.rst-content .align-center{margin:auto}.rst-content .align-center:not(table){display:block}.rst-content .code-block-caption .headerlink,.rst-content .eqno .headerlink,.rst-content .toctree-wrapper>p.caption .headerlink,.rst-content dl dt .headerlink,.rst-content h1 .headerlink,.rst-content h2 .headerlink,.rst-content h3 .headerlink,.rst-content h4 .headerlink,.rst-content h5 .headerlink,.rst-content h6 .headerlink,.rst-content p.caption .headerlink,.rst-content p .headerlink,.rst-content table>caption .headerlink{opacity:0;font-size:14px;font-family:FontAwesome;margin-left:.5em}.rst-content .code-block-caption .headerlink:focus,.rst-content .code-block-caption:hover .headerlink,.rst-content .eqno .headerlink:focus,.rst-content .eqno:hover .headerlink,.rst-content .toctree-wrapper>p.caption .headerlink:focus,.rst-content .toctree-wrapper>p.caption:hover .headerlink,.rst-content dl dt .headerlink:focus,.rst-content dl dt:hover .headerlink,.rst-content h1 .headerlink:focus,.rst-content h1:hover .headerlink,.rst-content h2 .headerlink:focus,.rst-content h2:hover .headerlink,.rst-content h3 .headerlink:focus,.rst-content h3:hover .headerlink,.rst-content h4 .headerlink:focus,.rst-content h4:hover .headerlink,.rst-content h5 .headerlink:focus,.rst-content h5:hover .headerlink,.rst-content h6 .headerlink:focus,.rst-content h6:hover .headerlink,.rst-content p.caption .headerlink:focus,.rst-content p.caption:hover .headerlink,.rst-content p .headerlink:focus,.rst-content p:hover .headerlink,.rst-content table>caption .headerlink:focus,.rst-content table>caption:hover .headerlink{opacity:1}.rst-content .btn:focus{outline:2px solid}.rst-content table>caption .headerlink:after{font-size:12px}.rst-content .centered{text-align:center}.rst-content .sidebar{float:right;width:40%;display:block;margin:0 0 24px 24px;padding:24px;background:#f3f6f6;border:1px solid #e1e4e5}.rst-content .sidebar dl,.rst-content .sidebar p,.rst-content .sidebar ul{font-size:90%}.rst-content .sidebar .last,.rst-content .sidebar>:last-child{margin-bottom:0}.rst-content .sidebar .sidebar-title{display:block;font-family:Roboto Slab,ff-tisa-web-pro,Georgia,Arial,sans-serif;font-weight:700;background:#e1e4e5;padding:6px 12px;margin:-24px -24px 24px;font-size:100%}.rst-content .highlighted{background:#f1c40f;box-shadow:0 0 0 2px #f1c40f;display:inline;font-weight:700}.rst-content .citation-reference,.rst-content .footnote-reference{vertical-align:baseline;position:relative;top:-.4em;line-height:0;font-size:90%}.rst-content .hlist{width:100%}.rst-content dl dt span.classifier:before{content:" : "}.rst-content dl dt span.classifier-delimiter{display:none!important}html.writer-html4 .rst-content table.docutils.citation,html.writer-html4 .rst-content table.docutils.footnote{background:none;border:none}html.writer-html4 .rst-content table.docutils.citation td,html.writer-html4 .rst-content table.docutils.citation tr,html.writer-html4 .rst-content table.docutils.footnote td,html.writer-html4 .rst-content table.docutils.footnote tr{border:none;background-color:transparent!important;white-space:normal}html.writer-html4 .rst-content table.docutils.citation td.label,html.writer-html4 .rst-content table.docutils.footnote td.label{padding-left:0;padding-right:0;vertical-align:top}html.writer-html5 .rst-content dl.field-list,html.writer-html5 .rst-content dl.footnote{display:grid;grid-template-columns:max-content auto}html.writer-html5 .rst-content dl.field-list>dt,html.writer-html5 .rst-content dl.footnote>dt{padding-left:1rem}html.writer-html5 .rst-content dl.field-list>dt:after,html.writer-html5 .rst-content dl.footnote>dt:after{content:":"}html.writer-html5 .rst-content dl.field-list>dd,html.writer-html5 .rst-content dl.field-list>dt,html.writer-html5 .rst-content dl.footnote>dd,html.writer-html5 .rst-content dl.footnote>dt{margin-bottom:0}html.writer-html5 .rst-content dl.footnote{font-size:.9rem}html.writer-html5 .rst-content dl.footnote>dt{margin:0 .5rem .5rem 0;line-height:1.2rem;word-break:break-all;font-weight:400}html.writer-html5 .rst-content dl.footnote>dt>span.brackets{margin-right:.5rem}html.writer-html5 .rst-content dl.footnote>dt>span.brackets:before{content:"["}html.writer-html5 .rst-content dl.footnote>dt>span.brackets:after{content:"]"}html.writer-html5 .rst-content dl.footnote>dt>span.fn-backref{font-style:italic}html.writer-html5 .rst-content dl.footnote>dd{margin:0 0 .5rem;line-height:1.2rem}html.writer-html5 .rst-content dl.footnote>dd p,html.writer-html5 .rst-content dl.option-list kbd{font-size:.9rem}.rst-content table.docutils.footnote,html.writer-html4 .rst-content table.docutils.citation,html.writer-html5 .rst-content dl.footnote{color:grey}.rst-content table.docutils.footnote code,.rst-content table.docutils.footnote tt,html.writer-html4 .rst-content table.docutils.citation code,html.writer-html4 .rst-content table.docutils.citation tt,html.writer-html5 .rst-content dl.footnote code,html.writer-html5 .rst-content dl.footnote tt{color:#555}.rst-content .wy-table-responsive.citation,.rst-content .wy-table-responsive.footnote{margin-bottom:0}.rst-content .wy-table-responsive.citation+:not(.citation),.rst-content .wy-table-responsive.footnote+:not(.footnote){margin-top:24px}.rst-content .wy-table-responsive.citation:last-child,.rst-content .wy-table-responsive.footnote:last-child{margin-bottom:24px}.rst-content table.docutils th{border-color:#e1e4e5}html.writer-html5 .rst-content table.docutils th{border:1px solid #e1e4e5}html.writer-html5 .rst-content table.docutils td>p,html.writer-html5 .rst-content table.docutils th>p{line-height:1rem;margin-bottom:0;font-size:.9rem}.rst-content table.docutils td .last,.rst-content table.docutils td .last>:last-child{margin-bottom:0}.rst-content table.field-list,.rst-content table.field-list td{border:none}.rst-content table.field-list td p{font-size:inherit;line-height:inherit}.rst-content table.field-list td>strong{display:inline-block}.rst-content table.field-list .field-name{padding-right:10px;text-align:left;white-space:nowrap}.rst-content table.field-list .field-body{text-align:left}.rst-content code,.rst-content tt{color:#000;font-family:SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,Courier,monospace;padding:2px 5px}.rst-content code big,.rst-content code em,.rst-content tt big,.rst-content tt em{font-size:100%!important;line-height:normal}.rst-content code.literal,.rst-content tt.literal{color:#e74c3c;white-space:normal}.rst-content code.xref,.rst-content tt.xref,a .rst-content code,a .rst-content tt{font-weight:700;color:#404040}.rst-content kbd,.rst-content pre,.rst-content samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,Courier,monospace}.rst-content a code,.rst-content a tt{color:#2980b9}.rst-content dl{margin-bottom:24px}.rst-content dl dt{font-weight:700;margin-bottom:12px}.rst-content dl ol,.rst-content dl p,.rst-content dl table,.rst-content dl ul{margin-bottom:12px}.rst-content dl dd{margin:0 0 12px 24px;line-height:24px}html.writer-html4 .rst-content dl:not(.docutils),html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple){margin-bottom:24px}html.writer-html4 .rst-content dl:not(.docutils)>dt,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple)>dt{display:table;margin:6px 0;font-size:90%;line-height:normal;background:#e7f2fa;color:#2980b9;border-top:3px solid #6ab0de;padding:6px;position:relative}html.writer-html4 .rst-content dl:not(.docutils)>dt:before,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple)>dt:before{color:#6ab0de}html.writer-html4 .rst-content dl:not(.docutils)>dt .headerlink,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple)>dt .headerlink{color:#404040;font-size:100%!important}html.writer-html4 .rst-content dl:not(.docutils) dl:not(.field-list)>dt,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple) dl:not(.field-list)>dt{margin-bottom:6px;border:none;border-left:3px solid #ccc;background:#f0f0f0;color:#555}html.writer-html4 .rst-content dl:not(.docutils) dl:not(.field-list)>dt .headerlink,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple) dl:not(.field-list)>dt .headerlink{color:#404040;font-size:100%!important}html.writer-html4 .rst-content dl:not(.docutils)>dt:first-child,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple)>dt:first-child{margin-top:0}html.writer-html4 .rst-content dl:not(.docutils) code.descclassname,html.writer-html4 .rst-content dl:not(.docutils) code.descname,html.writer-html4 .rst-content dl:not(.docutils) tt.descclassname,html.writer-html4 .rst-content dl:not(.docutils) tt.descname,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple) code.descclassname,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple) code.descname,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple) tt.descclassname,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple) tt.descname{background-color:transparent;border:none;padding:0;font-size:100%!important}html.writer-html4 .rst-content dl:not(.docutils) code.descname,html.writer-html4 .rst-content dl:not(.docutils) tt.descname,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple) code.descname,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple) tt.descname{font-weight:700}html.writer-html4 .rst-content dl:not(.docutils) .optional,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple) .optional{display:inline-block;padding:0 4px;color:#000;font-weight:700}html.writer-html4 .rst-content dl:not(.docutils) .property,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple) .property{display:inline-block;padding-right:8px;max-width:100%}html.writer-html4 .rst-content dl:not(.docutils) .k,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple) .k{font-style:italic}html.writer-html4 .rst-content dl:not(.docutils) .descclassname,html.writer-html4 .rst-content dl:not(.docutils) .descname,html.writer-html4 .rst-content dl:not(.docutils) .sig-name,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple) .descclassname,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple) .descname,html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple) .sig-name{font-family:SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,Courier,monospace;color:#000}.rst-content .viewcode-back,.rst-content .viewcode-link{display:inline-block;color:#27ae60;font-size:80%;padding-left:24px}.rst-content .viewcode-back{display:block;float:right}.rst-content p.rubric{margin-bottom:12px;font-weight:700}.rst-content code.download,.rst-content tt.download{background:inherit;padding:inherit;font-weight:400;font-family:inherit;font-size:inherit;color:inherit;border:inherit;white-space:inherit}.rst-content code.download span:first-child,.rst-content tt.download span:first-child{-webkit-font-smoothing:subpixel-antialiased}.rst-content code.download span:first-child:before,.rst-content tt.download span:first-child:before{margin-right:4px}.rst-content .guilabel{border:1px solid #7fbbe3;background:#e7f2fa;font-size:80%;font-weight:700;border-radius:4px;padding:2.4px 6px;margin:auto 2px}.rst-content .versionmodified{font-style:italic}@media screen and (max-width:480px){.rst-content .sidebar{width:100%}}span[id*=MathJax-Span]{color:#404040}.math{text-align:center}@font-face{font-family:Lato;src:url(fonts/lato-normal.woff2?bd03a2cc277bbbc338d464e679fe9942) format("woff2"),url(fonts/lato-normal.woff?27bd77b9162d388cb8d4c4217c7c5e2a) format("woff");font-weight:400;font-style:normal;font-display:block}@font-face{font-family:Lato;src:url(fonts/lato-bold.woff2?cccb897485813c7c256901dbca54ecf2) format("woff2"),url(fonts/lato-bold.woff?d878b6c29b10beca227e9eef4246111b) format("woff");font-weight:700;font-style:normal;font-display:block}@font-face{font-family:Lato;src:url(fonts/lato-bold-italic.woff2?0b6bb6725576b072c5d0b02ecdd1900d) format("woff2"),url(fonts/lato-bold-italic.woff?9c7e4e9eb485b4a121c760e61bc3707c) format("woff");font-weight:700;font-style:italic;font-display:block}@font-face{font-family:Lato;src:url(fonts/lato-normal-italic.woff2?4eb103b4d12be57cb1d040ed5e162e9d) format("woff2"),url(fonts/lato-normal-italic.woff?f28f2d6482446544ef1ea1ccc6dd5892) format("woff");font-weight:400;font-style:italic;font-display:block}@font-face{font-family:Roboto Slab;font-style:normal;font-weight:400;src:url(fonts/Roboto-Slab-Regular.woff2?7abf5b8d04d26a2cafea937019bca958) format("woff2"),url(fonts/Roboto-Slab-Regular.woff?c1be9284088d487c5e3ff0a10a92e58c) format("woff");font-display:block}@font-face{font-family:Roboto Slab;font-style:normal;font-weight:700;src:url(fonts/Roboto-Slab-Bold.woff2?9984f4a9bda09be08e83f2506954adbe) format("woff2"),url(fonts/Roboto-Slab-Bold.woff?bed5564a116b05148e3b3bea6fb1162a) format("woff");font-display:block}

@import url('theme.css');

/* Logo background */
.wy-side-nav-search, .wy-side-nav-search img {
    background-color: #ffffff !important;
}

.highlight {
  background: #f1f3f4;
}

.navbar {
  background: #ffffff;
}

.navbar-nav {
  background: #ffffff;
}

/* side bar */
.wy-nav-side {
  background: #f1f3f4;
}

.wy-menu-vertical a {
  color: #707070;
}

.wy-side-nav-search div.version {
  color: #404040;
}


/* Pandas dataframe css */
/* Taken from: https://github.com/spatialaudio/nbsphinx/blob/fb3ba670fc1ba5f54d4c487573dbc1b4ecf7e9ff/src/nbsphinx.py#L587-L619 */

table.dataframe {
  border: none !important;
  border-collapse: collapse;
  border-spacing: 0;
  border-color: transparent;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
table.dataframe thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
table.dataframe tr,
table.dataframe th,
table.dataframe td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
table.dataframe th {
  font-weight: bold;
}
table.dataframe tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
table.dataframe tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}


/* Adapted from notebook/static/style/style.min.css */

.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}


/* CSS for binder integration */

div.binder-badge {
  margin: 1em auto;
  vertical-align: middle;
}


pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: #ffffcc }
.highlight { background: #eeffcc; }
.highlight .c { color: #408090; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #007020; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408090; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408090; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #007020 } /* Comment.Preproc */
.highlight .cpf { color: #408090; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408090; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408090; background-color: #fff0f0 } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #333333 } /* Generic.Output */
.highlight .gp { color: #c65d09; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #007020; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #007020; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #007020; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #007020 } /* Keyword.Pseudo */
.highlight .kr { color: #007020; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #902000 } /* Keyword.Type */
.highlight .m { color: #208050 } /* Literal.Number */
.highlight .s { color: #4070a0 } /* Literal.String */
.highlight .na { color: #4070a0 } /* Name.Attribute */
.highlight .nb { color: #007020 } /* Name.Builtin */
.highlight .nc { color: #0e84b5; font-weight: bold } /* Name.Class */
.highlight .no { color: #60add5 } /* Name.Constant */
.highlight .nd { color: #555555; font-weight: bold } /* Name.Decorator */
.highlight .ni { color: #d55537; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #007020 } /* Name.Exception */
.highlight .nf { color: #06287e } /* Name.Function */
.highlight .nl { color: #002070; font-weight: bold } /* Name.Label */
.highlight .nn { color: #0e84b5; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #062873; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #bb60d5 } /* Name.Variable */
.highlight .ow { color: #007020; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #208050 } /* Literal.Number.Bin */
.highlight .mf { color: #208050 } /* Literal.Number.Float */
.highlight .mh { color: #208050 } /* Literal.Number.Hex */
.highlight .mi { color: #208050 } /* Literal.Number.Integer */
.highlight .mo { color: #208050 } /* Literal.Number.Oct */
.highlight .sa { color: #4070a0 } /* Literal.String.Affix */
.highlight .sb { color: #4070a0 } /* Literal.String.Backtick */
.highlight .sc { color: #4070a0 } /* Literal.String.Char */
.highlight .dl { color: #4070a0 } /* Literal.String.Delimiter */
.highlight .sd { color: #4070a0; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #4070a0 } /* Literal.String.Double */
.highlight .se { color: #4070a0; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #4070a0 } /* Literal.String.Heredoc */
.highlight .si { color: #70a0d0; font-style: italic } /* Literal.String.Interpol */
.highlight .sx { color: #c65d09 } /* Literal.String.Other */
.highlight .sr { color: #235388 } /* Literal.String.Regex */
.highlight .s1 { color: #4070a0 } /* Literal.String.Single */
.highlight .ss { color: #517918 } /* Literal.String.Symbol */
.highlight .bp { color: #007020 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #06287e } /* Name.Function.Magic */
.highlight .vc { color: #bb60d5 } /* Name.Variable.Class */
.highlight .vg { color: #bb60d5 } /* Name.Variable.Global */
.highlight .vi { color: #bb60d5 } /* Name.Variable.Instance */
.highlight .vm { color: #bb60d5 } /* Name.Variable.Magic */
.highlight .il { color: #208050 } /* Literal.Number.Integer.Long */

/*
Sphinx-Gallery has compatible CSS to fix default sphinx themes
Tested for Sphinx 1.3.1 for all themes: default, alabaster, sphinxdoc,
scrolls, agogo, traditional, nature, haiku, pyramid
Tested for Read the Docs theme 0.1.7 */
.sphx-glr-thumbcontainer {
  background: #fff;
  border: solid #fff 1px;
  -moz-border-radius: 5px;
  -webkit-border-radius: 5px;
  border-radius: 5px;
  box-shadow: none;
  float: left;
  margin: 5px;
  min-height: 230px;
  padding-top: 5px;
  position: relative;
}
.sphx-glr-thumbcontainer:hover {
  border: solid #b4ddfc 1px;
  box-shadow: 0 0 15px rgba(142, 176, 202, 0.5);
}
.sphx-glr-thumbcontainer a.internal {
  bottom: 0;
  display: block;
  left: 0;
  padding: 150px 10px 0;
  position: absolute;
  right: 0;
  top: 0;
}
/* Next one is to avoid Sphinx traditional theme to cover all the
thumbnail with its default link Background color */
.sphx-glr-thumbcontainer a.internal:hover {
  background-color: transparent;
}

.sphx-glr-thumbcontainer p {
  margin: 0 0 .1em 0;
}
.sphx-glr-thumbcontainer .figure {
  margin: 10px;
  width: 160px;
}
.sphx-glr-thumbcontainer img {
  display: inline;
  max-height: 112px;
  max-width: 160px;
}
.sphx-glr-thumbcontainer[tooltip]:hover:after {
  background: rgba(0, 0, 0, 0.8);
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
  color: #fff;
  content: attr(tooltip);
  left: 95%;
  padding: 5px 15px;
  position: absolute;
  z-index: 98;
  width: 220px;
  bottom: 52%;
}
.sphx-glr-thumbcontainer[tooltip]:hover:before {
  border: solid;
  border-color: #333 transparent;
  border-width: 18px 0 0 20px;
  bottom: 58%;
  content: '';
  left: 85%;
  position: absolute;
  z-index: 99;
}

.sphx-glr-script-out {
  color: #888;
  margin: 0;
}
p.sphx-glr-script-out {
    padding-top: 0.7em;
}
.sphx-glr-script-out .highlight {
  background-color: transparent;
  margin-left: 2.5em;
  margin-top: -2.1em;
}
.sphx-glr-script-out .highlight pre {
  background-color: #fafae2;
  border: 0;
  max-height: 30em;
  overflow: auto;
  padding-left: 1ex;
  margin: 0px;
  word-break: break-word;
}
.sphx-glr-script-out + p {
  margin-top: 1.8em;
}
blockquote.sphx-glr-script-out {
  margin-left: 0pt;
}
.sphx-glr-script-out.highlight-pytb .highlight pre {
  color: #000;
  background-color: #ffe4e4;
  border: 1px solid #f66;
  margin-top: 10px;
  padding: 7px;
}

div.sphx-glr-footer {
    text-align: center;
}

div.sphx-glr-download {
  margin: 1em auto;
  vertical-align: middle;
}

div.sphx-glr-download a {
  background-color: #ffc;
  background-image: linear-gradient(to bottom, #FFC, #d5d57e);
  border-radius: 4px;
  border: 1px solid #c2c22d;
  color: #000;
  display: inline-block;
  font-weight: bold;
  padding: 1ex;
  text-align: center;
}

div.sphx-glr-download code.download {
  display: inline-block;
  white-space: normal;
  word-break: normal;
  overflow-wrap: break-word;
  /* border and background are given by the enclosing 'a' */
  border: none;
  background: none;
}

div.sphx-glr-download a:hover {
  box-shadow: inset 0 1px 0 rgba(255,255,255,.1), 0 1px 5px rgba(0,0,0,.25);
  text-decoration: none;
  background-image: none;
  background-color: #d5d57e;
}

.sphx-glr-example-title:target::before {
  display: block;
  content: "";
  margin-top: -50px;
  height: 50px;
  visibility: hidden;
}

ul.sphx-glr-horizontal {
  list-style: none;
  padding: 0;
}
ul.sphx-glr-horizontal li {
  display: inline;
}
ul.sphx-glr-horizontal img {
  height: auto !important;
}

.sphx-glr-single-img {
  margin: auto;
  display: block;
  max-width: 100%;
}

.sphx-glr-multi-img {
  max-width: 42%;
  height: auto;
}

div.sphx-glr-animation {
  margin: auto;
  display: block;
  max-width: 100%;
}
div.sphx-glr-animation .animation{
  display: block;
}

p.sphx-glr-signature a.reference.external {
  -moz-border-radius: 5px;
  -webkit-border-radius: 5px;
  border-radius: 5px;
  padding: 3px;
  font-size: 75%;
  text-align: right;
  margin-left: auto;
  display: table;
}

.sphx-glr-clear{
  clear: both;
}

a.sphx-glr-backref-instance {
  text-decoration: none;
}


/* Left for CSS overrides we need to make in the future */

/* Fix badge on RTD Theme */

/* Please keep RTD badge displayed on your site */
.rst-versions.rst-badge {
    display: block;

    bottom: 50px;

    /* Workaround for mkdocs which set a specific height for this element */
    height: auto;
}

.rst-other-versions {
    text-align: left;
}

.rst-other-versions a {
    border: 0;
}

.rst-other-versions dl {
    margin: 0;
}

.rtd-current-item {
    font-weight: bold;
}


/* Fix RTD theme bottom margin */
.rst-content .line-block {
    margin-bottom: 24px
}

/* Fix for nav bottom padding with flyout */
nav.wy-nav-side {
    padding-bottom: 3em;
}

/* bookmark icon */
.bookmark-added-msg {display: none;}
.bookmark-active {display: none;}
.bookmark-inactive {display: none;}


/* Read the Docs promotional block, only applicable to RTD.org

To support sphinx_rtd_theme, a `wy-menu` element is added. Other themes are
targeted using the theme identifier and use custom elements instead of a CSS
framework html structure.

*/

div.ethical-sidebar,
div.ethical-footer {
    display: block !important;
}
.ethical-sidebar,
.ethical-footer {
    padding: 0.5em;
    margin: 1em 0;
}
.ethical-sidebar img,
.ethical-footer img {
    width: 120px;
    height: 90px;
    display: inline-block;
}
.ethical-sidebar .ethical-callout,
.ethical-footer .ethical-callout {
    padding-top: 1em;
    clear: both;
}
.ethical-sidebar .ethical-pixel,
.ethical-footer .ethical-pixel,
.ethical-fixedfooter .ethical-pixel {
    display: none !important;
}
.ethical-sidebar .ethical-text,
.ethical-footer .ethical-text {
    margin-top: 1em;
}
.ethical-sidebar .ethical-image-link,
.ethical-footer .ethical-image-link {
    border: 0;
}

.ethical-sidebar,
.ethical-footer {
    background-color: #eee;
    border: 1px solid #ccc;
    border-radius: 5px;
    color: #0a0a0a;
    font-size: 14px;
    line-height: 20px;
}

/* Techstack badging */
.ethical-sidebar ul {
    margin: 0 !important;
    padding-left: 0;
    list-style: none;
}
.ethical-sidebar ul li {
    display: inline-block;
    background-color: lightskyblue;
    color: black;
    padding: 0.25em 0.4em;
    font-size: 75%;
    font-weight: 700;
    margin: 0.25em;
    border-radius: 0.25rem;
    text-align: center;
    vertical-align: baseline;
    white-space: nowrap;
    line-height: 1.41;
}
.ethical-sidebar ul li:not(:last-child) {
    margin-right: .25rem;
}

.ethical-sidebar a,
.ethical-sidebar a:visited,
.ethical-sidebar a:hover,
.ethical-sidebar a:active,
.ethical-footer a,
.ethical-footer a:visited,
.ethical-footer a:hover,
.ethical-footer a:active {
    color: #0a0a0a;
    text-decoration: none !important;
    border-bottom: 0 !important;
}

.ethical-callout a {
    color: #707070 !important;
    text-decoration: none !important;
}

/* Sidebar promotions */
.ethical-sidebar {
    text-align: center;
    max-width: 300px;
    margin-left: auto;
    margin-right: auto;
}

/* Footer promotions */
.ethical-footer {
    text-align: left;

    font-size: 14px;
    line-height: 20px;
}
.ethical-footer img {
    float: right;
    margin-left: 25px;
}
.ethical-footer .ethical-callout {
    text-align: center;
}
.ethical-footer small {
    font-size: 10px;
}

/* Fixed footer promotions */
.ethical-fixedfooter {
    box-sizing: border-box;
    position: fixed;
    bottom: 0;
    left: 0;
    z-index: 100;
    background-color: #eee;
    border-top: 1px solid #bfbfbf;
    font-size: 12px;
    line-height: 1.5;
    padding: 0.5em 1.5em;
    text-align: center;
    color: #404040;
    width: 100%;    /* Fallback for Opera Mini */
    width: 100vw;
}
@media (min-width: 769px) {
    /* Improve viewing on non-mobile */
    .ethical-fixedfooter {
        font-size: 13px;
        padding: 1em 1.5em;
    }
}
.ethical-fixedfooter .ethical-text:before {
    margin-right: 4px;
    padding: 2px 6px;
    border-radius: 3px;
    background-color: #4caf50;
    color: #fff;
    content: "Sponsored";
}
.ethical-fixedfooter .ethical-callout {
    color: #999;
    padding-left: 6px;
    white-space: nowrap;
}
.ethical-fixedfooter a,
.ethical-fixedfooter a:hover,
.ethical-fixedfooter a:active,
.ethical-fixedfooter a:visited {
    color: #404040;
    text-decoration: none;
}
.ethical-fixedfooter .ethical-close {
    position: absolute;
    top: 0;
    right: 5px;
    font-size: 20px;
    line-height: 20px;
}

/* RTD Theme specific customizations */
.wy-nav-side .ethical-rtd {
    /* RTD theme doesn't correctly set the sidebar width */
    max-width: 300px;
    padding: 0 1em;
}
.ethical-rtd .ethical-sidebar {
    /* RTD theme doesn't set sidebar text color */
    color: #b3b3b3;

    font-size: 14px;
    line-height: 20px;
}

@media (min-width: 769px) {
    /* Make sure the fixed footer ad is under the RTD theme version selector */
    .wy-body-for-nav .ethical-fixedfooter {
        padding-left: 300px;
    }
}

/* Alabaster specific customizations */
.ethical-alabaster a.ethical-image-link {
    /* Alabaster adds a border even to image links on hover */
    border: 0 !important;
}
.ethical-alabaster hr {
    /* Alabaster needs some extra spacing before the footer ad */
    margin-top: 2em;
}
.ethical-alabaster::before {
    /* Alabaster's search box above the ad is floating */
    clear: both;
    content: '';
    display: table;
    margin-top: 3em;
}

/* Dark theme */
.ethical-dark-theme .ethical-sidebar {
    background-color: #4e4b4b;
    border: 1px solid #a0a0a0;
    color: #c2c2c2 !important;
}
.ethical-dark-theme a,
.ethical-dark-theme a:visited {
    color: #e6e6e6 !important;
    border-bottom: 0 !important;
}
.ethical-dark-theme .ethical-callout a {
    color: #b3b3b3 !important;
}


/* Ad block nag */
.keep-us-sustainable {
    padding: .5em;
    margin: 1em auto;
    text-align: center;
    border: 1px dotted #8ECC4C;
    max-width: 300px;
}
.keep-us-sustainable a,
.keep-us-sustainable a:hover,
.keep-us-sustainable a:visited {
    text-decoration: none;
}
/* Read the Docs theme specific fixes */
.wy-nav-side .keep-us-sustainable {
    margin: 1em 2em 1em 1em;
    color: #b3b3b3;
}
.wy-nav-side .keep-us-sustainable a {
    color: #efefef;
    font-size: 14px;
    line-height: 20px;
}

/* Margin between the search results */
.rtd_search_hits_spacing {
    margin: 10px 0;
}


/*
 * plot_directive.css
 * ~~~~~~~~~~~~
 *
 * Stylesheet controlling images created using the `plot` directive within
 * Sphinx.
 *
 * :copyright: Copyright 2020-* by the Matplotlib development team.
 * :license: Matplotlib, see LICENSE for details.
 *
 */

img.plot-directive {
    border: 0;
    max-width: 100%;
}

    
    </style>
    
  </head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
            <a href="../index.html">
            <img src="https://raw.githubusercontent.com/dmlc/dmlc.github.io/master/img/logo-m/xgboost.png" class="logo" alt="Logo">
          </a>
              <div class="version">
                stable
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs">
    <input type="hidden" name="check_keywords" value="yes">
    <input type="hidden" name="area" value="default">
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current" aria-expanded="true">
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../build.html">Building From Source</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started.html">Get Started with XGBoost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html">XGBoost Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discuss.xgboost.ai">XGBoost User Forum</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gpu/index.html">GPU Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parameter.html">XGBoost Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prediction.html">Prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../treemethod.html">Tree Methods</a></li>
<li class="toctree-l1 current" aria-expanded="true"><a class="reference internal" href="index.html"><button class="toctree-expand" title="Open/close menu"></button>Python Package</a><ul class="" aria-expanded="false">
<li class="toctree-l2"><a class="reference internal" href="python_intro.html">Python Package Introduction</a></li>
<li class="toctree-l2 current" aria-expanded="true"><a class="reference internal current" href="#" aria-expanded="true">Python API Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="callbacks.html">Callback Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="model.html">Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples/index.html">XGBoost Python Feature Walkthrough</a></li>
<li class="toctree-l2"><a class="reference internal" href="dask-examples/index.html">XGBoost Dask Feature Walkthrough</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../R-package/index.html">R Package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../jvm/index.html">JVM Package</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/ankane/xgb">Ruby Package</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/kongzii/SwiftXGBoost">Swift Package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../julia.html">Julia Package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../c.html">C Package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../c%2B%2B.html">C++ Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cli.html">CLI Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contrib/index.html">Contribute to XGBoost</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">xgboost</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> »</li>
          <li><a href="index.html">XGBoost Python Package</a> »</li>
      <li>Python API Reference</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/dmlc/xgboost/blob/5d92a7d936fc3fad4c7ecb6031c3c1c7da882a14/doc/python/python_api.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="python-api-reference">
<h1>Python API Reference<a class="headerlink" href="#python-api-reference" title="Permalink to this headline"></a></h1>
<p>This page gives the Python API reference of xgboost, please also refer to Python Package Introduction for more information about the Python package.</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#global-configuration" id="id3">Global Configuration</a></p></li>
<li><p><a class="reference internal" href="#module-xgboost.core" id="id4">Core Data Structure</a></p></li>
<li><p><a class="reference internal" href="#module-xgboost.training" id="id5">Learning API</a></p></li>
<li><p><a class="reference internal" href="#module-xgboost.sklearn" id="id6">Scikit-Learn API</a></p></li>
<li><p><a class="reference internal" href="#module-xgboost.plotting" id="id7">Plotting API</a></p></li>
<li><p><a class="reference internal" href="#module-xgboost.callback" id="id8">Callback API</a></p></li>
<li><p><a class="reference internal" href="#module-xgboost.dask" id="id9">Dask API</a></p>
<ul>
<li><p><a class="reference internal" href="#dask-extensions-for-distributed-training" id="id10">Dask extensions for distributed training</a></p>
<ul>
<li><p><a class="reference internal" href="#optional-dask-configuration" id="id11">Optional dask configuration</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<section id="global-configuration">
<h2>Global Configuration<a class="headerlink" href="#global-configuration" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="xgboost.config_context">
<span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">config_context</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">new_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.config_context" title="Permalink to this definition"></a></dt>
<dd><p>Context manager for global XGBoost configuration.</p>
<p>Global configuration consists of a collection of parameters that can be applied in the
global scope. See <a class="reference internal" href="../parameter.html#global-config"><span class="std std-ref">Global Configuration</span></a> for the full list of parameters supported in
the global configuration.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All settings, not just those presently modified, will be returned to their
previous values when the context manager is exited. This is not thread-safe.</p>
</div>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>new_config</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>Any</em><em>]</em>) – Keyword arguments representing the parameters and their values</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>

<span class="c1"># Show all messages, including ones pertaining to debugging</span>
<span class="n">xgb</span><span class="o">.</span><span class="n">set_config</span><span class="p">(</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Get current value of global configuration</span>
<span class="c1"># This is a dict containing all parameters in the global configuration,</span>
<span class="c1"># including 'verbosity'</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">config</span><span class="p">[</span><span class="s1">'verbosity'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>

<span class="c1"># Example of using the context manager xgb.config_context().</span>
<span class="c1"># The context manager will restore the previous value of the global</span>
<span class="c1"># configuration upon exiting.</span>
<span class="k">with</span> <span class="n">xgb</span><span class="o">.</span><span class="n">config_context</span><span class="p">(</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># Suppress warning caused by model generated with XGBoost version &lt; 1.0.0</span>
    <span class="n">bst</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">Booster</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s1">'./old_model.bin'</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">xgb</span><span class="o">.</span><span class="n">get_config</span><span class="p">()[</span><span class="s1">'verbosity'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>  <span class="c1"># old value restored</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#xgboost.set_config" title="xgboost.set_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_config</span></code></a></dt><dd><p>Set global XGBoost configuration</p>
</dd>
<dt><a class="reference internal" href="#xgboost.get_config" title="xgboost.get_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_config</span></code></a></dt><dd><p>Get current values of the global configuration</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="xgboost.set_config">
<span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">set_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">new_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.set_config" title="Permalink to this definition"></a></dt>
<dd><p>Set global configuration.</p>
<p>Global configuration consists of a collection of parameters that can be applied in the
global scope. See <a class="reference internal" href="../parameter.html#global-config"><span class="std std-ref">Global Configuration</span></a> for the full list of parameters supported in
the global configuration.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>new_config</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>Any</em><em>]</em>) – Keyword arguments representing the parameters and their values</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>

<span class="c1"># Show all messages, including ones pertaining to debugging</span>
<span class="n">xgb</span><span class="o">.</span><span class="n">set_config</span><span class="p">(</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Get current value of global configuration</span>
<span class="c1"># This is a dict containing all parameters in the global configuration,</span>
<span class="c1"># including 'verbosity'</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">config</span><span class="p">[</span><span class="s1">'verbosity'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>

<span class="c1"># Example of using the context manager xgb.config_context().</span>
<span class="c1"># The context manager will restore the previous value of the global</span>
<span class="c1"># configuration upon exiting.</span>
<span class="k">with</span> <span class="n">xgb</span><span class="o">.</span><span class="n">config_context</span><span class="p">(</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># Suppress warning caused by model generated with XGBoost version &lt; 1.0.0</span>
    <span class="n">bst</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">Booster</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s1">'./old_model.bin'</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">xgb</span><span class="o">.</span><span class="n">get_config</span><span class="p">()[</span><span class="s1">'verbosity'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>  <span class="c1"># old value restored</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="xgboost.get_config">
<span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Get current values of the global configuration.</p>
<p>Global configuration consists of a collection of parameters that can be applied in the
global scope. See <a class="reference internal" href="../parameter.html#global-config"><span class="std std-ref">Global Configuration</span></a> for the full list of parameters supported in
the global configuration.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>args</strong> – The list of global parameters and their values</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Dict[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, Any]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>

<span class="c1"># Show all messages, including ones pertaining to debugging</span>
<span class="n">xgb</span><span class="o">.</span><span class="n">set_config</span><span class="p">(</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Get current value of global configuration</span>
<span class="c1"># This is a dict containing all parameters in the global configuration,</span>
<span class="c1"># including 'verbosity'</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">config</span><span class="p">[</span><span class="s1">'verbosity'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>

<span class="c1"># Example of using the context manager xgb.config_context().</span>
<span class="c1"># The context manager will restore the previous value of the global</span>
<span class="c1"># configuration upon exiting.</span>
<span class="k">with</span> <span class="n">xgb</span><span class="o">.</span><span class="n">config_context</span><span class="p">(</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># Suppress warning caused by model generated with XGBoost version &lt; 1.0.0</span>
    <span class="n">bst</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">Booster</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s1">'./old_model.bin'</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">xgb</span><span class="o">.</span><span class="n">get_config</span><span class="p">()[</span><span class="s1">'verbosity'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>  <span class="c1"># old value restored</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-xgboost.core">
<span id="core-data-structure"></span><h2>Core Data Structure<a class="headerlink" href="#module-xgboost.core" title="Permalink to this headline"></a></h2>
<p>Core XGBoost Library.</p>
<dl class="py class">
<dt class="sig sig-object py" id="xgboost.DMatrix">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">DMatrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nthread</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_lower_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_upper_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Data Matrix used in XGBoost.</p>
<p>DMatrix is an internal data structure that is used by XGBoost,
which is optimized for both memory efficiency and training speed.
You can construct DMatrix from multiple different sources of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>os.PathLike/string/numpy.array/scipy.sparse/pd.DataFrame/</em>) – dt.Frame/cudf.DataFrame/cupy.array/dlpack
Data source of DMatrix.
When data is string or os.PathLike type, it represents the path
libsvm format txt file, csv file (by specifying uri parameter
‘path_to_csv?format=csv’), or binary file that xgboost can read
from.</p></li>
<li><p><strong>label</strong> (<em>array_like</em>) – Label of the training data.</p></li>
<li><p><strong>weight</strong> (<em>array_like</em>) – </p><p>Weight for each instance.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For ranking task, weights are per-group.</p>
<p>In ranking task, one weight is assigned to each group (not each
data point). This is because we only care about the relative
ordering of data points within each group, so it doesn’t make
sense to assign weights to individual data points.</p>
</div>
<p></p></li>
<li><p><strong>base_margin</strong> (<em>array_like</em>) – Base margin used for boosting from existing model.</p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>optional</em>) – Value in the input data which needs to be present as a missing
value. If None, defaults to np.nan.</p></li>
<li><p><strong>silent</strong> (<em>boolean</em><em>, </em><em>optional</em>) – Whether print messages during construction</p></li>
<li><p><strong>feature_names</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a><em>, </em><em>optional</em>) – Set names for features.</p></li>
<li><p><strong>feature_types</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Set types for features.  When <cite>enable_categorical</cite> is set to <cite>True</cite>, string
“c” represents categorical data type.</p></li>
<li><p><strong>nthread</strong> (<em>integer</em><em>, </em><em>optional</em>) – Number of threads to use for loading data when parallelization is
applicable. If -1, uses maximum threads available on the system.</p></li>
<li><p><strong>group</strong> (<em>array_like</em>) – Group size for all ranking group.</p></li>
<li><p><strong>qid</strong> (<em>array_like</em>) – Query ID for data samples, used for ranking.</p></li>
<li><p><strong>label_lower_bound</strong> (<em>array_like</em>) – Lower bound for survival training.</p></li>
<li><p><strong>label_upper_bound</strong> (<em>array_like</em>) – Upper bound for survival training.</p></li>
<li><p><strong>feature_weights</strong> (<em>array_like</em><em>, </em><em>optional</em>) – Set feature weights for column sampling.</p></li>
<li><p><strong>enable_categorical</strong> (<em>boolean</em><em>, </em><em>optional</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support of specializing for categorical features.  Do not set
to True unless you are interested in development. Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="xgboost.DMatrix.feature_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#xgboost.DMatrix.feature_names" title="Permalink to this definition"></a></dt>
<dd><p>Get feature names (column labels).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>feature_names</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#list" title="(in Python v3.6)">list</a> or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.DMatrix.feature_types">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_types</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#xgboost.DMatrix.feature_types" title="Permalink to this definition"></a></dt>
<dd><p>Get feature types (column types).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>feature_types</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#list" title="(in Python v3.6)">list</a> or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.get_base_margin">
<span class="sig-name descname"><span class="pre">get_base_margin</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.get_base_margin" title="Permalink to this definition"></a></dt>
<dd><p>Get the base margin of the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>base_margin</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.get_float_info">
<span class="sig-name descname"><span class="pre">get_float_info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">field</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.get_float_info" title="Permalink to this definition"></a></dt>
<dd><p>Get float property from the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>field</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The field name of the information</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>info</strong> – a numpy array of float information of the data</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.get_group">
<span class="sig-name descname"><span class="pre">get_group</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.get_group" title="Permalink to this definition"></a></dt>
<dd><p>Get the group of the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>group</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.get_label">
<span class="sig-name descname"><span class="pre">get_label</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.get_label" title="Permalink to this definition"></a></dt>
<dd><p>Get the label of the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>label</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.get_uint_info">
<span class="sig-name descname"><span class="pre">get_uint_info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">field</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.get_uint_info" title="Permalink to this definition"></a></dt>
<dd><p>Get unsigned integer property from the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>field</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The field name of the information</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>info</strong> – a numpy array of unsigned integer information of the data</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.get_weight">
<span class="sig-name descname"><span class="pre">get_weight</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.get_weight" title="Permalink to this definition"></a></dt>
<dd><p>Get the weight of the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>weight</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.num_col">
<span class="sig-name descname"><span class="pre">num_col</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.num_col" title="Permalink to this definition"></a></dt>
<dd><p>Get the number of columns (features) in the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>number of columns</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.num_row">
<span class="sig-name descname"><span class="pre">num_row</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.num_row" title="Permalink to this definition"></a></dt>
<dd><p>Get the number of rows in the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>number of rows</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.save_binary">
<span class="sig-name descname"><span class="pre">save_binary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.save_binary" title="Permalink to this definition"></a></dt>
<dd><p>Save DMatrix to an XGBoost buffer.  Saved binary can be later loaded
by providing the path to <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">xgboost.DMatrix()</span></code></a> as input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Name of the output buffer file.</p></li>
<li><p><strong>silent</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em> (</em><em>optional; default: True</em><em>)</em>) – If set, the output is suppressed.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.set_base_margin">
<span class="sig-name descname"><span class="pre">set_base_margin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">margin</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.set_base_margin" title="Permalink to this definition"></a></dt>
<dd><p>Set base margin of booster to start from.</p>
<p>This can be used to specify a prediction value of existing model to be
base_margin However, remember margin is needed, instead of transformed
prediction e.g. for logistic regression: need to put in value before
logistic transformation see also example/demo.py</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>margin</strong> (<em>array like</em>) – Prediction margin of each datapoint</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.set_float_info">
<span class="sig-name descname"><span class="pre">set_float_info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">field</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.set_float_info" title="Permalink to this definition"></a></dt>
<dd><p>Set float type property into the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>field</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The field name of the information</p></li>
<li><p><strong>data</strong> (<em>numpy array</em>) – The array of data to be set</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.set_float_info_npy2d">
<span class="sig-name descname"><span class="pre">set_float_info_npy2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">field</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.set_float_info_npy2d" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Set float type property into the DMatrix</dt><dd><p>for numpy 2d array input</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>field</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The field name of the information</p></li>
<li><p><strong>data</strong> (<em>numpy array</em>) – The array of data to be set</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.set_group">
<span class="sig-name descname"><span class="pre">set_group</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">group</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.set_group" title="Permalink to this definition"></a></dt>
<dd><p>Set group size of DMatrix (used for ranking).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>group</strong> (<em>array like</em>) – Group size of each group</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.set_info">
<span class="sig-name descname"><span class="pre">set_info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_lower_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_upper_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.set_info" title="Permalink to this definition"></a></dt>
<dd><p>Set meta info for DMatrix.  See doc string for <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.DMatrix</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>label</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
<li><p><strong>weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
<li><p><strong>qid</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
<li><p><strong>label_lower_bound</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
<li><p><strong>label_upper_bound</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
<li><p><strong>feature_names</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – </p></li>
<li><p><strong>feature_types</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – </p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.set_label">
<span class="sig-name descname"><span class="pre">set_label</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.set_label" title="Permalink to this definition"></a></dt>
<dd><p>Set label of dmatrix</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>label</strong> (<em>array like</em>) – The label information to be set into DMatrix</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.set_uint_info">
<span class="sig-name descname"><span class="pre">set_uint_info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">field</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.set_uint_info" title="Permalink to this definition"></a></dt>
<dd><p>Set uint type property into the DMatrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>field</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The field name of the information</p></li>
<li><p><strong>data</strong> (<em>numpy array</em>) – The array of data to be set</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.set_weight">
<span class="sig-name descname"><span class="pre">set_weight</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weight</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.set_weight" title="Permalink to this definition"></a></dt>
<dd><p>Set weight of each instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>weight</strong> (<em>array like</em>) – </p><p>Weight for each data point</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For ranking task, weights are per-group.</p>
<p>In ranking task, one weight is assigned to each group (not each
data point). This is because we only care about the relative
ordering of data points within each group, so it doesn’t make
sense to assign weights to individual data points.</p>
</div>
<p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.DMatrix.slice">
<span class="sig-name descname"><span class="pre">slice</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rindex</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DMatrix.slice" title="Permalink to this definition"></a></dt>
<dd><p>Slice the DMatrix and return a new DMatrix that only contains <cite>rindex</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rindex</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em>) – List of indices to be selected.</p></li>
<li><p><strong>allow_groups</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Allow slicing of a matrix with a groups attribute</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new DMatrix containing only selected indices.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>res</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.DeviceQuantileDMatrix">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">DeviceQuantileDMatrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nthread</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_bin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_lower_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_upper_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.DeviceQuantileDMatrix" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.core.DMatrix</span></code></a></p>
<p>Device memory Data Matrix used in XGBoost for training with tree_method=’gpu_hist’. Do
not use this for test/validation tasks as some information may be lost in
quantisation. This DMatrix is primarily designed to save memory in training from
device memory inputs by avoiding intermediate storage. Set max_bin to control the
number of bins during quantisation.  See doc string in <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.DMatrix</span></code></a> for
documents on meta info.</p>
<p>You can construct DeviceQuantileDMatrix from cupy/cudf/dlpack.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.1.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>os.PathLike/string/numpy.array/scipy.sparse/pd.DataFrame/</em>) – dt.Frame/cudf.DataFrame/cupy.array/dlpack
Data source of DMatrix.
When data is string or os.PathLike type, it represents the path
libsvm format txt file, csv file (by specifying uri parameter
‘path_to_csv?format=csv’), or binary file that xgboost can read
from.</p></li>
<li><p><strong>label</strong> (<em>array_like</em>) – Label of the training data.</p></li>
<li><p><strong>weight</strong> (<em>array_like</em>) – </p><p>Weight for each instance.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For ranking task, weights are per-group.</p>
<p>In ranking task, one weight is assigned to each group (not each
data point). This is because we only care about the relative
ordering of data points within each group, so it doesn’t make
sense to assign weights to individual data points.</p>
</div>
<p></p></li>
<li><p><strong>base_margin</strong> (<em>array_like</em>) – Base margin used for boosting from existing model.</p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>optional</em>) – Value in the input data which needs to be present as a missing
value. If None, defaults to np.nan.</p></li>
<li><p><strong>silent</strong> (<em>boolean</em><em>, </em><em>optional</em>) – Whether print messages during construction</p></li>
<li><p><strong>feature_names</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a><em>, </em><em>optional</em>) – Set names for features.</p></li>
<li><p><strong>feature_types</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Set types for features.  When <cite>enable_categorical</cite> is set to <cite>True</cite>, string
“c” represents categorical data type.</p></li>
<li><p><strong>nthread</strong> (<em>integer</em><em>, </em><em>optional</em>) – Number of threads to use for loading data when parallelization is
applicable. If -1, uses maximum threads available on the system.</p></li>
<li><p><strong>group</strong> (<em>array_like</em>) – Group size for all ranking group.</p></li>
<li><p><strong>qid</strong> (<em>array_like</em>) – Query ID for data samples, used for ranking.</p></li>
<li><p><strong>label_lower_bound</strong> (<em>array_like</em>) – Lower bound for survival training.</p></li>
<li><p><strong>label_upper_bound</strong> (<em>array_like</em>) – Upper bound for survival training.</p></li>
<li><p><strong>feature_weights</strong> (<em>array_like</em><em>, </em><em>optional</em>) – Set feature weights for column sampling.</p></li>
<li><p><strong>enable_categorical</strong> (<em>boolean</em><em>, </em><em>optional</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support of specializing for categorical features.  Do not set
to True unless you are interested in development. Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_bin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.Booster">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">Booster</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>A Booster of XGBoost.</p>
<p>Booster is the model of xgboost, that contains low level routines for
training, prediction and evaluation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a>) – Parameters for boosters.</p></li>
<li><p><strong>cache</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) – List of cache items.</p></li>
<li><p><strong>model_file</strong> (<em>string/os.PathLike/Booster/bytearray</em>) – Path to the model file if it’s string or PathLike.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.attr">
<span class="sig-name descname"><span class="pre">attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.attr" title="Permalink to this definition"></a></dt>
<dd><p>Get attribute string from the Booster.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>key</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The key to get attribute from.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>value</strong> – The attribute value of the key, returns None if attribute do not exist.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.attributes">
<span class="sig-name descname"><span class="pre">attributes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.attributes" title="Permalink to this definition"></a></dt>
<dd><p>Get attributes stored in the Booster as a dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>result</strong> – Returns an empty dict if there’s no attributes.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dictionary of  attribute_name: attribute_value pairs of strings.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.boost">
<span class="sig-name descname"><span class="pre">boost</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtrain</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hess</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.boost" title="Permalink to this definition"></a></dt>
<dd><p>Boost the booster for one iteration, with customized gradient
statistics.  Like <a class="reference internal" href="#xgboost.Booster.update" title="xgboost.Booster.update"><code class="xref py py-func docutils literal notranslate"><span class="pre">xgboost.Booster.update()</span></code></a>, this
function should not be called directly by users.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dtrain</strong> (<a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a>) – The training DMatrix.</p></li>
<li><p><strong>grad</strong> (<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a>) – The first order of gradient.</p></li>
<li><p><strong>hess</strong> (<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a>) – The second order of gradient.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.copy" title="Permalink to this definition"></a></dt>
<dd><p>Copy the booster object.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong> – a copied booster model</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><cite>Booster</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.dump_model">
<span class="sig-name descname"><span class="pre">dump_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_stats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dump_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'text'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.dump_model" title="Permalink to this definition"></a></dt>
<dd><p>Dump model into a text or JSON file.  Unlike <a class="reference internal" href="#xgboost.Booster.save_model" title="xgboost.Booster.save_model"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_model()</span></code></a>, the
output format is primarily used for visualization or interpretation,
hence it’s more human readable but cannot be loaded back to XGBoost.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fout</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name.</p></li>
<li><p><strong>fmap</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>, </em><em>optional</em>) – Name of the file containing feature map names.</p></li>
<li><p><strong>with_stats</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>optional</em>) – Controls whether the split statistics are output.</p></li>
<li><p><strong>dump_format</strong> (<em>string</em><em>, </em><em>optional</em>) – Format of model dump file. Can be ‘text’ or ‘json’.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'eval'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.eval" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the model on mat.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a>) – The dmatrix storing the input.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The name of the dataset.</p></li>
<li><p><strong>iteration</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – The current iteration number.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – Evaluation result string.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.eval_set">
<span class="sig-name descname"><span class="pre">eval_set</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">evals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.eval_set" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate a set of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>evals</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – List of items to be evaluated.</p></li>
<li><p><strong>iteration</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Current iteration.</p></li>
<li><p><strong>feval</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em>) – Custom evaluation function.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – Evaluation result string.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.Booster.feature_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#xgboost.Booster.feature_names" title="Permalink to this definition"></a></dt>
<dd><p>Feature names for this booster.  Can be directly set by input data or by
assignment.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.Booster.feature_types">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_types</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#xgboost.Booster.feature_types" title="Permalink to this definition"></a></dt>
<dd><p>Feature types for this booster.  Can be directly set by input data or by
assignment.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.get_dump">
<span class="sig-name descname"><span class="pre">get_dump</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_stats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dump_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'text'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.get_dump" title="Permalink to this definition"></a></dt>
<dd><p>Returns the model dump as a list of strings.  Unlike <a class="reference internal" href="#xgboost.Booster.save_model" title="xgboost.Booster.save_model"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_model()</span></code></a>, the output
format is primarily used for visualization or interpretation, hence it’s more
human readable but cannot be loaded back to XGBoost.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fmap</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Name of the file containing feature map names.</p></li>
<li><p><strong>with_stats</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Controls whether the split statistics are output.</p></li>
<li><p><strong>dump_format</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – Format of model dump. Can be ‘text’, ‘json’ or ‘dot’.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.get_fscore">
<span class="sig-name descname"><span class="pre">get_fscore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.get_fscore" title="Permalink to this definition"></a></dt>
<dd><p>Get feature importance of each feature.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Zero-importance features will not be included</p>
<p>Keep in mind that this function does not include zero-importance feature, i.e.
those features that have not been used in any split conditions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fmap</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – The name of feature map file</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a>]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.get_score">
<span class="sig-name descname"><span class="pre">get_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">importance_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'weight'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.get_score" title="Permalink to this definition"></a></dt>
<dd><p>Get feature importance of each feature.
For tree model Importance type can be defined as:</p>
<ul class="simple">
<li><p>‘weight’: the number of times a feature is used to split the data across all trees.</p></li>
<li><p>‘gain’: the average gain across all splits the feature is used in.</p></li>
<li><p>‘cover’: the average coverage across all splits the feature is used in.</p></li>
<li><p>‘total_gain’: the total gain across all splits the feature is used in.</p></li>
<li><p>‘total_cover’: the total coverage across all splits the feature is used in.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Zero-importance features will not be included</p>
<p>Keep in mind that this function does not include zero-importance feature, i.e.
those features that have not been used in any split conditions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fmap</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – The name of feature map file.</p></li>
<li><p><strong>importance_type</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – One of the importance types defined above.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p><ul class="simple">
<li><p>A map between feature names and their scores.  When <cite>gblinear</cite> is used for</p></li>
<li><p><em>multi-class classification the scores for each feature is a list with length</em></p></li>
<li><p><cite>n_classes</cite>, otherwise they’re scalars.</p></li>
</ul>
<p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a>]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.get_split_value_histogram">
<span class="sig-name descname"><span class="pre">get_split_value_histogram</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_pandas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.get_split_value_histogram" title="Permalink to this definition"></a></dt>
<dd><p>Get split value histogram of a feature</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The name of the feature.</p></li>
<li><p><strong>fmap</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em> (</em><em>optional</em><em>)</em>) – The name of feature map file.</p></li>
<li><p><strong>bin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><em>default None</em>) – The maximum number of bins.
Number of bins equals number of unique split values n_unique,
if bins == None or bins &gt; n_unique.</p></li>
<li><p><strong>as_pandas</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>default True</em>) – Return pd.DataFrame when pandas is installed.
If False or pandas is not installed, return numpy ndarray.</p></li>
<li><p><strong>bins</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p><ul class="simple">
<li><p><em>a histogram of used splitting values for the specified feature</em></p></li>
<li><p><em>either as numpy array or pandas DataFrame.</em></p></li>
</ul>
<p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a>[<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)">numpy.ndarray</a>, pandas.core.frame.DataFrame]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.inplace_predict">
<span class="sig-name descname"><span class="pre">inplace_predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'value'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.inplace_predict" title="Permalink to this definition"></a></dt>
<dd><p>Run prediction in-place, Unlike <a class="reference internal" href="#xgboost.Booster.predict" title="xgboost.Booster.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a> method, inplace prediction does not
cache the prediction result.</p>
<p>Calling only <code class="docutils literal notranslate"><span class="pre">inplace_predict</span></code> in multiple threads is safe and lock
free.  But the safety does not hold when used in conjunction with other
methods. E.g. you can’t train the booster in one thread and perform
prediction in the other.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">booster</span><span class="o">.</span><span class="n">set_param</span><span class="p">({</span><span class="s1">'predictor'</span><span class="p">:</span> <span class="s1">'gpu_predictor'</span><span class="p">})</span>
<span class="n">booster</span><span class="o">.</span><span class="n">inplace_predict</span><span class="p">(</span><span class="n">cupy_array</span><span class="p">)</span>

<span class="n">booster</span><span class="o">.</span><span class="n">set_param</span><span class="p">({</span><span class="s1">'predictor'</span><span class="p">:</span> <span class="s1">'cpu_predictor})</span>
<span class="n">booster</span><span class="o">.</span><span class="n">inplace_predict</span><span class="p">(</span><span class="n">numpy_array</span><span class="p">)</span>
</pre></div>
</div>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.1.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>numpy.ndarray/scipy.sparse.csr_matrix/cupy.ndarray/</em>) – cudf.DataFrame/pd.DataFrame
The input data, must not be a view for numpy array.  Set
<code class="docutils literal notranslate"><span class="pre">predictor</span></code> to <code class="docutils literal notranslate"><span class="pre">gpu_predictor</span></code> for running prediction on CuPy
array or CuDF DataFrame.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – See <a class="reference internal" href="#xgboost.Booster.predict" title="xgboost.Booster.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a> for details.</p></li>
<li><p><strong>predict_type</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – </p><ul>
<li><p><cite>value</cite> Output model prediction values.</p></li>
<li><p><cite>margin</cite> Output the raw untransformed margin value.</p></li>
</ul>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – See <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.DMatrix</span></code></a> for details.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – See <a class="reference internal" href="#xgboost.Booster.predict" title="xgboost.Booster.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">xgboost.Booster.predict()</span></code></a> for details.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p><p>See <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.DMatrix</span></code></a> for details.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
<li><p><strong>strict_shape</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><p>See <a class="reference internal" href="#xgboost.Booster.predict" title="xgboost.Booster.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">xgboost.Booster.predict()</span></code></a> for details.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>prediction</strong> – The prediction result.  When input data is on GPU, prediction
result is stored in a cupy array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy.ndarray/cupy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.load_config">
<span class="sig-name descname"><span class="pre">load_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.load_config" title="Permalink to this definition"></a></dt>
<dd><p>Load configuration returned by <cite>save_config</cite>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.num_boosted_rounds">
<span class="sig-name descname"><span class="pre">num_boosted_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.num_boosted_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Get number of boosted rounds.  For gblinear this is reset to 0 after
serializing the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.num_features">
<span class="sig-name descname"><span class="pre">num_features</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.num_features" title="Permalink to this definition"></a></dt>
<dd><p>Number of features in booster.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_contribs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approx_contribs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_interactions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with data.  The full model will be used unless <cite>iteration_range</cite> is specified,
meaning user have to either slice the model or use the <code class="docutils literal notranslate"><span class="pre">best_iteration</span></code>
attribute to get prediction from best model returned from early stopping.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>See <a class="reference internal" href="../prediction.html"><span class="doc">Prediction</span></a> for issues like thread safety and a
summary of outputs from this function.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a>) – The dmatrix storing the input.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>pred_leaf</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this option is on, the output will be a matrix of (nsample,
ntrees) with each record indicating the predicted leaf index of
each sample in each tree.  Note that the leaf index of a tree is
unique per tree, so you may find leaf 1 in both tree 1 and tree 0.</p></li>
<li><p><strong>pred_contribs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True the output will be a matrix of size (nsample,
nfeats + 1) with each record indicating the feature contributions
(SHAP values) for that prediction. The sum of all feature
contributions is equal to the raw untransformed margin value of the
prediction. Note the final column is the bias term.</p></li>
<li><p><strong>approx_contribs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Approximate the contributions of each feature.  Used when <code class="docutils literal notranslate"><span class="pre">pred_contribs</span></code> or
<code class="docutils literal notranslate"><span class="pre">pred_interactions</span></code> is set to True.  Changing the default of this parameter
(False) is not recommended.</p></li>
<li><p><strong>pred_interactions</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True the output will be a matrix of size (nsample,
nfeats + 1, nfeats + 1) indicating the SHAP interaction values for
each pair of features. The sum of each row (or column) of the
interaction values equals the corresponding SHAP value (from
pred_contribs), and the sum of the entire matrix equals the raw
untransformed margin value of the prediction. Note the last row and
column correspond to the bias term.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s
feature_names are identical.  Otherwise, it is assumed that the
feature_names are the same.</p></li>
<li><p><strong>training</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><p>Whether the prediction value is used for training.  This can effect <cite>dart</cite>
booster, which performs dropouts during training iterations but use all trees
for inference. If you want to obtain result with dropouts, set this parameter
to <cite>True</cite>.  Also, the parameter is set to true when obtaining prediction for
custom objective function.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.0.</span></p>
</div>
<p></p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <cite>iteration_range=(10,
20)</cite>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
<li><p><strong>strict_shape</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><p>When set to True, output shape is invariant to whether classification is used.
For both value and margin prediction, the output shape is (n_samples,
n_groups), n_groups == 1 when multi-class is not used.  Default to False, in
which case the output shape can be (n_samples, ) if multi-class is not used.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>prediction</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.save_config">
<span class="sig-name descname"><span class="pre">save_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.save_config" title="Permalink to this definition"></a></dt>
<dd><p>Output internal parameter configuration of Booster as a JSON
string.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.save_raw">
<span class="sig-name descname"><span class="pre">save_raw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">raw_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'deprecated'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.save_raw" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a in memory buffer representation instead of file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>raw_format</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – Format of output buffer. Can be <cite>json</cite>, <cite>ubj</cite> or <cite>deprecated</cite>.  Right now
the default is <cite>deprecated</cite> but it will be changed to <cite>ubj</cite> (univeral binary
json) in the future.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>An in memory buffer representation of the model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.set_attr">
<span class="sig-name descname"><span class="pre">set_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.set_attr" title="Permalink to this definition"></a></dt>
<dd><p>Set the attribute of the Booster.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>**kwargs</strong> – The attributes to set. Setting a value to None deletes an attribute.</p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.set_param">
<span class="sig-name descname"><span class="pre">set_param</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.set_param" title="Permalink to this definition"></a></dt>
<dd><p>Set parameters into the Booster.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>dict/list/str</em>) – list of key,value pairs, dict of key to value or simply str key</p></li>
<li><p><strong>value</strong> (<em>optional</em>) – value of the specified parameter, when params is str key</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.trees_to_dataframe">
<span class="sig-name descname"><span class="pre">trees_to_dataframe</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.trees_to_dataframe" title="Permalink to this definition"></a></dt>
<dd><p>Parse a boosted tree model text dump into a pandas DataFrame structure.</p>
<p>This feature is only defined when the decision tree model is chosen as base
learner (<cite>booster in {gbtree, dart}</cite>). It is not defined for other base learner
types, such as linear learners (<cite>booster=gblinear</cite>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fmap</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em> (</em><em>optional</em><em>)</em>) – The name of feature map file.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.core.frame.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.Booster.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtrain</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fobj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.Booster.update" title="Permalink to this definition"></a></dt>
<dd><p>Update for one iteration, with objective function calculated
internally.  This function should not be called directly by users.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dtrain</strong> (<a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><em>DMatrix</em></a>) – Training data.</p></li>
<li><p><strong>iteration</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Current iteration number.</p></li>
<li><p><strong>fobj</strong> (<em>function</em>) – Customized objective function.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-xgboost.training">
<span id="learning-api"></span><h2>Learning API<a class="headerlink" href="#module-xgboost.training" title="Permalink to this headline"></a></h2>
<p>Training Library containing training routines.</p>
<dl class="py function">
<dt class="sig sig-object py" id="xgboost.train">
<span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtrain</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_boost_round</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_result</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.train" title="Permalink to this definition"></a></dt>
<dd><p>Train a booster with given parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Booster params.</p></li>
<li><p><strong>dtrain</strong> (<a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a>) – Data to be trained.</p></li>
<li><p><strong>num_boost_round</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of boosting iterations.</p></li>
<li><p><strong>evals</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em>) – List of validation sets for which metrics will evaluated during training.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>obj</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>]</em>) – Custom objective function.  See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective</span></a> for details.</p></li>
<li><p><strong>feval</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>custom_metric</cite> instead.</p>
</div>
<p></p></li>
<li><p><strong>maximize</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to maximize feval.</p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.
Requires at least one item in <strong>evals</strong>.
The method returns the model from the last iteration (not the best one).  Use
custom callback or model slicing if the best model is desired.
If there’s more than one item in <strong>evals</strong>, the last entry will be used for early
stopping.
If there’s more than one metric in the <strong>eval_metric</strong> parameter given in
<strong>params</strong>, the last metric will be used for early stopping.
If early stopping occurs, the model will have two additional fields:
<code class="docutils literal notranslate"><span class="pre">bst.best_score</span></code>, <code class="docutils literal notranslate"><span class="pre">bst.best_iteration</span></code>.</p></li>
<li><p><strong>evals_result</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p><p>This dictionary stores the evaluation results of all the items in watchlist.</p>
<p>Example: with a watchlist containing
<code class="docutils literal notranslate"><span class="pre">[(dtest,'eval'),</span> <span class="pre">(dtrain,'train')]</span></code> and
a parameter containing <code class="docutils literal notranslate"><span class="pre">('eval_metric':</span> <span class="pre">'logloss')</span></code>,
the <strong>evals_result</strong> returns</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'train'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.48253'</span><span class="p">,</span> <span class="s1">'0.35953'</span><span class="p">]},</span>
 <span class="s1">'eval'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.480385'</span><span class="p">,</span> <span class="s1">'0.357756'</span><span class="p">]}}</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>verbose_eval</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – Requires at least one item in <strong>evals</strong>.
If <strong>verbose_eval</strong> is True then the evaluation metric on the validation set is
printed at each boosting stage.
If <strong>verbose_eval</strong> is an integer then the evaluation metric on the validation set
is printed at every given <strong>verbose_eval</strong> boosting stage. The last boosting stage
/ the boosting stage found by using <strong>early_stopping_rounds</strong> is also printed.
Example: with <code class="docutils literal notranslate"><span class="pre">verbose_eval=4</span></code> and at least one item in <strong>evals</strong>, an evaluation metric
is printed every 4 boosting stages, instead of every boosting stage.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>, </em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>]</em><em>]</em>) – Xgb model to be loaded before training (allows training continuation).</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>custom_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em>) – </p><p>Custom metric function.  See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Metric</span></a>
for details.</p>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Booster</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>a trained booster model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="xgboost.cv">
<span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">cv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtrain</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_boost_round</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nfold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stratified</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">folds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fpreproc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_pandas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_stdv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.cv" title="Permalink to this definition"></a></dt>
<dd><p>Cross-validation with given parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a>) – Booster params.</p></li>
<li><p><strong>dtrain</strong> (<a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><em>DMatrix</em></a>) – Data to be trained.</p></li>
<li><p><strong>num_boost_round</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of boosting iterations.</p></li>
<li><p><strong>nfold</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of folds in CV.</p></li>
<li><p><strong>stratified</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Perform stratified sampling.</p></li>
<li><p><strong>folds</strong> (<em>a KFold</em><em> or </em><em>StratifiedKFold instance</em><em> or </em><em>list of fold indices</em>) – Sklearn KFolds or StratifiedKFolds object.
Alternatively may explicitly pass sample indices for each fold.
For <code class="docutils literal notranslate"><span class="pre">n</span></code> folds, <strong>folds</strong> should be a length <code class="docutils literal notranslate"><span class="pre">n</span></code> list of tuples.
Each tuple is <code class="docutils literal notranslate"><span class="pre">(in,out)</span></code> where <code class="docutils literal notranslate"><span class="pre">in</span></code> is a list of indices to be used
as the training samples for the <code class="docutils literal notranslate"><span class="pre">n</span></code> th fold and <code class="docutils literal notranslate"><span class="pre">out</span></code> is a list of
indices to be used as the testing samples for the <code class="docutils literal notranslate"><span class="pre">n</span></code> th fold.</p></li>
<li><p><strong>metrics</strong> (<em>string</em><em> or </em><em>list of strings</em>) – Evaluation metrics to be watched in CV.</p></li>
<li><p><strong>obj</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>]</em>) – Custom objective function.  See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective</span></a> for details.</p></li>
<li><p><strong>feval</strong> (<em>function</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>custom_metric</cite> instead.</p>
</div>
<p></p></li>
<li><p><strong>maximize</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to maximize feval.</p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Activates early stopping. Cross-Validation metric (average of validation
metric computed over CV folds) needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.
The last entry in the evaluation history will represent the best iteration.
If there’s more than one metric in the <strong>eval_metric</strong> parameter given in
<strong>params</strong>, the last metric will be used for early stopping.</p></li>
<li><p><strong>fpreproc</strong> (<em>function</em>) – Preprocessing function that takes (dtrain, dtest, param) and returns
transformed versions of those.</p></li>
<li><p><strong>as_pandas</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>default True</em>) – Return pd.DataFrame when pandas is installed.
If False or pandas is not installed, return np.ndarray</p></li>
<li><p><strong>verbose_eval</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, or </em><em>None</em><em>, </em><em>default None</em>) – Whether to display the progress. If None, progress will be displayed
when np.ndarray is returned. If True, progress will be displayed at
boosting stage. If an integer is given, progress will be displayed
at every given <cite>verbose_eval</cite> boosting stage.</p></li>
<li><p><strong>show_stdv</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>default True</em>) – Whether to display the standard deviation in progress.
Results are not affected, and always contains std.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Seed used to generate the folds (passed to numpy.random.seed).</p></li>
<li><p><strong>callbacks</strong> – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>shuffle</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Shuffle data before creating folds.</p></li>
<li><p><strong>custom_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em>) – </p><p>Custom metric function.  See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Metric</span></a>
for details.</p>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>evaluation history</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#list" title="(in Python v3.6)">list</a>(string)</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-xgboost.sklearn">
<span id="scikit-learn-api"></span><h2>Scikit-Learn API<a class="headerlink" href="#module-xgboost.sklearn" title="Permalink to this headline"></a></h2>
<p>Scikit-Learn Wrapper interface for XGBoost.</p>
<dl class="py class">
<dt class="sig sig-object py" id="xgboost.XGBRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">XGBRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'reg:squarederror'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.sklearn.XGBModel</span></code>, <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html#sklearn.base.RegressorMixin" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.RegressorMixin</span></code></a></p>
<p>Implementation of the scikit-learn API for XGBoost regression.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of gradient boosted trees.  Equivalent to number of boosting
rounds.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.XGBRegressor.fit" title="xgboost.XGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.XGBRegressor.fit" title="xgboost.XGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.XGBRegressor.best_score" title="xgboost.XGBRegressor.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.XGBRegressor.best_iteration" title="xgboost.XGBRegressor.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.XGBRegressor.fit" title="xgboost.XGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Custom objective function</p>
<p>A custom objective function can be provided for the <code class="docutils literal notranslate"><span class="pre">objective</span></code>
parameter. In this case, it should have the signature
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code>:</p>
<dl class="simple">
<dt>y_true: array_like of shape [n_samples]</dt><dd><p>The target values</p>
</dd>
<dt>y_pred: array_like of shape [n_samples]</dt><dd><p>The predicted values</p>
</dd>
<dt>grad: array_like of shape [n_samples]</dt><dd><p>The value of the gradient for each sample point.</p>
</dd>
<dt>hess: array_like of shape [n_samples]</dt><dd><p>The value of the second derivative for each sample point</p>
</dd>
</dl>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.XGBRegressor.predict" title="xgboost.XGBRegressor.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBRegressor.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.XGBRegressor.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRegressor.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.XGBRegressor.fit" title="xgboost.XGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.XGBRegressor.fit" title="xgboost.XGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.XGBRegressor.fit" title="xgboost.XGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRegressor.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRegressor.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.XGBRegressor.fit" title="xgboost.XGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting model.</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Labels</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – instance weights</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, or </em><em>callable</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBRegressor.set_params" title="xgboost.XGBRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.XGBRegressor.set_params" title="xgboost.XGBRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [L_1, L_2, …, L_n], where each L_i is an array like
object storing instance weights for the i-th validation set.</p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBRegressor.set_params" title="xgboost.XGBRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>xgboost.sklearn.XGBModel</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRegressor.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBRegressor.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.XGBRegressor.fit" title="xgboost.XGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.score" title="Permalink to this definition"></a></dt>
<dd><p>Return the coefficient of determination of the prediction.</p>
<p>The coefficient of determination <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="0"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> is defined as
<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="1"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mfrac><mi>u</mi><mi>v</mi></mfrac><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></span>, where <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="2"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>u</mi></math></mjx-assistive-mml></mjx-container></span> is the residual
sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_pred)**</span> <span class="pre">2).sum()</span></code> and <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="3"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>v</mi></math></mjx-assistive-mml></mjx-container></span>
is the total sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_true.mean())</span> <span class="pre">**</span> <span class="pre">2).sum()</span></code>.
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always predicts
the expected value of <cite>y</cite>, disregarding the input features, would get
a <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="4"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> score of 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test samples. For some estimators this may be a precomputed
kernel matrix or a list of generic objects instead with shape
<code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_samples_fitted)</span></code>, where <code class="docutils literal notranslate"><span class="pre">n_samples_fitted</span></code>
is the number of samples used in the fitting for the estimator.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – True values for <cite>X</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> – <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="5"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <cite>y</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="6"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> score used when calling <code class="docutils literal notranslate"><span class="pre">score</span></code> on a regressor uses
<code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code> from version 0.23 to keep consistent
with default value of <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score()</span></code></a>.
This influences the <code class="docutils literal notranslate"><span class="pre">score</span></code> method of all the multioutput
regressors (except for
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRegressor</span></code></a>).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRegressor.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRegressor.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.XGBClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">XGBClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'binary:logistic'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_label_encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.sklearn.XGBModel</span></code>, <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.ClassifierMixin.html#sklearn.base.ClassifierMixin" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.ClassifierMixin</span></code></a></p>
<p>Implementation of the scikit-learn API for XGBoost classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of boosting rounds.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.XGBClassifier.fit" title="xgboost.XGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.XGBClassifier.fit" title="xgboost.XGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.XGBClassifier.best_score" title="xgboost.XGBClassifier.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.XGBClassifier.best_iteration" title="xgboost.XGBClassifier.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.XGBClassifier.fit" title="xgboost.XGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Custom objective function</p>
<p>A custom objective function can be provided for the <code class="docutils literal notranslate"><span class="pre">objective</span></code>
parameter. In this case, it should have the signature
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code>:</p>
<dl class="simple">
<dt>y_true: array_like of shape [n_samples]</dt><dd><p>The target values</p>
</dd>
<dt>y_pred: array_like of shape [n_samples]</dt><dd><p>The predicted values</p>
</dd>
<dt>grad: array_like of shape [n_samples]</dt><dd><p>The value of the gradient for each sample point.</p>
</dd>
<dt>hess: array_like of shape [n_samples]</dt><dd><p>The value of the second derivative for each sample point</p>
</dd>
</dl>
</div>
<p></p></li>
<li><p><strong>use_label_encoder</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.XGBClassifier.predict" title="xgboost.XGBClassifier.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBClassifier.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.XGBClassifier.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBClassifier.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.XGBClassifier.fit" title="xgboost.XGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.XGBClassifier.fit" title="xgboost.XGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.XGBClassifier.fit" title="xgboost.XGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBClassifier.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBClassifier.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.XGBClassifier.fit" title="xgboost.XGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting classifier.</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Labels</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – instance weights</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, or </em><em>callable</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBClassifier.set_params" title="xgboost.XGBClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.XGBClassifier.set_params" title="xgboost.XGBClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [L_1, L_2, …, L_n], where each L_i is an array like
object storing instance weights for the i-th validation set.</p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBClassifier.set_params" title="xgboost.XGBClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.XGBClassifier" title="xgboost.sklearn.XGBClassifier">xgboost.sklearn.XGBClassifier</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBClassifier.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBClassifier.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.XGBClassifier.fit" title="xgboost.XGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.predict_proba" title="Permalink to this definition"></a></dt>
<dd><p>Predict the probability of each <cite>X</cite> example being of a given class.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em>) – Feature matrix.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<em>array_like</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <cite>iteration_range=(10,
20)</cite>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a numpy array of shape array-like of shape (n_samples, n_classes) with the
probability of each data example being of a given class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.score" title="Permalink to this definition"></a></dt>
<dd><p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test samples.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – True labels for <cite>X</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> – Mean accuracy of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <cite>y</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBClassifier.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBClassifier.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.XGBRanker">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">XGBRanker</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'rank:pairwise'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.sklearn.XGBModel</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.sklearn.XGBRankerMixIn</span></code></p>
<p>Implementation of the Scikit-Learn API for XGBoost Ranking.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of gradient boosted trees.  Equivalent to number of boosting
rounds.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.XGBRanker.fit" title="xgboost.XGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.XGBRanker.fit" title="xgboost.XGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.XGBRanker.best_score" title="xgboost.XGBRanker.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.XGBRanker.best_iteration" title="xgboost.XGBRanker.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.XGBRanker.fit" title="xgboost.XGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A custom objective function is currently not supported by XGBRanker.
Likewise, a custom metric function is not supported either.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Query group information is required for ranking tasks by either using the
<cite>group</cite> parameter or <cite>qid</cite> parameter in <cite>fit</cite> method.</p>
</div>
<p>Before fitting the model, your data need to be sorted by query group. When fitting
the model, you need to provide an additional array that contains the size of each
query group.</p>
<p>For example, if your original data look like:</p>
<div class="wy-table-responsive"><table class="docutils align-default">
<colgroup>
<col style="width: 21%">
<col style="width: 33%">
<col style="width: 45%">
</colgroup>
<tbody>
<tr class="row-odd"><td><p>qid</p></td>
<td><p>label</p></td>
<td><p>features</p></td>
</tr>
<tr class="row-even"><td><p>1</p></td>
<td><p>0</p></td>
<td><p>x_1</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>1</p></td>
<td><p>x_2</p></td>
</tr>
<tr class="row-even"><td><p>1</p></td>
<td><p>0</p></td>
<td><p>x_3</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>0</p></td>
<td><p>x_4</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>1</p></td>
<td><p>x_5</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>1</p></td>
<td><p>x_6</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>1</p></td>
<td><p>x_7</p></td>
</tr>
</tbody>
</table></div>
<p>then your group array should be <code class="docutils literal notranslate"><span class="pre">[3,</span> <span class="pre">4]</span></code>.  Sometimes using query id (<cite>qid</cite>)
instead of group can be more convenient.</p>
<p></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.XGBRanker.predict" title="xgboost.XGBRanker.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRanker.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBRanker.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRanker.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.XGBRanker.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRanker.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRanker.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.XGBRanker.fit" title="xgboost.XGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.XGBRanker.fit" title="xgboost.XGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.XGBRanker.fit" title="xgboost.XGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRanker.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRanker.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRanker.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRanker.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.XGBRanker.fit" title="xgboost.XGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting ranker</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Labels</p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Size of each query group of training data. Should have as many elements as the
query groups in the training data.  If this is set to None, then user must
provide qid.</p></li>
<li><p><strong>qid</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Query ID for each training sample.  Should have the size of n_samples.  If
this is set to None, then user must provide group.</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p><p>Query group weights</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Weights are per-group for ranking tasks</p>
<p>In ranking task, one weight is assigned to each query group/id (not each
data point). This is because we only care about the relative ordering of
data points within each group, so it doesn’t make sense to assign weights
to individual data points.</p>
</div>
<p></p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list in which <code class="docutils literal notranslate"><span class="pre">eval_group[i]</span></code> is the list containing the sizes of all
query groups in the <code class="docutils literal notranslate"><span class="pre">i</span></code>-th pair in <strong>eval_set</strong>.</p></li>
<li><p><strong>eval_qid</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list in which <code class="docutils literal notranslate"><span class="pre">eval_qid[i]</span></code> is the array containing query ID of <code class="docutils literal notranslate"><span class="pre">i</span></code>-th
pair in <strong>eval_set</strong>.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBRanker.set_params" title="xgboost.XGBRanker.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.XGBRanker.set_params" title="xgboost.XGBRanker.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – </p><p>A list of the form [L_1, L_2, …, L_n], where each L_i is a list of
group weights on the i-th validation set.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Weights are per-group for ranking tasks</p>
<p>In ranking task, one weight is assigned to each query group (not each
data point). This is because we only care about the relative ordering of
data points within each group, so it doesn’t make sense to assign
weights to individual data points.</p>
</div>
<p></p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBRanker.set_params" title="xgboost.XGBRanker.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.XGBRanker" title="xgboost.sklearn.XGBRanker">xgboost.sklearn.XGBRanker</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRanker.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRanker.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRanker.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBRanker.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.XGBRanker.fit" title="xgboost.XGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRanker.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRanker.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">XGBRFRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bynode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.XGBRegressor" title="xgboost.sklearn.XGBRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.sklearn.XGBRegressor</span></code></a></p>
<p>scikit-learn API for XGBoost random forest regression.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of trees in random forest to fit.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.XGBRFRegressor.fit" title="xgboost.XGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.XGBRFRegressor.fit" title="xgboost.XGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.XGBRFRegressor.best_score" title="xgboost.XGBRFRegressor.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.XGBRFRegressor.best_iteration" title="xgboost.XGBRFRegressor.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.XGBRFRegressor.fit" title="xgboost.XGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Custom objective function</p>
<p>A custom objective function can be provided for the <code class="docutils literal notranslate"><span class="pre">objective</span></code>
parameter. In this case, it should have the signature
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code>:</p>
<dl class="simple">
<dt>y_true: array_like of shape [n_samples]</dt><dd><p>The target values</p>
</dd>
<dt>y_pred: array_like of shape [n_samples]</dt><dd><p>The predicted values</p>
</dd>
<dt>grad: array_like of shape [n_samples]</dt><dd><p>The value of the gradient for each sample point.</p>
</dd>
<dt>hess: array_like of shape [n_samples]</dt><dd><p>The value of the second derivative for each sample point</p>
</dd>
</dl>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.XGBRFRegressor.predict" title="xgboost.XGBRFRegressor.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBRFRegressor.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.XGBRFRegressor.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRFRegressor.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.XGBRFRegressor.fit" title="xgboost.XGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.XGBRFRegressor.fit" title="xgboost.XGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.XGBRFRegressor.fit" title="xgboost.XGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRFRegressor.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRFRegressor.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.XGBRFRegressor.fit" title="xgboost.XGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting model.</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Labels</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – instance weights</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, or </em><em>callable</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBRFRegressor.set_params" title="xgboost.XGBRFRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.XGBRFRegressor.set_params" title="xgboost.XGBRFRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [L_1, L_2, …, L_n], where each L_i is an array like
object storing instance weights for the i-th validation set.</p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBRFRegressor.set_params" title="xgboost.XGBRFRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.XGBRFRegressor" title="xgboost.sklearn.XGBRFRegressor">xgboost.sklearn.XGBRFRegressor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRFRegressor.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBRFRegressor.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.XGBRFRegressor.fit" title="xgboost.XGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.score" title="Permalink to this definition"></a></dt>
<dd><p>Return the coefficient of determination of the prediction.</p>
<p>The coefficient of determination <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="7"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> is defined as
<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="8"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mfrac><mi>u</mi><mi>v</mi></mfrac><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></span>, where <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="9"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>u</mi></math></mjx-assistive-mml></mjx-container></span> is the residual
sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_pred)**</span> <span class="pre">2).sum()</span></code> and <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="10"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>v</mi></math></mjx-assistive-mml></mjx-container></span>
is the total sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_true.mean())</span> <span class="pre">**</span> <span class="pre">2).sum()</span></code>.
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always predicts
the expected value of <cite>y</cite>, disregarding the input features, would get
a <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="11"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> score of 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test samples. For some estimators this may be a precomputed
kernel matrix or a list of generic objects instead with shape
<code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_samples_fitted)</span></code>, where <code class="docutils literal notranslate"><span class="pre">n_samples_fitted</span></code>
is the number of samples used in the fitting for the estimator.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – True values for <cite>X</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> – <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="12"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <cite>y</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="13"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> score used when calling <code class="docutils literal notranslate"><span class="pre">score</span></code> on a regressor uses
<code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code> from version 0.23 to keep consistent
with default value of <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score()</span></code></a>.
This influences the <code class="docutils literal notranslate"><span class="pre">score</span></code> method of all the multioutput
regressors (except for
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRegressor</span></code></a>).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFRegressor.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFRegressor.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">XGBRFClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bynode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.XGBClassifier" title="xgboost.sklearn.XGBClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.sklearn.XGBClassifier</span></code></a></p>
<p>scikit-learn API for XGBoost random forest classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of trees in random forest to fit.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.XGBRFClassifier.fit" title="xgboost.XGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.XGBRFClassifier.fit" title="xgboost.XGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.XGBRFClassifier.best_score" title="xgboost.XGBRFClassifier.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.XGBRFClassifier.best_iteration" title="xgboost.XGBRFClassifier.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.XGBRFClassifier.fit" title="xgboost.XGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Custom objective function</p>
<p>A custom objective function can be provided for the <code class="docutils literal notranslate"><span class="pre">objective</span></code>
parameter. In this case, it should have the signature
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code>:</p>
<dl class="simple">
<dt>y_true: array_like of shape [n_samples]</dt><dd><p>The target values</p>
</dd>
<dt>y_pred: array_like of shape [n_samples]</dt><dd><p>The predicted values</p>
</dd>
<dt>grad: array_like of shape [n_samples]</dt><dd><p>The value of the gradient for each sample point.</p>
</dd>
<dt>hess: array_like of shape [n_samples]</dt><dd><p>The value of the second derivative for each sample point</p>
</dd>
</dl>
</div>
<p></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.XGBRFClassifier.predict" title="xgboost.XGBRFClassifier.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBRFClassifier.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.XGBRFClassifier.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRFClassifier.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.XGBRFClassifier.fit" title="xgboost.XGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.XGBRFClassifier.fit" title="xgboost.XGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.XGBRFClassifier.fit" title="xgboost.XGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRFClassifier.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRFClassifier.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.XGBRFClassifier.fit" title="xgboost.XGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting classifier.</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Labels</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – instance weights</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, or </em><em>callable</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBRFClassifier.set_params" title="xgboost.XGBRFClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.XGBRFClassifier.set_params" title="xgboost.XGBRFClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [L_1, L_2, …, L_n], where each L_i is an array like
object storing instance weights for the i-th validation set.</p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.XGBRFClassifier.set_params" title="xgboost.XGBRFClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.XGBRFClassifier" title="xgboost.sklearn.XGBRFClassifier">xgboost.sklearn.XGBRFClassifier</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.XGBRFClassifier.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.XGBRFClassifier.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.XGBRFClassifier.fit" title="xgboost.XGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.predict_proba" title="Permalink to this definition"></a></dt>
<dd><p>Predict the probability of each <cite>X</cite> example being of a given class.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em>) – Feature matrix.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<em>array_like</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <cite>iteration_range=(10,
20)</cite>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a numpy array of shape array-like of shape (n_samples, n_classes) with the
probability of each data example being of a given class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.score" title="Permalink to this definition"></a></dt>
<dd><p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test samples.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – True labels for <cite>X</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> – Mean accuracy of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <cite>y</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.XGBRFClassifier.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.XGBRFClassifier.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-xgboost.plotting">
<span id="plotting-api"></span><h2>Plotting API<a class="headerlink" href="#module-xgboost.plotting" title="Permalink to this headline"></a></h2>
<p>Plotting Library.</p>
<dl class="py function">
<dt class="sig sig-object py" id="xgboost.plot_importance">
<span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">plot_importance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">booster</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">height</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xlim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Feature</span> <span class="pre">importance'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xlabel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'F</span> <span class="pre">score'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ylabel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Features'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">importance_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'weight'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.plot_importance" title="Permalink to this definition"></a></dt>
<dd><p>Plot importance based on fitted trees.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>booster</strong> (<a class="reference internal" href="#xgboost.Booster" title="xgboost.Booster"><em>Booster</em></a><em>, </em><em>XGBModel</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a>) – Booster or XGBModel instance, or dict taken by Booster.get_fscore()</p></li>
<li><p><strong>ax</strong> (<em>matplotlib Axes</em><em>, </em><em>default None</em>) – Target axes instance. If None, new figure and axes will be created.</p></li>
<li><p><strong>grid</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>Turn the axes grids on</em><em> or </em><em>off.  Default is True</em><em> (</em><em>On</em><em>)</em><em>.</em>) – </p></li>
<li><p><strong>importance_type</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>default "weight"</em>) – </p><p>How the importance is calculated: either “weight”, “gain”, or “cover”</p>
<ul>
<li><p>”weight” is the number of times a feature appears in a tree</p></li>
<li><p>”gain” is the average gain of splits which use the feature</p></li>
<li><p>”cover” is the average coverage of splits which use the feature
where coverage is defined as the number of samples affected by the split</p></li>
</ul>
<p></p></li>
<li><p><strong>max_num_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><em>default None</em>) – Maximum number of top features displayed on plot. If None, all features will be displayed.</p></li>
<li><p><strong>height</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default 0.2</em>) – Bar height, passed to ax.barh()</p></li>
<li><p><strong>xlim</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a><em>, </em><em>default None</em>) – Tuple passed to axes.xlim()</p></li>
<li><p><strong>ylim</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a><em>, </em><em>default None</em>) – Tuple passed to axes.ylim()</p></li>
<li><p><strong>title</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>default "Feature importance"</em>) – Axes title. To disable, pass None.</p></li>
<li><p><strong>xlabel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>default "F score"</em>) – X axis title label. To disable, pass None.</p></li>
<li><p><strong>ylabel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>default "Features"</em>) – Y axis title label. To disable, pass None.</p></li>
<li><p><strong>fmap</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em> (</em><em>optional</em><em>)</em>) – The name of feature map file.</p></li>
<li><p><strong>show_values</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>, </em><em>default True</em>) – Show values on plot. To disable, pass False.</p></li>
<li><p><strong>kwargs</strong> – Other keywords passed to ax.barh()</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ax</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>matplotlib Axes</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="xgboost.plot_tree">
<span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">plot_tree</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">booster</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_trees</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rankdir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.plot_tree" title="Permalink to this definition"></a></dt>
<dd><p>Plot specified tree.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>booster</strong> (<a class="reference internal" href="#xgboost.Booster" title="xgboost.Booster"><em>Booster</em></a><em>, </em><em>XGBModel</em>) – Booster or XGBModel instance</p></li>
<li><p><strong>fmap</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em> (</em><em>optional</em><em>)</em>) – The name of feature map file</p></li>
<li><p><strong>num_trees</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><em>default 0</em>) – Specify the ordinal number of target tree</p></li>
<li><p><strong>rankdir</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>default "TB"</em>) – Passed to graphiz via graph_attr</p></li>
<li><p><strong>ax</strong> (<em>matplotlib Axes</em><em>, </em><em>default None</em>) – Target axes instance. If None, new figure and axes will be created.</p></li>
<li><p><strong>kwargs</strong> – Other keywords passed to to_graphviz</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ax</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>matplotlib Axes</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="xgboost.to_graphviz">
<span class="sig-prename descclassname"><span class="pre">xgboost.</span></span><span class="sig-name descname"><span class="pre">to_graphviz</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">booster</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_trees</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rankdir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">yes_color</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">no_color</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition_node_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaf_node_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.to_graphviz" title="Permalink to this definition"></a></dt>
<dd><p>Convert specified tree to graphviz instance. IPython can automatically plot
the returned graphiz instance. Otherwise, you should call .render() method
of the returned graphiz instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>booster</strong> (<a class="reference internal" href="#xgboost.Booster" title="xgboost.Booster"><em>Booster</em></a><em>, </em><em>XGBModel</em>) – Booster or XGBModel instance</p></li>
<li><p><strong>fmap</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em> (</em><em>optional</em><em>)</em>) – The name of feature map file</p></li>
<li><p><strong>num_trees</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><em>default 0</em>) – Specify the ordinal number of target tree</p></li>
<li><p><strong>rankdir</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>default "UT"</em>) – Passed to graphiz via graph_attr</p></li>
<li><p><strong>yes_color</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>default '#0000FF'</em>) – Edge color when meets the node condition.</p></li>
<li><p><strong>no_color</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>default '#FF0000'</em>) – Edge color when doesn’t meet the node condition.</p></li>
<li><p><strong>condition_node_params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Condition node configuration for for graphviz.  Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'shape'</span><span class="p">:</span> <span class="s1">'box'</span><span class="p">,</span>
 <span class="s1">'style'</span><span class="p">:</span> <span class="s1">'filled,rounded'</span><span class="p">,</span>
 <span class="s1">'fillcolor'</span><span class="p">:</span> <span class="s1">'#78bceb'</span><span class="p">}</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>leaf_node_params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Leaf node configuration for graphviz. Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'shape'</span><span class="p">:</span> <span class="s1">'box'</span><span class="p">,</span>
 <span class="s1">'style'</span><span class="p">:</span> <span class="s1">'filled'</span><span class="p">,</span>
 <span class="s1">'fillcolor'</span><span class="p">:</span> <span class="s1">'#e48038'</span><span class="p">}</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – Other keywords passed to graphviz graph_attr, e.g. <code class="docutils literal notranslate"><span class="pre">graph</span> <span class="pre">[</span> <span class="pre">{key}</span> <span class="pre">=</span> <span class="pre">{value}</span> <span class="pre">]</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>graph</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>graphviz.Source</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-xgboost.callback">
<span id="id1"></span><span id="callback-api"></span><h2>Callback API<a class="headerlink" href="#module-xgboost.callback" title="Permalink to this headline"></a></h2>
<p>Callback library containing training routines.  See <a class="reference internal" href="callbacks.html"><span class="doc">Callback Functions</span></a> for a quick introduction.</p>
<dl class="py class">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCallback">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.callback.</span></span><span class="sig-name descname"><span class="pre">TrainingCallback</span></span><a class="headerlink" href="#xgboost.callback.TrainingCallback" title="Permalink to this definition"></a></dt>
<dd><p>Interface for training callback.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCallback.after_iteration">
<span class="sig-name descname"><span class="pre">after_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCallback.after_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run after each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCallback.after_training">
<span class="sig-name descname"><span class="pre">after_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCallback.after_training" title="Permalink to this definition"></a></dt>
<dd><p>Run after training is finished.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCallback.before_iteration">
<span class="sig-name descname"><span class="pre">before_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCallback.before_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run before each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCallback.before_training">
<span class="sig-name descname"><span class="pre">before_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCallback.before_training" title="Permalink to this definition"></a></dt>
<dd><p>Run before training starts.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.callback.EvaluationMonitor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.callback.</span></span><span class="sig-name descname"><span class="pre">EvaluationMonitor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">period</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_stdv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EvaluationMonitor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.callback.TrainingCallback</span></code></a></p>
<p>Print the evaluation result at each iteration.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metric</strong> – Extra user defined metric.</p></li>
<li><p><strong>rank</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Which worker should be used for printing the result.</p></li>
<li><p><strong>period</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – How many epoches between printing.</p></li>
<li><p><strong>show_stdv</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Used in cv to show standard deviation.  Users should not specify it.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.EvaluationMonitor.after_iteration">
<span class="sig-name descname"><span class="pre">after_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EvaluationMonitor.after_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run after each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.EvaluationMonitor.after_training">
<span class="sig-name descname"><span class="pre">after_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EvaluationMonitor.after_training" title="Permalink to this definition"></a></dt>
<dd><p>Run after training is finished.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.EvaluationMonitor.before_iteration">
<span class="sig-name descname"><span class="pre">before_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EvaluationMonitor.before_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run before each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.EvaluationMonitor.before_training">
<span class="sig-name descname"><span class="pre">before_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EvaluationMonitor.before_training" title="Permalink to this definition"></a></dt>
<dd><p>Run before training starts.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.callback.EarlyStopping">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.callback.</span></span><span class="sig-name descname"><span class="pre">EarlyStopping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_best</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_delta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EarlyStopping" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.callback.TrainingCallback</span></code></a></p>
<p>Callback function for early stopping</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Early stopping rounds.</p></li>
<li><p><strong>metric_name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Name of metric that is used for early stopping.</p></li>
<li><p><strong>data_name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Name of dataset that is used for early stopping.</p></li>
<li><p><strong>maximize</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Whether to maximize evaluation metric.  None means auto (discouraged).</p></li>
<li><p><strong>save_best</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Whether training should return the best model or the last model.</p></li>
<li><p><strong>min_delta</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – </p><p>Minimum absolute change in score to be qualified as an improvement.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">xgboost</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">tree_method</span><span class="o">=</span><span class="s2">"gpu_hist"</span><span class="p">)</span>
<span class="n">es</span> <span class="o">=</span> <span class="n">xgboost</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span>
    <span class="n">rounds</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">abs_tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">save_best</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">maximize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">data_name</span><span class="o">=</span><span class="s2">"validation_0"</span><span class="p">,</span>
    <span class="n">metric_name</span><span class="o">=</span><span class="s2">"mlogloss"</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)],</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">es</span><span class="p">])</span>
</pre></div>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.EarlyStopping.after_iteration">
<span class="sig-name descname"><span class="pre">after_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EarlyStopping.after_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run after each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.EarlyStopping.after_training">
<span class="sig-name descname"><span class="pre">after_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EarlyStopping.after_training" title="Permalink to this definition"></a></dt>
<dd><p>Run after training is finished.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.EarlyStopping.before_iteration">
<span class="sig-name descname"><span class="pre">before_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EarlyStopping.before_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run before each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.EarlyStopping.before_training">
<span class="sig-name descname"><span class="pre">before_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.EarlyStopping.before_training" title="Permalink to this definition"></a></dt>
<dd><p>Run before training starts.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.callback.LearningRateScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.callback.</span></span><span class="sig-name descname"><span class="pre">LearningRateScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">learning_rates</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.LearningRateScheduler" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.callback.TrainingCallback</span></code></a></p>
<p>Callback function for scheduling learning rate.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>learning_rates</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em>) – If it’s a callable object, then it should accept an integer parameter
<cite>epoch</cite> and returns the corresponding learning rate.  Otherwise it
should be a sequence like list or tuple with the same size of boosting
rounds.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.LearningRateScheduler.after_iteration">
<span class="sig-name descname"><span class="pre">after_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.LearningRateScheduler.after_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run after each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.LearningRateScheduler.after_training">
<span class="sig-name descname"><span class="pre">after_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.LearningRateScheduler.after_training" title="Permalink to this definition"></a></dt>
<dd><p>Run after training is finished.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.LearningRateScheduler.before_iteration">
<span class="sig-name descname"><span class="pre">before_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.LearningRateScheduler.before_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run before each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.LearningRateScheduler.before_training">
<span class="sig-name descname"><span class="pre">before_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.LearningRateScheduler.before_training" title="Permalink to this definition"></a></dt>
<dd><p>Run before training starts.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCheckPoint">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.callback.</span></span><span class="sig-name descname"><span class="pre">TrainingCheckPoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">directory</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'model'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_pickle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCheckPoint" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.callback.TrainingCallback</span></code></a></p>
<p>Checkpointing operation.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>directory</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Output model directory.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – pattern of output model file.  Models will be saved as name_0.json, name_1.json,
name_2.json ….</p></li>
<li><p><strong>as_pickle</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When set to True, all training parameters will be saved in pickle format, instead
of saving only the model.</p></li>
<li><p><strong>iterations</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Interval of checkpointing.  Checkpointing is slow so setting a larger number can
reduce performance hit.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCheckPoint.after_iteration">
<span class="sig-name descname"><span class="pre">after_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCheckPoint.after_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run after each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCheckPoint.after_training">
<span class="sig-name descname"><span class="pre">after_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCheckPoint.after_training" title="Permalink to this definition"></a></dt>
<dd><p>Run after training is finished.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCheckPoint.before_iteration">
<span class="sig-name descname"><span class="pre">before_iteration</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals_log</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCheckPoint.before_iteration" title="Permalink to this definition"></a></dt>
<dd><p>Run before each iteration.  Return True when training should stop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals_log</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.callback.TrainingCheckPoint.before_training">
<span class="sig-name descname"><span class="pre">before_training</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.callback.TrainingCheckPoint.before_training" title="Permalink to this definition"></a></dt>
<dd><p>Run before training starts.</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-xgboost.dask">
<span id="id2"></span><span id="dask-api"></span><h2>Dask API<a class="headerlink" href="#module-xgboost.dask" title="Permalink to this headline"></a></h2>
<section id="dask-extensions-for-distributed-training">
<h3>Dask extensions for distributed training<a class="headerlink" href="#dask-extensions-for-distributed-training" title="Permalink to this headline"></a></h3>
<p>See <a class="reference internal" href="../tutorials/dask.html"><span class="doc">Distributed XGBoost with Dask</span></a> for simple tutorial.  Also
<a class="reference internal" href="dask-examples/index.html"><span class="doc">XGBoost Dask Feature Walkthrough</span></a> for some examples.</p>
<p>There are two sets of APIs in this module, one is the functional API including
<code class="docutils literal notranslate"><span class="pre">train</span></code> and <code class="docutils literal notranslate"><span class="pre">predict</span></code> methods.  Another is stateful Scikit-Learner wrapper
inherited from single-node Scikit-Learn interface.</p>
<p>The implementation is heavily influenced by dask_xgboost:
<a class="reference external" href="https://github.com/dask/dask-xgboost">https://github.com/dask/dask-xgboost</a></p>
<section id="optional-dask-configuration">
<h4>Optional dask configuration<a class="headerlink" href="#optional-dask-configuration" title="Permalink to this headline"></a></h4>
<ul>
<li><p><strong>xgboost.scheduler_address</strong>: Specify the scheduler address, see <a class="reference internal" href="../tutorials/dask.html#tracker-ip"><span class="std std-ref">Troubleshooting</span></a>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set</span><span class="p">({</span><span class="s2">"xgboost.scheduler_address"</span><span class="p">:</span> <span class="s2">"192.0.0.100"</span><span class="p">})</span>
<span class="c1"># We can also specify the port.</span>
<span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set</span><span class="p">({</span><span class="s2">"xgboost.scheduler_address"</span><span class="p">:</span> <span class="s2">"192.0.0.100:12345"</span><span class="p">})</span>
</pre></div>
</div>
</li>
</ul>
</section>
</section>
<dl class="py class">
<dt class="sig sig-object py" id="xgboost.dask.DaskDMatrix">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">DaskDMatrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">client</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_lower_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_upper_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskDMatrix" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>DMatrix holding on references to Dask DataFrame or Dask Array.  Constructing a
<cite>DaskDMatrix</cite> forces all lazy computation to be carried out.  Wait for the input data
explicitly if you want to see actual computation of constructing <cite>DaskDMatrix</cite>.</p>
<p>See doc for <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.DMatrix</span></code></a> constructor for other parameters.  DaskDMatrix
accepts only dask collection.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>DaskDMatrix does not repartition or move data between workers.  It’s
the caller’s responsibility to balance the data.</p>
</div>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><em>distributed.Client</em></a>) – Specify the dask client used for training.  Use default client returned from dask
if it’s set to None.</p></li>
<li><p><strong>data</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – </p></li>
<li><p><strong>label</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – </p></li>
<li><p><strong>silent</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
<li><p><strong>feature_names</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – </p></li>
<li><p><strong>feature_types</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – </p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>qid</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>label_lower_bound</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>label_upper_bound</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.dask.DaskDeviceQuantileDMatrix">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">DaskDeviceQuantileDMatrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">client</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_bin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_lower_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_upper_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskDeviceQuantileDMatrix" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.dask.DaskDMatrix" title="xgboost.dask.DaskDMatrix"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.dask.DaskDMatrix</span></code></a></p>
<p>Specialized data type for <cite>gpu_hist</cite> tree method.  This class is used to reduce the
memory usage by eliminating data copies.  Internally the all partitions/chunks of data
are merged by weighted GK sketching.  So the number of partitions from dask may affect
training accuracy as GK generates bounded error for each merge.  See doc string for
<a class="reference internal" href="#xgboost.DeviceQuantileDMatrix" title="xgboost.DeviceQuantileDMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.DeviceQuantileDMatrix</span></code></a> and <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.DMatrix</span></code></a> for other
parameters.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.2.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_bin</strong> (<em>Number of bins for histogram construction.</em>) – </p></li>
<li><p><strong>client</strong> (<a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><em>distributed.Client</em></a>) – </p></li>
<li><p><strong>data</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – </p></li>
<li><p><strong>label</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – </p></li>
<li><p><strong>silent</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
<li><p><strong>feature_names</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – </p></li>
<li><p><strong>feature_types</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.List" title="(in Python v3.6)"><em>List</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>qid</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>label_lower_bound</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>label_upper_bound</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="xgboost.dask.train">
<span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">client</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtrain</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_boost_round</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.train" title="Permalink to this definition"></a></dt>
<dd><p>Train XGBoost model.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Other parameters are the same as <a class="reference internal" href="#xgboost.train" title="xgboost.train"><code class="xref py py-func docutils literal notranslate"><span class="pre">xgboost.train()</span></code></a> except for
<cite>evals_result</cite>, which is returned as part of function return value instead of
argument.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><em>distributed.Client</em></a>) – Specify the dask client used for training.  Use default client returned from dask
if it’s set to None.</p></li>
<li><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em>) – </p></li>
<li><p><strong>dtrain</strong> (<a class="reference internal" href="#xgboost.dask.DaskDMatrix" title="xgboost.dask.DaskDMatrix"><em>xgboost.dask.DaskDMatrix</em></a>) – </p></li>
<li><p><strong>num_boost_round</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>evals</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference internal" href="#xgboost.dask.DaskDMatrix" title="xgboost.dask.DaskDMatrix"><em>xgboost.dask.DaskDMatrix</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>obj</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>feval</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>]</em>) – </p></li>
<li><p><strong>verbose_eval</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – </p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p></li>
<li><p><strong>custom_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="#xgboost.DMatrix" title="xgboost.core.DMatrix"><em>xgboost.core.DMatrix</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p><p><strong>results</strong> – A dictionary containing trained booster and evaluation history.  <cite>history</cite> field
is the same as <cite>eval_result</cite> from <cite>xgboost.train</cite>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'booster'</span><span class="p">:</span> <span class="n">xgboost</span><span class="o">.</span><span class="n">Booster</span><span class="p">,</span>
 <span class="s1">'history'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'train'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.48253'</span><span class="p">,</span> <span class="s1">'0.35953'</span><span class="p">]},</span>
             <span class="s1">'eval'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.480385'</span><span class="p">,</span> <span class="s1">'0.357756'</span><span class="p">]}}}</span>
</pre></div>
</div>
<p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)">dict</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="xgboost.dask.predict">
<span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">client</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_contribs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approx_contribs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_interactions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.predict" title="Permalink to this definition"></a></dt>
<dd><p>Run prediction with a trained booster.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using <code class="docutils literal notranslate"><span class="pre">inplace_predict</span></code> might be faster when some features are not needed.  See
<a class="reference internal" href="#xgboost.Booster.predict" title="xgboost.Booster.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">xgboost.Booster.predict()</span></code></a> for details on various parameters.  When output
has more than 2 dimensions (shap value, leaf with strict_shape), input should be
<code class="docutils literal notranslate"><span class="pre">da.Array</span></code> or <code class="docutils literal notranslate"><span class="pre">DaskDMatrix</span></code>.</p>
</div>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.0.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><em>distributed.Client</em></a>) – Specify the dask client used for training.  Use default client
returned from dask if it’s set to None.</p></li>
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>, </em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Future" title="(in Dask.distributed v2022.5.0)"><em>distributed.Future</em></a><em>]</em>) – The trained model.  It can be a distributed.Future so user can
pre-scatter it onto all workers.</p></li>
<li><p><strong>data</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.dask.DaskDMatrix" title="xgboost.dask.DaskDMatrix"><em>xgboost.dask.DaskDMatrix</em></a><em>, </em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Input data used for prediction.  When input is a dataframe object,
prediction output is a series.</p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Used when input data is not DaskDMatrix.  Specify the value
considered as missing.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
<li><p><strong>pred_leaf</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
<li><p><strong>pred_contribs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
<li><p><strong>approx_contribs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
<li><p><strong>pred_interactions</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p></li>
<li><p><strong>strict_shape</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>prediction</strong> – When input data is <code class="docutils literal notranslate"><span class="pre">dask.array.Array</span></code> or <code class="docutils literal notranslate"><span class="pre">DaskDMatrix</span></code>, the return value is an
array, when input data is <code class="docutils literal notranslate"><span class="pre">dask.dataframe.DataFrame</span></code>, return value can be
<code class="docutils literal notranslate"><span class="pre">dask.dataframe.Series</span></code>, <code class="docutils literal notranslate"><span class="pre">dask.dataframe.DataFrame</span></code>, depending on the output
shape.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dask.array.Array/dask.dataframe.Series</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="xgboost.dask.inplace_predict">
<span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">inplace_predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">client</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'value'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.inplace_predict" title="Permalink to this definition"></a></dt>
<dd><p>Inplace prediction. See doc in <a class="reference internal" href="#xgboost.Booster.inplace_predict" title="xgboost.Booster.inplace_predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">xgboost.Booster.inplace_predict()</span></code></a> for details.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.1.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><em>distributed.Client</em></a>) – Specify the dask client used for training.  Use default client
returned from dask if it’s set to None.</p></li>
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a><em>]</em><em>, </em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Future" title="(in Dask.distributed v2022.5.0)"><em>distributed.Future</em></a><em>]</em>) – See <a class="reference internal" href="#xgboost.dask.predict" title="xgboost.dask.predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">xgboost.dask.predict()</span></code></a> for details.</p></li>
<li><p><strong>data</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – dask collection.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – See <a class="reference internal" href="#xgboost.Booster.predict" title="xgboost.Booster.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">xgboost.Booster.predict()</span></code></a> for details.</p></li>
<li><p><strong>predict_type</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – See <a class="reference internal" href="#xgboost.Booster.inplace_predict" title="xgboost.Booster.inplace_predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">xgboost.Booster.inplace_predict()</span></code></a> for details.</p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – Value in the input data which needs to be present as a missing
value. If None, defaults to np.nan.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p><p>See <a class="reference internal" href="#xgboost.DMatrix" title="xgboost.DMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.DMatrix</span></code></a> for details.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
<li><p><strong>strict_shape</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><p>See <a class="reference internal" href="#xgboost.Booster.predict" title="xgboost.Booster.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">xgboost.Booster.predict()</span></code></a> for details.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>When input data is <code class="docutils literal notranslate"><span class="pre">dask.array.Array</span></code>, the return value is an array, when input
data is <code class="docutils literal notranslate"><span class="pre">dask.dataframe.DataFrame</span></code>, return value can be
<code class="docutils literal notranslate"><span class="pre">dask.dataframe.Series</span></code>, <code class="docutils literal notranslate"><span class="pre">dask.dataframe.DataFrame</span></code>, depending on the output
shape.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">DaskXGBClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_leaves</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_bin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grow_policy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">booster</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tree_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_child_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_delta_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampling_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bytree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bylevel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bynode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_pos_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_parallel_tree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monotone_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interaction_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">importance_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gpu_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_cat_to_onehot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.dask.DaskScikitLearnBase</span></code>, <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.ClassifierMixin.html#sklearn.base.ClassifierMixin" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.ClassifierMixin</span></code></a></p>
<p>Implementation of the scikit-learn API for XGBoost classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of gradient boosted trees.  Equivalent to number of boosting
rounds.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.fit" title="xgboost.dask.DaskXGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.fit" title="xgboost.dask.DaskXGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.best_score" title="xgboost.dask.DaskXGBClassifier.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.best_iteration" title="xgboost.dask.DaskXGBClassifier.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.fit" title="xgboost.dask.DaskXGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.dask.predict" title="xgboost.dask.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.client">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">client</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><span class="pre">distributed.Client</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.client" title="Permalink to this definition"></a></dt>
<dd><p>The dask client used in this model.  The <cite>Client</cite> object can not be serialized for
transmission, so if task is launched from a worker instead of directly from the
client process, this attribute needs to be set at that worker.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.fit" title="xgboost.dask.DaskXGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.fit" title="xgboost.dask.DaskXGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.fit" title="xgboost.dask.DaskXGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.fit" title="xgboost.dask.DaskXGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting model.</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Labels</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – instance weights</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, or </em><em>callable</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.set_params" title="xgboost.dask.DaskXGBClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.set_params" title="xgboost.dask.DaskXGBClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [L_1, L_2, …, L_n], where each L_i is an array like
object storing instance weights for the i-th validation set.</p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.set_params" title="xgboost.dask.DaskXGBClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.dask.DaskXGBClassifier" title="xgboost.dask.DaskXGBClassifier">DaskXGBClassifier</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier.fit" title="xgboost.dask.DaskXGBClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.predict_proba" title="Permalink to this definition"></a></dt>
<dd><p>Predict the probability of each <cite>X</cite> example being of a given class.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em>) – Feature matrix.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<em>array_like</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <cite>iteration_range=(10,
20)</cite>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a numpy array of shape array-like of shape (n_samples, n_classes) with the
probability of each data example being of a given class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.score" title="Permalink to this definition"></a></dt>
<dd><p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test samples.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – True labels for <cite>X</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> – Mean accuracy of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <cite>y</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBClassifier.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBClassifier.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">DaskXGBRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_leaves</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_bin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grow_policy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">booster</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tree_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_child_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_delta_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampling_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bytree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bylevel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bynode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_pos_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">nan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_parallel_tree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monotone_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interaction_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">importance_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gpu_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_cat_to_onehot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.dask.DaskScikitLearnBase</span></code>, <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html#sklearn.base.RegressorMixin" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.RegressorMixin</span></code></a></p>
<p>Implementation of the Scikit-Learn API for XGBoost.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of gradient boosted trees.  Equivalent to number of boosting
rounds.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.fit" title="xgboost.dask.DaskXGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.fit" title="xgboost.dask.DaskXGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.best_score" title="xgboost.dask.DaskXGBRegressor.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.best_iteration" title="xgboost.dask.DaskXGBRegressor.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.fit" title="xgboost.dask.DaskXGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.dask.predict" title="xgboost.dask.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.client">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">client</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><span class="pre">distributed.Client</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.client" title="Permalink to this definition"></a></dt>
<dd><p>The dask client used in this model.  The <cite>Client</cite> object can not be serialized for
transmission, so if task is launched from a worker instead of directly from the
client process, this attribute needs to be set at that worker.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.fit" title="xgboost.dask.DaskXGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.fit" title="xgboost.dask.DaskXGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.fit" title="xgboost.dask.DaskXGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.fit" title="xgboost.dask.DaskXGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting model.</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Labels</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – instance weights</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, or </em><em>callable</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.set_params" title="xgboost.dask.DaskXGBRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.set_params" title="xgboost.dask.DaskXGBRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [L_1, L_2, …, L_n], where each L_i is an array like
object storing instance weights for the i-th validation set.</p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.set_params" title="xgboost.dask.DaskXGBRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.dask.DaskXGBRegressor" title="xgboost.dask.DaskXGBRegressor">DaskXGBRegressor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor.fit" title="xgboost.dask.DaskXGBRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.score" title="Permalink to this definition"></a></dt>
<dd><p>Return the coefficient of determination of the prediction.</p>
<p>The coefficient of determination <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="14"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> is defined as
<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="15"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mfrac><mi>u</mi><mi>v</mi></mfrac><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></span>, where <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="16"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>u</mi></math></mjx-assistive-mml></mjx-container></span> is the residual
sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_pred)**</span> <span class="pre">2).sum()</span></code> and <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="17"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>v</mi></math></mjx-assistive-mml></mjx-container></span>
is the total sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_true.mean())</span> <span class="pre">**</span> <span class="pre">2).sum()</span></code>.
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always predicts
the expected value of <cite>y</cite>, disregarding the input features, would get
a <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="18"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> score of 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test samples. For some estimators this may be a precomputed
kernel matrix or a list of generic objects instead with shape
<code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_samples_fitted)</span></code>, where <code class="docutils literal notranslate"><span class="pre">n_samples_fitted</span></code>
is the number of samples used in the fitting for the estimator.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – True values for <cite>X</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> – <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="19"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <cite>y</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="20"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> score used when calling <code class="docutils literal notranslate"><span class="pre">score</span></code> on a regressor uses
<code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code> from version 0.23 to keep consistent
with default value of <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score()</span></code></a>.
This influences the <code class="docutils literal notranslate"><span class="pre">score</span></code> method of all the multioutput
regressors (except for
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRegressor</span></code></a>).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRegressor.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRegressor.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">DaskXGBRanker</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'rank:pairwise'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.dask.DaskScikitLearnBase</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.sklearn.XGBRankerMixIn</span></code></p>
<p>Implementation of the Scikit-Learn API for XGBoost Ranking.</p>
<blockquote>
<div><div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of gradient boosted trees.  Equivalent to number of boosting
rounds.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.fit" title="xgboost.dask.DaskXGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.fit" title="xgboost.dask.DaskXGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.dask.DaskXGBRanker.best_score" title="xgboost.dask.DaskXGBRanker.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.best_iteration" title="xgboost.dask.DaskXGBRanker.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.fit" title="xgboost.dask.DaskXGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For dask implementation, group is not supported, use qid instead.</p>
</div>
<p></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.dask.predict" title="xgboost.dask.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.client">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">client</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><span class="pre">distributed.Client</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.client" title="Permalink to this definition"></a></dt>
<dd><p>The dask client used in this model.  The <cite>Client</cite> object can not be serialized for
transmission, so if task is launched from a worker instead of directly from the
client process, this attribute needs to be set at that worker.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.fit" title="xgboost.dask.DaskXGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.fit" title="xgboost.dask.DaskXGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.fit" title="xgboost.dask.DaskXGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.fit" title="xgboost.dask.DaskXGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_qid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting ranker</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Labels</p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Size of each query group of training data. Should have as many elements as the
query groups in the training data.  If this is set to None, then user must
provide qid.</p></li>
<li><p><strong>qid</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Query ID for each training sample.  Should have the size of n_samples.  If
this is set to None, then user must provide group.</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – </p><p>Query group weights</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Weights are per-group for ranking tasks</p>
<p>In ranking task, one weight is assigned to each query group/id (not each
data point). This is because we only care about the relative ordering of
data points within each group, so it doesn’t make sense to assign weights
to individual data points.</p>
</div>
<p></p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_group</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list in which <code class="docutils literal notranslate"><span class="pre">eval_group[i]</span></code> is the list containing the sizes of all
query groups in the <code class="docutils literal notranslate"><span class="pre">i</span></code>-th pair in <strong>eval_set</strong>.</p></li>
<li><p><strong>eval_qid</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list in which <code class="docutils literal notranslate"><span class="pre">eval_qid[i]</span></code> is the array containing query ID of <code class="docutils literal notranslate"><span class="pre">i</span></code>-th
pair in <strong>eval_set</strong>.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.set_params" title="xgboost.dask.DaskXGBRanker.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.dask.DaskXGBRanker.set_params" title="xgboost.dask.DaskXGBRanker.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – </p><p>A list of the form [L_1, L_2, …, L_n], where each L_i is a list of
group weights on the i-th validation set.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Weights are per-group for ranking tasks</p>
<p>In ranking task, one weight is assigned to each query group (not each
data point). This is because we only care about the relative ordering of
data points within each group, so it doesn’t make sense to assign
weights to individual data points.</p>
</div>
<p></p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.set_params" title="xgboost.dask.DaskXGBRanker.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.dask.DaskXGBRanker" title="xgboost.dask.DaskXGBRanker">DaskXGBRanker</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBRanker.fit" title="xgboost.dask.DaskXGBRanker.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRanker.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRanker.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">DaskXGBRFRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bynode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.dask.DaskXGBRegressor" title="xgboost.dask.DaskXGBRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.dask.DaskXGBRegressor</span></code></a></p>
<p>Implementation of the Scikit-Learn API for XGBoost Random Forest Regressor.</p>
<blockquote>
<div><div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of trees in random forest to fit.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="xgboost.dask.DaskXGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="xgboost.dask.DaskXGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.best_score" title="xgboost.dask.DaskXGBRFRegressor.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.best_iteration" title="xgboost.dask.DaskXGBRFRegressor.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="xgboost.dask.DaskXGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Custom objective function</p>
<p>A custom objective function can be provided for the <code class="docutils literal notranslate"><span class="pre">objective</span></code>
parameter. In this case, it should have the signature
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code>:</p>
<dl class="simple">
<dt>y_true: array_like of shape [n_samples]</dt><dd><p>The target values</p>
</dd>
<dt>y_pred: array_like of shape [n_samples]</dt><dd><p>The predicted values</p>
</dd>
<dt>grad: array_like of shape [n_samples]</dt><dd><p>The value of the gradient for each sample point.</p>
</dd>
<dt>hess: array_like of shape [n_samples]</dt><dd><p>The value of the second derivative for each sample point</p>
</dd>
</dl>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.dask.predict" title="xgboost.dask.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.client">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">client</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><span class="pre">distributed.Client</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.client" title="Permalink to this definition"></a></dt>
<dd><p>The dask client used in this model.  The <cite>Client</cite> object can not be serialized for
transmission, so if task is launched from a worker instead of directly from the
client process, this attribute needs to be set at that worker.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="xgboost.dask.DaskXGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="xgboost.dask.DaskXGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="xgboost.dask.DaskXGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="xgboost.dask.DaskXGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting model.</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Labels</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – instance weights</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, or </em><em>callable</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.set_params" title="xgboost.dask.DaskXGBRFRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.set_params" title="xgboost.dask.DaskXGBRFRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [L_1, L_2, …, L_n], where each L_i is an array like
object storing instance weights for the i-th validation set.</p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.set_params" title="xgboost.dask.DaskXGBRFRegressor.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor" title="xgboost.dask.DaskXGBRFRegressor">DaskXGBRFRegressor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBRFRegressor.fit" title="xgboost.dask.DaskXGBRFRegressor.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.score" title="Permalink to this definition"></a></dt>
<dd><p>Return the coefficient of determination of the prediction.</p>
<p>The coefficient of determination <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="21"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> is defined as
<span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="22"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mi class="mjx-i" size="s"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mfrac><mi>u</mi><mi>v</mi></mfrac><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></span>, where <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="23"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>u</mi></math></mjx-assistive-mml></mjx-container></span> is the residual
sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_pred)**</span> <span class="pre">2).sum()</span></code> and <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="24"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>v</mi></math></mjx-assistive-mml></mjx-container></span>
is the total sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_true.mean())</span> <span class="pre">**</span> <span class="pre">2).sum()</span></code>.
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always predicts
the expected value of <cite>y</cite>, disregarding the input features, would get
a <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="25"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> score of 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test samples. For some estimators this may be a precomputed
kernel matrix or a list of generic objects instead with shape
<code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_samples_fitted)</span></code>, where <code class="docutils literal notranslate"><span class="pre">n_samples_fitted</span></code>
is the number of samples used in the fitting for the estimator.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – True values for <cite>X</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> – <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="26"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <cite>y</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The <span class="math notranslate nohighlight"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" style="font-size: 116.9%; position: relative;" tabindex="0" ctxtmenu_counter="27"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container></span> score used when calling <code class="docutils literal notranslate"><span class="pre">score</span></code> on a regressor uses
<code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code> from version 0.23 to keep consistent
with default value of <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="(in scikit-learn v1.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score()</span></code></a>.
This influences the <code class="docutils literal notranslate"><span class="pre">score</span></code> method of all the multioutput
regressors (except for
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRegressor</span></code></a>).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFRegressor.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFRegressor.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">xgboost.dask.</span></span><span class="sig-name descname"><span class="pre">DaskXGBRFClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colsample_bynode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#xgboost.dask.DaskXGBClassifier" title="xgboost.dask.DaskXGBClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">xgboost.dask.DaskXGBClassifier</span></code></a></p>
<p>Implementation of the Scikit-Learn API for XGBoost Random Forest Classifier.</p>
<blockquote>
<div><div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of trees in random forest to fit.</p></li>
<li><p><strong>max_depth</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Maximum tree depth for base learners.</p></li>
<li><p><strong>max_leaves</strong> – Maximum number of leaves; 0 indicates no limit.</p></li>
<li><p><strong>max_bin</strong> – If using histogram-based algorithm, maximum number of bins per feature</p></li>
<li><p><strong>grow_policy</strong> – Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow
depth-wise. 1: favor splitting at nodes with highest loss change.</p></li>
<li><p><strong>learning_rate</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Boosting learning rate (xgb’s “eta”)</p></li>
<li><p><strong>verbosity</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</p></li>
<li><p><strong>objective</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Callable" title="(in Python v3.6)"><em>Callable</em></a><em>[</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><em>numpy.ndarray</em></a><em>]</em><em>]</em><em>, </em><em>NoneType</em><em>]</em>) – Specify the learning task and the corresponding learning objective or
a custom objective function to be used (see note below).</p></li>
<li><p><strong>booster</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which booster to use: gbtree, gblinear or dart.</p></li>
<li><p><strong>tree_method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Specify which tree method to use.  Default to auto.  If this parameter is set to
default, XGBoost will choose the most conservative option available.  It’s
recommended to study this option from the parameters document <a class="reference internal" href="../treemethod.html"><span class="doc">tree method</span></a></p></li>
<li><p><strong>n_jobs</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
algorithms like grid search, you may choose which algorithm to parallelize and
balance the threads.  Creating thread contention will significantly slow down both
algorithms.</p></li>
<li><p><strong>gamma</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – (min_split_loss) Minimum loss reduction required to make a further partition on a
leaf node of the tree.</p></li>
<li><p><strong>min_child_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Minimum sum of instance weight(hessian) needed in a child.</p></li>
<li><p><strong>max_delta_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Maximum delta step we allow each tree’s weight estimation to be.</p></li>
<li><p><strong>subsample</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of the training instance.</p></li>
<li><p><strong>sampling_method</strong> – </p><dl class="simple">
<dt>Sampling method. Used only by <cite>gpu_hist</cite> tree method.</dt><dd><ul>
<li><p><cite>uniform</cite>: select random training instances uniformly.</p></li>
<li><p><cite>gradient_based</cite> select random training instances with higher probability when
the gradient and hessian are larger. (cf. CatBoost)</p></li>
</ul>
</dd>
</dl>
<p></p></li>
<li><p><strong>colsample_bytree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns when constructing each tree.</p></li>
<li><p><strong>colsample_bylevel</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each level.</p></li>
<li><p><strong>colsample_bynode</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Subsample ratio of columns for each split.</p></li>
<li><p><strong>reg_alpha</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L1 regularization term on weights (xgb’s alpha).</p></li>
<li><p><strong>reg_lambda</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – L2 regularization term on weights (xgb’s lambda).</p></li>
<li><p><strong>scale_pos_weight</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – Balancing of positive and negative weights.</p></li>
<li><p><strong>base_score</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – The initial prediction score of all instances, global bias.</p></li>
<li><p><strong>random_state</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.22)"><em>numpy.random.RandomState</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Random number seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using gblinear booster with shotgun updater is nondeterministic as
it uses Hogwild algorithm.</p>
</div>
<p></p></li>
<li><p><strong>missing</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>, </em><em>default np.nan</em>) – Value in the data which needs to be present as a missing value.</p></li>
<li><p><strong>num_parallel_tree</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Used for boosting random forest.</p></li>
<li><p><strong>monotone_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em>) – Constraint of variable monotonicity.  See <a class="reference internal" href="../tutorials/monotonic.html"><span class="doc">tutorial</span></a>
for more information.</p></li>
<li><p><strong>interaction_constraints</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>]</em><em>]</em><em>]</em>) – Constraints for interaction representing permitted interactions.  The
constraints must be specified in the form of a nested list, e.g. <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">1],</span> <span class="pre">[2,</span>
<span class="pre">3,</span> <span class="pre">4]]</span></code>, where each inner list is a group of indices of features that are
allowed to interact with each other.  See <a class="reference internal" href="../tutorials/feature_interaction_constraint.html"><span class="doc">tutorial</span></a> for more information</p></li>
<li><p><strong>importance_type</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p><p>The feature importance type for the feature_importances_ property:</p>
<ul>
<li><p>For tree model, it’s either “gain”, “weight”, “cover”, “total_gain” or
“total_cover”.</p></li>
<li><p>For linear model, only “weight” is defined and it’s the normalized coefficients
without bias.</p></li>
</ul>
<p></p></li>
<li><p><strong>gpu_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Device ordinal.</p></li>
<li><p><strong>validate_parameters</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a><em>]</em>) – Give warnings for unknown parameter.</p></li>
<li><p><strong>predictor</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – Force XGBoost to use specific predictor, available choices are [cpu_predictor,
gpu_predictor].</p></li>
<li><p><strong>enable_categorical</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.5.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame
should be used to specify categorical data type.  Also, JSON/UBJSON
serialization format is required.</p>
<p></p></li>
<li><p><strong>max_cat_to_onehot</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter is experimental</p>
</div>
<p>A threshold for deciding whether XGBoost should use one-hot encoding based split
for categorical data.  When number of categories is lesser than the threshold
then one-hot encoding is chosen, otherwise the categories will be partitioned
into children nodes.  Only relevant for regression and binary classification.
See <a class="reference internal" href="../tutorials/categorical.html"><span class="doc">Categorical Data</span></a> for details.</p>
<p></p></li>
<li><p><strong>eval_metric</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em><em>, </em><em>Callable</em><em>]</em><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Metric used for monitoring the training result and early stopping.  It can be a
string or list of strings as names of predefined metric in XGBoost (See
doc/parameter.rst), one of the metrics in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" title="(in scikit-learn v1.0)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a>, or any other
user defined metric that looks like <cite>sklearn.metrics</cite>.</p>
<p>If custom objective is also provided, then custom metric should implement the
corresponding reverse link function.</p>
<p>Unlike the <cite>scoring</cite> parameter commonly used in scikit-learn, when a callable
object is provided, it’s assumed to be a cost function and by default XGBoost will
minimize the result during early stopping.</p>
<p>For advanced usage on Early stopping like directly choosing to maximize instead of
minimize, see <a class="reference internal" href="#xgboost.callback.EarlyStopping" title="xgboost.callback.EarlyStopping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xgboost.callback.EarlyStopping</span></code></a>.</p>
<p>See <a class="reference internal" href="../tutorials/custom_metric_obj.html"><span class="doc">Custom Objective and Evaluation Metric</span></a>
for more.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>eval_metric</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="xgboost.dask.DaskXGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.  The old one
receives un-transformed prediction regardless of whether custom objective is
being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span>
    <span class="n">tree_method</span><span class="o">=</span><span class="s2">"hist"</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)])</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p><div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.0.</span></p>
</div>
<p>Activates early stopping. Validation metric needs to improve at least once in
every <strong>early_stopping_rounds</strong> round(s) to continue training.  Requires at least
one item in <strong>eval_set</strong> in <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="xgboost.dask.DaskXGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
<p>The method returns the model from the last iteration (not the best one).  If
there’s more than one item in <strong>eval_set</strong>, the last entry will be used for early
stopping.  If there’s more than one metric in <strong>eval_metric</strong>, the last metric
will be used for early stopping.</p>
<p>If early stopping occurs, the model will have three additional fields:
<a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.best_score" title="xgboost.dask.DaskXGBRFClassifier.best_score"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_score</span></code></a>, <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.best_iteration" title="xgboost.dask.DaskXGBRFClassifier.best_iteration"><code class="xref py py-attr docutils literal notranslate"><span class="pre">best_iteration</span></code></a> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">best_ntree_limit</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter replaces <cite>early_stopping_rounds</cite> in <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="xgboost.dask.DaskXGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> method.</p>
</div>
<p></p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>TrainingCallback</em></a><em>]</em><em>]</em>) – </p><p>List of callback functions that are applied at end of each iteration.
It is possible to use predefined callbacks by using
<a class="reference internal" href="#callback-api"><span class="std std-ref">Callback API</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>States in callback are not preserved during training, which means callback
objects can not be reused for multiple training sessions without
reinitialization or deepcopy.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">parameters_grid</span><span class="p">:</span>
    <span class="c1"># be sure to (re)initialize the callbacks before each run</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">xgb</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">custom_rates</span><span class="p">)]</span>
    <span class="n">xgboost</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p></p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#dict" title="(in Python v3.6)"><em>dict</em></a><em>, </em><em>optional</em>) – </p><p>Keyword arguments for XGBoost Booster object.  Full documentation of parameters
can be found <a class="reference internal" href="../parameter.html"><span class="doc">here</span></a>.
Attempting to set a parameter via the constructor args and **kwargs
dict simultaneously will result in a TypeError.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>**kwargs unsupported by scikit-learn</p>
<p>**kwargs is unsupported by scikit-learn.  We do not guarantee
that parameters passed via this argument will interact properly
with scikit-learn.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Custom objective function</p>
<p>A custom objective function can be provided for the <code class="docutils literal notranslate"><span class="pre">objective</span></code>
parameter. In this case, it should have the signature
<code class="docutils literal notranslate"><span class="pre">objective(y_true,</span> <span class="pre">y_pred)</span> <span class="pre">-&gt;</span> <span class="pre">grad,</span> <span class="pre">hess</span></code>:</p>
<dl class="simple">
<dt>y_true: array_like of shape [n_samples]</dt><dd><p>The target values</p>
</dd>
<dt>y_pred: array_like of shape [n_samples]</dt><dd><p>The predicted values</p>
</dd>
<dt>grad: array_like of shape [n_samples]</dt><dd><p>The value of the gradient for each sample point.</p>
</dd>
<dt>hess: array_like of shape [n_samples]</dt><dd><p>The value of the second derivative for each sample point</p>
</dd>
</dl>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.apply" title="Permalink to this definition"></a></dt>
<dd><p>Return the predicted leaf every tree for each sample. If the model is trained with
early stopping, then <cite>best_iteration</cite> is used automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em><em>, </em><em>shape=</em><em>[</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Input features matrix.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – See <a class="reference internal" href="#xgboost.dask.predict" title="xgboost.dask.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <code class="docutils literal notranslate"><span class="pre">iteration_range</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_leaves</strong> – For each datapoint x in X and for each tree, return the index of the
leaf x ends up in. Leaves are numbered within
<code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">2**(self.max_depth+1))</span></code>, possibly with gaps in the numbering.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array_like, shape=[n_samples, n_trees]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.best_iteration">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_iteration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.best_iteration" title="Permalink to this definition"></a></dt>
<dd><p>The best iteration obtained by early stopping.  This attribute is 0-based,
for instance if the best iteration is the first round, then best_iteration is 0.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.best_score">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.best_score" title="Permalink to this definition"></a></dt>
<dd><p>The best score obtained by early stopping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.client">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">client</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://distributed.dask.org/en/stable/api.html#distributed.Client" title="(in Dask.distributed v2022.5.0)"><span class="pre">distributed.Client</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.client" title="Permalink to this definition"></a></dt>
<dd><p>The dask client used in this model.  The <cite>Client</cite> object can not be serialized for
transmission, so if task is launched from a worker instead of directly from the
client process, this attribute needs to be set at that worker.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.coef_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">coef_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.coef_" title="Permalink to this definition"></a></dt>
<dd><p>Coefficients property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Coefficients are defined only for linear learners</p>
<p>Coefficients are only defined when the linear model is chosen as
base learner (<cite>booster=gblinear</cite>). It is not defined for other base
learner types, such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>coef_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes,</span> <span class="pre">n_features]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.evals_result">
<span class="sig-name descname"><span class="pre">evals_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.evals_result" title="Permalink to this definition"></a></dt>
<dd><p>Return the evaluation results.</p>
<p>If <strong>eval_set</strong> is passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="xgboost.dask.DaskXGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, you can call
<code class="docutils literal notranslate"><span class="pre">evals_result()</span></code> to get evaluation results for all passed <strong>eval_sets</strong>.  When
<strong>eval_metric</strong> is also passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="xgboost.dask.DaskXGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a> function, the
<strong>evals_result</strong> will contain the <strong>eval_metrics</strong> passed to the <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="xgboost.dask.DaskXGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>
function.</p>
<p>The returned evaluation result is a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">'validation_0'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.604835'</span><span class="p">,</span> <span class="s1">'0.531479'</span><span class="p">]},</span>
 <span class="s1">'validation_1'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'logloss'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'0.41965'</span><span class="p">,</span> <span class="s1">'0.17686'</span><span class="p">]}}</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>evals_result</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.feature_importances_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.feature_importances_" title="Permalink to this definition"></a></dt>
<dd><p>Feature importances property, return depends on <cite>importance_type</cite> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p><ul class="simple">
<li><p><strong>feature_importances_</strong> (array of shape <code class="docutils literal notranslate"><span class="pre">[n_features]</span></code> except for multi-class)</p></li>
<li><p>linear model, which returns an array with shape <cite>(n_features, n_classes)</cite></p></li>
</ul>
<p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.feature_names_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">feature_names_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.feature_names_in_" title="Permalink to this definition"></a></dt>
<dd><p>Names of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="xgboost.dask.DaskXGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.  Defined only when <cite>X</cite> has feature
names that are all strings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_rounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xgb_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin_eval_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit gradient boosting model.</p>
<p>Note that calling <code class="docutils literal notranslate"><span class="pre">fit()</span></code> multiple times will cause the model object to be
re-fit from scratch. To resume training from a previous checkpoint, explicitly
pass <code class="docutils literal notranslate"><span class="pre">xgb_model</span></code> argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Feature matrix</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Labels</p></li>
<li><p><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – instance weights</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – global bias for each instance.</p></li>
<li><p><strong>eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A list of (X, y) tuple pairs to use as validation sets, for which
metrics will be computed.
Validation metrics will help us track the performance of the model.</p></li>
<li><p><strong>eval_metric</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>list of str</em><em>, or </em><em>callable</em><em>, </em><em>optional</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>eval_metric</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.set_params" title="xgboost.dask.DaskXGBRFClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>early_stopping_rounds</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>early_stopping_rounds</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or
<a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.set_params" title="xgboost.dask.DaskXGBRFClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – If <cite>verbose</cite> and an evaluation set is used, writes the evaluation metric
measured on the validation set to stderr.</p></li>
<li><p><strong>xgb_model</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference internal" href="#xgboost.Booster" title="xgboost.core.Booster"><em>xgboost.core.Booster</em></a><em>, </em><em>xgboost.sklearn.XGBModel</em><em>]</em><em>]</em>) – file name of stored XGBoost model or ‘Booster’ instance XGBoost model to be
loaded before training (allows training continuation).</p></li>
<li><p><strong>sample_weight_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [L_1, L_2, …, L_n], where each L_i is an array like
object storing instance weights for the i-th validation set.</p></li>
<li><p><strong>base_margin_eval_set</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em><em>]</em>) – A list of the form [M_1, M_2, …, M_n], where each M_i is an array like
object storing base margin for the i-th validation set.</p></li>
<li><p><strong>feature_weights</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Weight for each feature, defines the probability of each feature being
selected when colsample is being used.  All values must be greater than 0,
otherwise a <cite>ValueError</cite> is thrown.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#xgboost.callback.TrainingCallback" title="xgboost.callback.TrainingCallback"><em>xgboost.callback.TrainingCallback</em></a><em>]</em><em>]</em>) – </p><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.6.0: </span>Use <cite>callbacks</cite> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> or <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.set_params" title="xgboost.dask.DaskXGBRFClassifier.set_params"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_params()</span></code></a> instead.</p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier" title="xgboost.dask.DaskXGBRFClassifier">DaskXGBRFClassifier</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.get_booster">
<span class="sig-name descname"><span class="pre">get_booster</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.get_booster" title="Permalink to this definition"></a></dt>
<dd><p>Get the underlying xgboost Booster of this model.</p>
<p>This will raise an exception when fit was not called</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>booster</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a xgboost booster of underlying model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.get_num_boosting_rounds">
<span class="sig-name descname"><span class="pre">get_num_boosting_rounds</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.get_num_boosting_rounds" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of xgboost boosting rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.get_xgb_params">
<span class="sig-name descname"><span class="pre">get_xgb_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.get_xgb_params" title="Permalink to this definition"></a></dt>
<dd><p>Get xgboost specific parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a>[<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)">str</a>, <a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.intercept_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">intercept_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><span class="pre">numpy.ndarray</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.intercept_" title="Permalink to this definition"></a></dt>
<dd><p>Intercept (bias) property</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Intercept is defined only for linear learners</p>
<p>Intercept (bias) is only defined when the linear model is chosen as base
learner (<cite>booster=gblinear</cite>). It is not defined for other base learner types,
such as tree learners (<cite>booster=gbtree</cite>).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>intercept_</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> or <code class="docutils literal notranslate"><span class="pre">[n_classes]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a file or bytearray. Path to file can be local
or as an URI.</p>
<p>The model is loaded from XGBoost format which is universal among the various
XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as
feature_names) will not be loaded when using binary format.  To save those
attributes, use JSON/UBJ instead.  See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a>
for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#bytearray" title="(in Python v3.6)"><em>bytearray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a><em>]</em>) – Input file name or memory buffer(see also save_raw)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.n_features_in_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_features_in_</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a></em><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.n_features_in_" title="Permalink to this definition"></a></dt>
<dd><p>Number of features seen during <a class="reference internal" href="#xgboost.dask.DaskXGBRFClassifier.fit" title="xgboost.dask.DaskXGBRFClassifier.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict with <cite>X</cite>.  If the model is trained with early stopping, then <cite>best_iteration</cite>
is used automatically.  For tree models, when data is on GPU, like cupy array or
cuDF dataframe and <cite>predictor</cite> is not specified, the prediction is run on GPU
automatically, otherwise it will run on CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em>) – Data to predict with.</p></li>
<li><p><strong>output_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – Whether to output the raw untransformed margin value.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>da.Array</em><em>, </em><em>dd.DataFrame</em><em>, </em><em>dd.Series</em><em>]</em><em>]</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – </p><p>Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <code class="docutils literal notranslate"><span class="pre">iteration_range=(10,</span>
<span class="pre">20)</span></code>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p></p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ntree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_margin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.predict_proba" title="Permalink to this definition"></a></dt>
<dd><p>Predict the probability of each <cite>X</cite> example being of a given class.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is only thread safe for <cite>gbtree</cite> and <cite>dart</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array_like</em>) – Feature matrix.</p></li>
<li><p><strong>ntree_limit</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Deprecated, use <cite>iteration_range</cite> instead.</p></li>
<li><p><strong>validate_features</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – When this is True, validate that the Booster’s and data’s feature_names are
identical.  Otherwise, it is assumed that the feature_names are the same.</p></li>
<li><p><strong>base_margin</strong> (<em>array_like</em>) – Margin added to prediction.</p></li>
<li><p><strong>iteration_range</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em><em>]</em>) – Specifies which layer of trees are used in prediction.  For example, if a
random forest is trained with 100 rounds.  Specifying <cite>iteration_range=(10,
20)</cite>, then only the forests built during [10, 20) (half open set) rounds are
used in this prediction.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a numpy array of shape array-like of shape (n_samples, n_classes) with the
probability of each data example being of a given class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>prediction</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save the model to a file.</p>
<p>The model is saved in an XGBoost internal format which is universal among the
various XGBoost interfaces. Auxiliary attributes of the Python Booster object
(such as feature_names) will not be saved when using binary format.  To save
those attributes, use JSON/UBJ instead. See <a class="reference internal" href="../tutorials/saving_model.html"><span class="doc">Model IO</span></a> for more info.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">)</span>
<span class="c1"># or</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">"model.ubj"</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fname</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3.6/library/os.html#os.PathLike" title="(in Python v3.6)"><em>os.PathLike</em></a>) – Output file name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.score" title="Permalink to this definition"></a></dt>
<dd><p>Return the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Test samples.</p></li>
<li><p><strong>y</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>) or </em><em>(</em><em>n_samples</em><em>, </em><em>n_outputs</em><em>)</em>) – True labels for <cite>X</cite>.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score</strong> – Mean accuracy of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> wrt. <cite>y</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="xgboost.dask.DaskXGBRFClassifier.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#xgboost.dask.DaskXGBRFClassifier.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.  Modification of the sklearn method to
allow unknown kwargs. This allows using the full range of xgboost
parameters that are not defined as member variables in sklearn grid
search.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Any" title="(in Python v3.6)"><em>Any</em></a>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="python_intro.html" class="btn btn-neutral float-left" title="Python Package Introduction" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="callbacks.html" class="btn btn-neutral float-right" title="Callback Functions" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr><div><div id="rtd-sidebar" data-ea-publisher="readthedocs" data-ea-type="readthedocs-sidebar" data-ea-manual="true" class="ethical-rtd loaded" data-ea-keywords="c++|distributed-systems|gbdt|gbm|gbrt|machine-learning|readthedocs-project-33745|readthedocs-project-xgboost|xgboost" data-ea-campaign-types="community|house|paid"><div class="ethical-sidebar"><div class="ethical-content"><a href="https://server.ethicalads.io/proxy/click/2723/2e805cab-71c0-4659-952a-0f5298376805/" rel="nofollow noopener" target="_blank" class="ethical-image-link"><img src="https://media.ethicalads.io/media/images/2020/01/sticker-wtd-colors-240-180_b9300nU.png" alt="Sponsored: Read the Docs"></a><div class="ethical-text"><a href="https://server.ethicalads.io/proxy/click/2723/2e805cab-71c0-4659-952a-0f5298376805/" rel="nofollow noopener" target="_blank">Love Documentation? Write the Docs is for people like you! Join our virtual conferences or Slack.</a></div></div><div class="ethical-callout"><small><em><a href="https://docs.readthedocs.io/en/latest/advertising/ethical-advertising.html#community-ads">Community Ad</a></em></small></div></div><img src="https://server.ethicalads.io/proxy/view/2723/2e805cab-71c0-4659-952a-0f5298376805/" class="ea-pixel"><img src="https://server.ethicalads.io/proxy/viewtime/2723/2e805cab-71c0-4659-952a-0f5298376805/?view_time=20" class="ea-pixel"></div></div>

  <div role="contentinfo">
    <p>© Copyright 2021, xgboost developers.
      <span class="commit">Revision <code>5d92a7d9</code>.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="Versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: stable
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions"><!-- Inserted RTD Footer -->

<div class="injected">

  

      
      
      
      <dl>
        <dt>Versions</dt>
        
        <dd>
          <a href="https://xgboost.readthedocs.io/en/latest/python/python_api.html">latest</a>
        </dd>
        
        <dd class="rtd-current-item">
          <a href="https://xgboost.readthedocs.io/en/stable/python/python_api.html">stable</a>
        </dd>
        
        <dd>
          <a href="https://xgboost.readthedocs.io/en/release_1.5.0/python/python_api.html">release_1.5.0</a>
        </dd>
        
        <dd>
          <a href="https://xgboost.readthedocs.io/en/release_1.4.0/python/python_api.html">release_1.4.0</a>
        </dd>
        
        <dd>
          <a href="https://xgboost.readthedocs.io/en/release_1.3.0/python/python_api.html">release_1.3.0</a>
        </dd>
        
        <dd>
          <a href="https://xgboost.readthedocs.io/en/release_1.2.0/python/python_api.html">release_1.2.0</a>
        </dd>
        
        <dd>
          <a href="https://xgboost.readthedocs.io/en/release_1.1.0/python/python_api.html">release_1.1.0</a>
        </dd>
        
        <dd>
          <a href="https://xgboost.readthedocs.io/en/release_1.0.0/python/python_api.html">release_1.0.0</a>
        </dd>
        
        <dd>
          <a href="https://xgboost.readthedocs.io/en/release_0.90/python/python_api.html">release_0.90</a>
        </dd>
        
        <dd>
          <a href="https://xgboost.readthedocs.io/en/release_0.82/python/python_api.html">release_0.82</a>
        </dd>
        
        <dd>
          <a href="https://xgboost.readthedocs.io/en/release_0.81/python/python_api.html">release_0.81</a>
        </dd>
        
        <dd>
          <a href="https://xgboost.readthedocs.io/en/release_0.80/python/python_api.html">release_0.80</a>
        </dd>
        
        <dd>
          <a href="https://xgboost.readthedocs.io/en/release_0.72/python/python_api.html">release_0.72</a>
        </dd>
        
      </dl>
      
      

      
      
      <dl>
        <dt>Downloads</dt>
        
        <dd><a href="//xgboost.readthedocs.io/_/downloads/en/stable/pdf/">PDF</a></dd>
        
        <dd><a href="//xgboost.readthedocs.io/_/downloads/en/stable/htmlzip/">HTML</a></dd>
        
      </dl>
      
      

      
      <dl>
        
        <!-- These are kept as relative links for internal installs that are http -->
        <dt>On Read the Docs</dt>
        <dd>
          <a href="//readthedocs.org/projects/xgboost/">Project Home</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/projects/xgboost/builds/">Builds</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/projects/xgboost/downloads/">Downloads</a>
        </dd>
      </dl>
      

      

      
      <dl>
        <dt>On GitHub</dt>
        <dd>
          <a href="https://github.com/dmlc/xgboost/blob/5d92a7d936fc3fad4c7ecb6031c3c1c7da882a14/doc/python/python_api.rst">View</a>
        </dd>
        
      </dl>
      
      

      
      <dl>
        <dt>Search</dt>
        <dd>
          <div style="padding: 6px;">
            
            <form id="flyout-search-form" class="wy-form" target="_blank" action="//readthedocs.org/projects/xgboost/search/" method="get">
              <input type="text" name="q" aria-label="Search docs" placeholder="Search docs">
              </form>
          </div>
        </dd>
      </dl>
      

      <hr>

      
        <small>
          <span>Hosted by <a href="https://readthedocs.org">Read the Docs</a></span>
          <span> · </span>
          <a href="https://docs.readthedocs.io/page/privacy-policy.html">Privacy Policy</a>
        </small>
      

      

</div>
</div>
  </div>
<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 


</body>